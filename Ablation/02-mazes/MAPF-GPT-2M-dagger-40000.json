[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 654, "makespan": 31, "avg_agents_density": 0.10289315140264141, "runtime": 0.627779308022582}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 911, "makespan": 45, "avg_agents_density": 0.12072313125675403, "runtime": 0.6417005279072328}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 1219, "makespan": 98, "avg_agents_density": 0.08334765700326542, "runtime": 1.3178766630153405}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 805, "makespan": 44, "avg_agents_density": 0.10880932980930821, "runtime": 1.0686884309834568}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 851, "makespan": 45, "avg_agents_density": 0.10835426218952451, "runtime": 0.8221201880078297}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1222, "makespan": 74, "avg_agents_density": 0.10541098322062536, "runtime": 1.459788159976597}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 804, "makespan": 47, "avg_agents_density": 0.10185207240859843, "runtime": 0.9117217300081393}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1155, "makespan": 56, "avg_agents_density": 0.11238314979379845, "runtime": 1.4174183999857632}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 980, "makespan": 48, "avg_agents_density": 0.11819161627344706, "runtime": 1.0236113430000842}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 823, "makespan": 46, "avg_agents_density": 0.13583454683832236, "runtime": 0.7075791919633048}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 821, "makespan": 49, "avg_agents_density": 0.0869005280759744, "runtime": 0.7363004529906902}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1216, "makespan": 78, "avg_agents_density": 0.1379830106265902, "runtime": 1.3617707279336173}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 859, "makespan": 49, "avg_agents_density": 0.10470096338423485, "runtime": 1.2461955759499688}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 693, "makespan": 55, "avg_agents_density": 0.1070153368121736, "runtime": 1.146420768025564}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 747, "makespan": 44, "avg_agents_density": 0.12142387177156583, "runtime": 0.6919363010092638}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 906, "makespan": 52, "avg_agents_density": 0.10902472634623209, "runtime": 0.767043573941919}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 744, "makespan": 43, "avg_agents_density": 0.10698962267129901, "runtime": 0.700474171055248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 748, "makespan": 52, "avg_agents_density": 0.09074945255343447, "runtime": 0.794389913949999}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1141, "makespan": 64, "avg_agents_density": 0.1125640552884148, "runtime": 1.317443625026499}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 1542, "makespan": 117, "avg_agents_density": 0.11144759448123304, "runtime": 0.6828595860279165}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 875, "makespan": 50, "avg_agents_density": 0.09122105127822201, "runtime": 0.43876453895063605}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 977, "makespan": 56, "avg_agents_density": 0.11974862613018006, "runtime": 0.5315774389891885}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 690, "makespan": 37, "avg_agents_density": 0.10078048011260804, "runtime": 0.5452670518716332}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 871, "makespan": 51, "avg_agents_density": 0.11459531280713584, "runtime": 1.2843908539944096}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 922, "makespan": 47, "avg_agents_density": 0.10697243010301867, "runtime": 1.0037072940031067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 423, "makespan": 29, "avg_agents_density": 0.09345471156308707, "runtime": 0.43277331098215654}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 727, "makespan": 45, "avg_agents_density": 0.09714138067623203, "runtime": 0.6480896519933594}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 965, "makespan": 60, "avg_agents_density": 0.08582744947372581, "runtime": 1.0278990340448217}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1068, "makespan": 61, "avg_agents_density": 0.09577642041754218, "runtime": 0.17737081700761337}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 998, "makespan": 60, "avg_agents_density": 0.10579655967601369, "runtime": 0.40678986100829206}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 805, "makespan": 40, "avg_agents_density": 0.11331392741151597, "runtime": 0.2994757950073108}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 547, "makespan": 33, "avg_agents_density": 0.11195939015623085, "runtime": 0.4724113029806176}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1430, "makespan": 48, "avg_agents_density": 0.1514458476676857, "runtime": 1.4472375340556027}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1752, "makespan": 59, "avg_agents_density": 0.15793028812992216, "runtime": 1.5184606399416225}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1636, "makespan": 128, "avg_agents_density": 0.13190634951307295, "runtime": 3.2647061971656512}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1627, "makespan": 60, "avg_agents_density": 0.17372786019157974, "runtime": 1.5466149789863266}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1486, "makespan": 52, "avg_agents_density": 0.15092246829808484, "runtime": 1.3660238250158727}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2770, "makespan": 128, "avg_agents_density": 0.14579377036041227, "runtime": 3.315360083957785}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1347, "makespan": 55, "avg_agents_density": 0.1411123298262047, "runtime": 1.4117915079696104}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3311, "makespan": 128, "avg_agents_density": 0.15661541297166054, "runtime": 3.5207625300390646}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1928, "makespan": 63, "avg_agents_density": 0.17455713810928647, "runtime": 1.6179124740010593}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1722, "makespan": 57, "avg_agents_density": 0.17571034556221193, "runtime": 1.4819705670233816}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1336, "makespan": 54, "avg_agents_density": 0.12575452865931558, "runtime": 1.3885100879560923}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2857, "makespan": 128, "avg_agents_density": 0.1984999976038143, "runtime": 3.6819678229367128}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1656, "makespan": 62, "avg_agents_density": 0.1624089417440303, "runtime": 1.8430211469967617}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1657, "makespan": 72, "avg_agents_density": 0.14865331545133273, "runtime": 2.19129294193408}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1364, "makespan": 53, "avg_agents_density": 0.16949278262431525, "runtime": 1.357184245978715}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1891, "makespan": 77, "avg_agents_density": 0.16206173594422582, "runtime": 2.3769204090349376}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1817, "makespan": 62, "avg_agents_density": 0.17261962473381892, "runtime": 1.5666629660263425}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1198, "makespan": 57, "avg_agents_density": 0.12042715394541241, "runtime": 1.466591502961819}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2517, "makespan": 86, "avg_agents_density": 0.16803635020768848, "runtime": 2.216216826956952}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 4143, "makespan": 121, "avg_agents_density": 0.18030602889967576, "runtime": 2.479801249981392}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2123, "makespan": 85, "avg_agents_density": 0.1452983897780059, "runtime": 1.5999199739890173}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2200, "makespan": 78, "avg_agents_density": 0.15713772996364905, "runtime": 1.706086386970128}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1310, "makespan": 48, "avg_agents_density": 0.16253387547981016, "runtime": 1.2162418299267301}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1801, "makespan": 55, "avg_agents_density": 0.18693163386161046, "runtime": 1.2879175499256235}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2097, "makespan": 83, "avg_agents_density": 0.16007839694417372, "runtime": 2.055102239071857}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 648, "makespan": 30, "avg_agents_density": 0.135488310504212, "runtime": 0.7482256909570424}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1250, "makespan": 55, "avg_agents_density": 0.1327604419042545, "runtime": 1.4604409599269275}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1808, "makespan": 70, "avg_agents_density": 0.1326277827483427, "runtime": 1.7677777459612116}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2307, "makespan": 102, "avg_agents_density": 0.14509862196616766, "runtime": 2.5723411059298087}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2181, "makespan": 70, "avg_agents_density": 0.1705908150793818, "runtime": 1.6311869869969087}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 1957, "makespan": 104, "avg_agents_density": 0.18121162817946573, "runtime": 2.632392360974336}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 960, "makespan": 41, "avg_agents_density": 0.14913153977117002, "runtime": 1.0148439909680746}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 2999, "makespan": 128, "avg_agents_density": 0.17998806380396495, "runtime": 4.358970642002532}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 3060, "makespan": 75, "avg_agents_density": 0.1998208867249688, "runtime": 2.7537226429849397}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4163, "makespan": 128, "avg_agents_density": 0.2113492898913317, "runtime": 4.4325138720014365}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2396, "makespan": 65, "avg_agents_density": 0.19986089982722816, "runtime": 2.3546025609248318}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4495, "makespan": 128, "avg_agents_density": 0.2299900260244091, "runtime": 4.440443030995084}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5463, "makespan": 128, "avg_agents_density": 0.202199573526418, "runtime": 4.3914118179964134}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 3674, "makespan": 105, "avg_agents_density": 0.1868467800242138, "runtime": 3.327753671008395}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.671875, "CSR": 0.0, "ep_length": 128, "SoC": 6854, "makespan": 128, "avg_agents_density": 0.23473323924762482, "runtime": 4.109036209003534}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 4130, "makespan": 112, "avg_agents_density": 0.19326840079571114, "runtime": 3.706217083046795}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2745, "makespan": 89, "avg_agents_density": 0.2204711268589691, "runtime": 2.8137031640217174}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 4642, "makespan": 128, "avg_agents_density": 0.19810397431494994, "runtime": 4.211891536950134}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 128, "SoC": 6586, "makespan": 128, "avg_agents_density": 0.3728121703014272, "runtime": 4.041649492050055}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 3093, "makespan": 73, "avg_agents_density": 0.21437951606190456, "runtime": 2.3235136449802667}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2843, "makespan": 92, "avg_agents_density": 0.19293262938709918, "runtime": 2.932715538001503}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3375, "makespan": 92, "avg_agents_density": 0.22891079428477196, "runtime": 3.2704457169311354}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2823, "makespan": 76, "avg_agents_density": 0.20330717958084446, "runtime": 2.5059357180143707}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5996, "makespan": 128, "avg_agents_density": 0.24059944148288198, "runtime": 4.189753678903799}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1934, "makespan": 56, "avg_agents_density": 0.15462059884380983, "runtime": 1.788461700998596}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5943, "makespan": 128, "avg_agents_density": 0.21163471943817846, "runtime": 3.7596341131429654}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.671875, "CSR": 0.0, "ep_length": 128, "SoC": 6881, "makespan": 128, "avg_agents_density": 0.22959975621289572, "runtime": 3.8403522230655653}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3666, "makespan": 94, "avg_agents_density": 0.19483068000035755, "runtime": 2.7406709620845504}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3070, "makespan": 84, "avg_agents_density": 0.19478095759723607, "runtime": 2.5681156989885494}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1743, "makespan": 49, "avg_agents_density": 0.19523101775174506, "runtime": 1.489014917940949}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3194, "makespan": 128, "avg_agents_density": 0.18709015691447625, "runtime": 4.171622090056189}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4205, "makespan": 128, "avg_agents_density": 0.19796895088948085, "runtime": 3.961336417036364}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1062, "makespan": 38, "avg_agents_density": 0.18391656586813232, "runtime": 1.2930553819605848}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2361, "makespan": 72, "avg_agents_density": 0.17551777378603162, "runtime": 2.1831224160123384}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4410, "makespan": 128, "avg_agents_density": 0.17217113416838367, "runtime": 4.161471238970989}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4930, "makespan": 128, "avg_agents_density": 0.20242408454299807, "runtime": 4.19728699499683}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 3859, "makespan": 103, "avg_agents_density": 0.21149012064406106, "runtime": 3.1879086809640285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2978, "makespan": 79, "avg_agents_density": 0.22952789248291916, "runtime": 2.5008481579861837}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1646, "makespan": 50, "avg_agents_density": 0.19609339248078933, "runtime": 1.8164314799651038}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-40000"}]