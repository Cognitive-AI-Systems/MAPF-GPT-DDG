[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 751, "makespan": 36, "avg_agents_density": 0.09998008598466489, "runtime": 1.1558444979746128}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 896, "makespan": 50, "avg_agents_density": 0.11893075936193394, "runtime": 0.6264026169810677}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 937, "makespan": 88, "avg_agents_density": 0.0853311473253677, "runtime": 2.2446448240661994}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 622, "makespan": 35, "avg_agents_density": 0.10591424155154029, "runtime": 0.9907968709740089}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 796, "makespan": 44, "avg_agents_density": 0.10708058027511899, "runtime": 1.4621079419594025}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1093, "makespan": 60, "avg_agents_density": 0.11017979459634812, "runtime": 2.1731905460037524}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 740, "makespan": 45, "avg_agents_density": 0.09896570258412093, "runtime": 1.6411076280201087}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1251, "makespan": 57, "avg_agents_density": 0.11108623999294039, "runtime": 1.882378269045148}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 897, "makespan": 41, "avg_agents_density": 0.11487097454328156, "runtime": 1.1887834829831263}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 908, "makespan": 57, "avg_agents_density": 0.12174027627358154, "runtime": 1.4349264670163393}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 836, "makespan": 57, "avg_agents_density": 0.08986485009541048, "runtime": 1.1792578040767694}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1072, "makespan": 70, "avg_agents_density": 0.13734204150676751, "runtime": 2.2893122379900888}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 858, "makespan": 49, "avg_agents_density": 0.11372344901091999, "runtime": 1.6139626779622631}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 631, "makespan": 37, "avg_agents_density": 0.11200596898440168, "runtime": 1.1549730130354874}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 855, "makespan": 56, "avg_agents_density": 0.12006678056195526, "runtime": 1.1765600090584485}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 873, "makespan": 47, "avg_agents_density": 0.1045907200891825, "runtime": 0.6444428310205694}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 787, "makespan": 47, "avg_agents_density": 0.11264573393619644, "runtime": 1.460301332990639}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 759, "makespan": 52, "avg_agents_density": 0.09603925589421773, "runtime": 1.786295720943599}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1176, "makespan": 62, "avg_agents_density": 0.12158069447223117, "runtime": 2.2225793169782264}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 988, "makespan": 47, "avg_agents_density": 0.11271487007219251, "runtime": 0.5425819081137888}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 892, "makespan": 92, "avg_agents_density": 0.09094396990544, "runtime": 0.9274716019717744}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 851, "makespan": 38, "avg_agents_density": 0.1120537505293945, "runtime": 0.46473206994414795}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 635, "makespan": 43, "avg_agents_density": 0.0925746719333833, "runtime": 0.5387630649929633}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 716, "makespan": 38, "avg_agents_density": 0.10927230003199687, "runtime": 1.0373193840059685}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 979, "makespan": 56, "avg_agents_density": 0.09593281794142478, "runtime": 1.9430522610346088}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 429, "makespan": 30, "avg_agents_density": 0.09453110758213855, "runtime": 0.6276506399590289}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 680, "makespan": 45, "avg_agents_density": 0.09621027586650667, "runtime": 1.0341517099441262}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 970, "makespan": 55, "avg_agents_density": 0.08753964191162338, "runtime": 1.45238702595816}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1069, "makespan": 58, "avg_agents_density": 0.08938526437036104, "runtime": 0.5893192739167716}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 933, "makespan": 55, "avg_agents_density": 0.10441154852643643, "runtime": 0.2784829919983167}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 604, "makespan": 28, "avg_agents_density": 0.11825231087795182, "runtime": 0.23646691501198802}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 518, "makespan": 29, "avg_agents_density": 0.11537027401026836, "runtime": 0.3328129870351404}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1487, "makespan": 59, "avg_agents_density": 0.1452125384441456, "runtime": 2.3744880390004255}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1738, "makespan": 54, "avg_agents_density": 0.16439573025863882, "runtime": 2.2534760650305543}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1475, "makespan": 128, "avg_agents_density": 0.13173996889297032, "runtime": 4.669493599954876}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1297, "makespan": 51, "avg_agents_density": 0.16305806811763487, "runtime": 1.9079168630414642}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1459, "makespan": 68, "avg_agents_density": 0.1431676855948012, "runtime": 2.4779871530336095}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2070, "makespan": 74, "avg_agents_density": 0.1597224771096329, "runtime": 2.8404226220591227}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1237, "makespan": 49, "avg_agents_density": 0.14116021414782698, "runtime": 2.1223398269648897}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 3498, "makespan": 110, "avg_agents_density": 0.15775728077318046, "runtime": 4.19364738096192}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1554, "makespan": 53, "avg_agents_density": 0.17505190411950602, "runtime": 2.1270347590761958}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1413, "makespan": 53, "avg_agents_density": 0.16884191029260295, "runtime": 2.0162274300528225}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1362, "makespan": 61, "avg_agents_density": 0.12937472845210882, "runtime": 2.1914446400332963}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 3111, "makespan": 128, "avg_agents_density": 0.2211485616905408, "runtime": 5.314348836036515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1357, "makespan": 47, "avg_agents_density": 0.16034875885929345, "runtime": 1.9853126060334034}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1200, "makespan": 49, "avg_agents_density": 0.15363405606545036, "runtime": 1.997746939989156}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1337, "makespan": 48, "avg_agents_density": 0.17399426515842906, "runtime": 2.060046115977457}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1365, "makespan": 45, "avg_agents_density": 0.1621285592299632, "runtime": 1.9272218380210688}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1620, "makespan": 51, "avg_agents_density": 0.17043829864550328, "runtime": 2.0079647240636405}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1293, "makespan": 54, "avg_agents_density": 0.1154062244383266, "runtime": 2.3754942059749737}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 2842, "makespan": 104, "avg_agents_density": 0.16036391316292142, "runtime": 4.321679062952171}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2831, "makespan": 89, "avg_agents_density": 0.1756043950394434, "runtime": 2.9762087510316633}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1579, "makespan": 52, "avg_agents_density": 0.14651141393718062, "runtime": 1.8058928040263709}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1562, "makespan": 59, "avg_agents_density": 0.15441177094765038, "runtime": 1.8882701970433118}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1069, "makespan": 45, "avg_agents_density": 0.146152676202525, "runtime": 1.7161924840474967}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1531, "makespan": 54, "avg_agents_density": 0.16729797903658514, "runtime": 1.6389884890377289}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1677, "makespan": 63, "avg_agents_density": 0.15280125054513616, "runtime": 2.2145379400608363}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 653, "makespan": 29, "avg_agents_density": 0.1353365118041922, "runtime": 1.1864289630029816}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1244, "makespan": 54, "avg_agents_density": 0.13378029106591857, "runtime": 2.0504760590411024}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1832, "makespan": 63, "avg_agents_density": 0.13082527022746607, "runtime": 2.0872620639711386}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2138, "makespan": 77, "avg_agents_density": 0.13595026899717672, "runtime": 2.4800250310509}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1916, "makespan": 62, "avg_agents_density": 0.15919159753633802, "runtime": 1.9592550859670155}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1720, "makespan": 77, "avg_agents_density": 0.17900830110240468, "runtime": 3.0861290769826155}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 913, "makespan": 36, "avg_agents_density": 0.14425887744282528, "runtime": 1.1392559180094395}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2630, "makespan": 72, "avg_agents_density": 0.18215251407199115, "runtime": 5.34411652199924}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 3615, "makespan": 77, "avg_agents_density": 0.21790844834562903, "runtime": 4.902511770022102}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 2597, "makespan": 128, "avg_agents_density": 0.1856217679138515, "runtime": 6.625933779971092}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2058, "makespan": 59, "avg_agents_density": 0.19881260677244983, "runtime": 3.3234844790422358}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2737, "makespan": 83, "avg_agents_density": 0.20387878706683354, "runtime": 4.391840931930346}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 5509, "makespan": 128, "avg_agents_density": 0.20967505969174927, "runtime": 6.636274929871433}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2312, "makespan": 69, "avg_agents_density": 0.18284474669893985, "runtime": 3.1885935189930024}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5251, "makespan": 128, "avg_agents_density": 0.2043244953527148, "runtime": 5.893522464000853}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 3138, "makespan": 90, "avg_agents_density": 0.20388366468625438, "runtime": 4.211373831014498}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2209, "makespan": 61, "avg_agents_density": 0.22328909490159227, "runtime": 2.880597353927442}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2338, "makespan": 66, "avg_agents_density": 0.16518666980596808, "runtime": 2.9621339379809797}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.609375, "CSR": 0.0, "ep_length": 128, "SoC": 6660, "makespan": 128, "avg_agents_density": 0.30203273265352965, "runtime": 5.802385908988072}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2581, "makespan": 102, "avg_agents_density": 0.19883649990095534, "runtime": 4.483799031979288}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1968, "makespan": 60, "avg_agents_density": 0.18824000413857106, "runtime": 2.5041970120801125}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2580, "makespan": 102, "avg_agents_density": 0.20156754459951956, "runtime": 5.4380175929982215}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3279, "makespan": 84, "avg_agents_density": 0.2096210586289678, "runtime": 3.625525784023921}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 3880, "makespan": 115, "avg_agents_density": 0.19972522442515747, "runtime": 5.253810612033703}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2009, "makespan": 62, "avg_agents_density": 0.15899937462016994, "runtime": 2.921278829977382}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5347, "makespan": 128, "avg_agents_density": 0.19648455570355, "runtime": 4.96846751900739}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 5269, "makespan": 128, "avg_agents_density": 0.2091840964924835, "runtime": 5.153659996925853}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3621, "makespan": 128, "avg_agents_density": 0.19009644214388352, "runtime": 5.419016160070896}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2963, "makespan": 76, "avg_agents_density": 0.1982250700922537, "runtime": 3.3583537969825557}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1715, "makespan": 62, "avg_agents_density": 0.17906747596994857, "runtime": 2.599393380980473}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2959, "makespan": 128, "avg_agents_density": 0.19117931008167674, "runtime": 5.922904054867104}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 3560, "makespan": 128, "avg_agents_density": 0.1987505534621648, "runtime": 5.696588689927012}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 1015, "makespan": 34, "avg_agents_density": 0.18574680724836057, "runtime": 1.8013711080129724}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1832, "makespan": 44, "avg_agents_density": 0.17163462139595026, "runtime": 1.93609443702735}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3773, "makespan": 128, "avg_agents_density": 0.17090767872784307, "runtime": 6.104957686940907}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 4264, "makespan": 115, "avg_agents_density": 0.19090656884173868, "runtime": 5.462624588893959}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 3342, "makespan": 78, "avg_agents_density": 0.2114971977830734, "runtime": 3.7368732730392367}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 3245, "makespan": 86, "avg_agents_density": 0.22580345150513145, "runtime": 3.931180538929766}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1448, "makespan": 52, "avg_agents_density": 0.17974304273915687, "runtime": 2.9707512999302708}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-384000"}]