[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 696, "makespan": 38, "avg_agents_density": 0.09791649263688587, "runtime": 1.0176035469776252}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 909, "makespan": 51, "avg_agents_density": 0.12316231266443899, "runtime": 1.5316783619782655}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 741, "makespan": 38, "avg_agents_density": 0.09428612063879122, "runtime": 0.9547032960254}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 732, "makespan": 40, "avg_agents_density": 0.11006098366385693, "runtime": 1.3825479350052774}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 841, "makespan": 62, "avg_agents_density": 0.10085960066689771, "runtime": 1.8364599509950494}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1076, "makespan": 57, "avg_agents_density": 0.11012877696518537, "runtime": 1.5858350589987822}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 850, "makespan": 60, "avg_agents_density": 0.09742701378302476, "runtime": 1.6384128170029726}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1527, "makespan": 83, "avg_agents_density": 0.10713534074487525, "runtime": 2.8314981111034285}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1135, "makespan": 48, "avg_agents_density": 0.11903563954586285, "runtime": 1.3597201899829088}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 828, "makespan": 50, "avg_agents_density": 0.12589927511752422, "runtime": 1.088375404040562}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1039, "makespan": 58, "avg_agents_density": 0.08930302886663385, "runtime": 1.7186815500172088}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1180, "makespan": 57, "avg_agents_density": 0.1483586299095186, "runtime": 1.6188603399787098}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 964, "makespan": 52, "avg_agents_density": 0.10308050983360317, "runtime": 1.7760149859823287}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 751, "makespan": 41, "avg_agents_density": 0.10873839650590761, "runtime": 1.3785899150097976}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 719, "makespan": 41, "avg_agents_density": 0.1223372502816998, "runtime": 1.2984251020097872}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1172, "makespan": 60, "avg_agents_density": 0.11104067699745515, "runtime": 0.610307839961024}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 964, "makespan": 61, "avg_agents_density": 0.10534105067468466, "runtime": 1.6767993289686274}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 930, "makespan": 65, "avg_agents_density": 0.09460482815466935, "runtime": 1.749379789995146}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1375, "makespan": 92, "avg_agents_density": 0.11891347842404255, "runtime": 3.16073570100707}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1197, "makespan": 85, "avg_agents_density": 0.11385857534940066, "runtime": 2.051798489977955}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 760, "makespan": 40, "avg_agents_density": 0.09497383243372297, "runtime": 1.1628290610242402}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 967, "makespan": 53, "avg_agents_density": 0.11243906087121494, "runtime": 0.2646958560217172}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 741, "makespan": 43, "avg_agents_density": 0.09928273904430532, "runtime": 0.9689771079720231}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 806, "makespan": 50, "avg_agents_density": 0.10746567117004782, "runtime": 1.385204393940512}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 966, "makespan": 65, "avg_agents_density": 0.09996196306111459, "runtime": 1.8799372450448573}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 429, "makespan": 29, "avg_agents_density": 0.09285011800115824, "runtime": 0.7245612499973504}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 773, "makespan": 49, "avg_agents_density": 0.09843567260560715, "runtime": 1.159058199977153}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 906, "makespan": 50, "avg_agents_density": 0.08688917274898743, "runtime": 1.5145856220187852}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1303, "makespan": 76, "avg_agents_density": 0.08823676058485604, "runtime": 0.7358193229883909}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1134, "makespan": 67, "avg_agents_density": 0.10659044306941999, "runtime": 1.6286321391235106}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 989, "makespan": 66, "avg_agents_density": 0.11378367179606742, "runtime": 0.32472034500096925}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 524, "makespan": 30, "avg_agents_density": 0.11378240549873439, "runtime": 0.4229658150143223}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1693, "makespan": 59, "avg_agents_density": 0.14524683959406667, "runtime": 1.925178652003524}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2285, "makespan": 71, "avg_agents_density": 0.16650429187393392, "runtime": 2.45082563192409}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1534, "makespan": 67, "avg_agents_density": 0.14191549763701983, "runtime": 2.139856697016512}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1449, "makespan": 54, "avg_agents_density": 0.1567813660014878, "runtime": 1.896923052991042}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1615, "makespan": 63, "avg_agents_density": 0.1502475640106966, "runtime": 2.072810325975297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2165, "makespan": 76, "avg_agents_density": 0.1559932046890906, "runtime": 2.3153424319898477}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1188, "makespan": 42, "avg_agents_density": 0.143217430949582, "runtime": 1.4169960679864744}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3443, "makespan": 128, "avg_agents_density": 0.15389484310993243, "runtime": 4.103714030148694}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1451, "makespan": 47, "avg_agents_density": 0.1666721737787478, "runtime": 1.5040178089402616}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1542, "makespan": 63, "avg_agents_density": 0.17457691832079286, "runtime": 2.0387254380329978}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1338, "makespan": 62, "avg_agents_density": 0.12806108306419697, "runtime": 2.0055102309852373}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 128, "SoC": 4640, "makespan": 128, "avg_agents_density": 0.3343565119126992, "runtime": 4.20763616192562}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1543, "makespan": 46, "avg_agents_density": 0.1579085243376857, "runtime": 1.5362221119576134}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1621, "makespan": 50, "avg_agents_density": 0.14847541418200524, "runtime": 1.6292347189883003}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1970, "makespan": 83, "avg_agents_density": 0.17739621369973968, "runtime": 2.837050093934522}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1938, "makespan": 62, "avg_agents_density": 0.16683349724520444, "runtime": 2.0199890160001814}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1940, "makespan": 75, "avg_agents_density": 0.16210799766239375, "runtime": 2.6502779210277367}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1357, "makespan": 56, "avg_agents_density": 0.12349139269687576, "runtime": 1.7390574379824102}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2898, "makespan": 128, "avg_agents_density": 0.15962695736335805, "runtime": 4.352298047015211}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3997, "makespan": 128, "avg_agents_density": 0.16486788600258334, "runtime": 3.6750747870246414}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1814, "makespan": 77, "avg_agents_density": 0.14608289921329454, "runtime": 2.7485395620024065}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1972, "makespan": 60, "avg_agents_density": 0.1548020910615022, "runtime": 1.976935550061171}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1179, "makespan": 47, "avg_agents_density": 0.15083566608347646, "runtime": 1.5488442400383065}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1967, "makespan": 73, "avg_agents_density": 0.15846742281717088, "runtime": 2.2160899770242395}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2537, "makespan": 128, "avg_agents_density": 0.15747456687874006, "runtime": 4.451937024990912}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 685, "makespan": 35, "avg_agents_density": 0.13353664923198827, "runtime": 1.2043651379499352}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1345, "makespan": 53, "avg_agents_density": 0.13588713084179077, "runtime": 1.6931911089632194}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2355, "makespan": 83, "avg_agents_density": 0.13474513174259845, "runtime": 3.0285432380333077}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2521, "makespan": 91, "avg_agents_density": 0.15021221702259901, "runtime": 3.1952734049700666}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1870, "makespan": 60, "avg_agents_density": 0.16331812817790942, "runtime": 2.0428178740112344}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2033, "makespan": 69, "avg_agents_density": 0.17897198977558368, "runtime": 2.4903630919288844}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 948, "makespan": 41, "avg_agents_density": 0.1481790295270711, "runtime": 1.4049858669895912}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2498, "makespan": 59, "avg_agents_density": 0.18626293035000868, "runtime": 2.7694504880491877}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 3465, "makespan": 73, "avg_agents_density": 0.21428790629974434, "runtime": 3.320593558048131}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3466, "makespan": 94, "avg_agents_density": 0.2087796144292701, "runtime": 4.286811292098719}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2577, "makespan": 65, "avg_agents_density": 0.20084685170263375, "runtime": 2.9877459950512275}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2560, "makespan": 79, "avg_agents_density": 0.1883220262657011, "runtime": 3.701380878992495}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5824, "makespan": 128, "avg_agents_density": 0.200442330850379, "runtime": 5.691782596026314}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 3427, "makespan": 120, "avg_agents_density": 0.17978391572407587, "runtime": 5.16447532796883}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 6981, "makespan": 128, "avg_agents_density": 0.23934549000712177, "runtime": 5.32403292687377}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2749, "makespan": 69, "avg_agents_density": 0.2052566819804943, "runtime": 2.7836581979790935}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2581, "makespan": 85, "avg_agents_density": 0.2204678994642553, "runtime": 3.4715668939606985}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2266, "makespan": 55, "avg_agents_density": 0.16794890652352348, "runtime": 2.4239256361033767}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 128, "SoC": 6579, "makespan": 128, "avg_agents_density": 0.3427184485848905, "runtime": 5.399959521921119}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 3666, "makespan": 103, "avg_agents_density": 0.20494775913047458, "runtime": 4.413803242903668}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2533, "makespan": 65, "avg_agents_density": 0.19047541412402008, "runtime": 2.7518620200135047}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 3270, "makespan": 82, "avg_agents_density": 0.21251492543359843, "runtime": 3.633748619031394}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 3811, "makespan": 93, "avg_agents_density": 0.19529695058916904, "runtime": 3.8504687530512456}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 5765, "makespan": 128, "avg_agents_density": 0.21067499928690742, "runtime": 5.215797921875492}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2051, "makespan": 59, "avg_agents_density": 0.1563089751940427, "runtime": 2.503015790018253}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 6345, "makespan": 128, "avg_agents_density": 0.1848223597331762, "runtime": 4.241741013960564}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 6119, "makespan": 128, "avg_agents_density": 0.2020232975159811, "runtime": 4.272717133993865}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 3759, "makespan": 120, "avg_agents_density": 0.1885579364607804, "runtime": 4.444246031838702}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3943, "makespan": 101, "avg_agents_density": 0.2119308562525822, "runtime": 3.659987263963558}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2027, "makespan": 57, "avg_agents_density": 0.1899819280221316, "runtime": 2.4231269199663075}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3903, "makespan": 101, "avg_agents_density": 0.19916777198975047, "runtime": 4.192652369834832}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4318, "makespan": 128, "avg_agents_density": 0.19272481895793991, "runtime": 4.7673874600441195}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1093, "makespan": 36, "avg_agents_density": 0.18330422749127187, "runtime": 1.5208533219847595}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2125, "makespan": 55, "avg_agents_density": 0.1842120429734057, "runtime": 1.7946409790311009}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 3956, "makespan": 113, "avg_agents_density": 0.1914652532577484, "runtime": 4.603070944940555}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5702, "makespan": 128, "avg_agents_density": 0.21174315241916802, "runtime": 4.975627504842123}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 4544, "makespan": 94, "avg_agents_density": 0.24268317547752144, "runtime": 3.6611977449356345}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2853, "makespan": 82, "avg_agents_density": 0.2301483833131288, "runtime": 3.4482830600172747}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1675, "makespan": 52, "avg_agents_density": 0.197275050016049, "runtime": 2.3960582710715244}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-72000"}]