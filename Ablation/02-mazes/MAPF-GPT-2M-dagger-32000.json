[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 827, "makespan": 49, "avg_agents_density": 0.10130871985697429, "runtime": 1.1092849730775924}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 979, "makespan": 64, "avg_agents_density": 0.12093581662614948, "runtime": 0.6144794440770056}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 884, "makespan": 79, "avg_agents_density": 0.08292503075729477, "runtime": 0.8938514740584651}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 693, "makespan": 43, "avg_agents_density": 0.1118239513157706, "runtime": 0.9538247790187597}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 884, "makespan": 53, "avg_agents_density": 0.1090411144342613, "runtime": 1.1520666060678195}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1204, "makespan": 71, "avg_agents_density": 0.11157602098401043, "runtime": 1.423543479933869}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 869, "makespan": 59, "avg_agents_density": 0.09973604913979892, "runtime": 1.2043197429884458}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1199, "makespan": 60, "avg_agents_density": 0.10649890513401851, "runtime": 1.7328398860117886}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 955, "makespan": 50, "avg_agents_density": 0.11584212228851436, "runtime": 1.0957235789392143}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 758, "makespan": 44, "avg_agents_density": 0.12698640435314615, "runtime": 0.6397445900074672}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 930, "makespan": 57, "avg_agents_density": 0.09105110129002042, "runtime": 0.7043175399739994}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 1840, "makespan": 128, "avg_agents_density": 0.1496317901319218, "runtime": 2.4594707999931416}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 847, "makespan": 39, "avg_agents_density": 0.10783450236278838, "runtime": 0.9413302919565467}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 701, "makespan": 37, "avg_agents_density": 0.10783088049332186, "runtime": 0.8212364659702871}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 736, "makespan": 38, "avg_agents_density": 0.12832042561494264, "runtime": 0.4953411869937554}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1058, "makespan": 50, "avg_agents_density": 0.11082684374055837, "runtime": 0.5358247170079267}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 851, "makespan": 45, "avg_agents_density": 0.10952446280862808, "runtime": 0.6177011760883033}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 753, "makespan": 49, "avg_agents_density": 0.09109289660653434, "runtime": 1.0650431750254938}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1117, "makespan": 69, "avg_agents_density": 0.11519453916000931, "runtime": 1.5173292550462065}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1489, "makespan": 82, "avg_agents_density": 0.1091935028558358, "runtime": 0.6172000670339912}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 1224, "makespan": 128, "avg_agents_density": 0.09445371633371578, "runtime": 0.8403774769249139}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1045, "makespan": 64, "avg_agents_density": 0.11531097876431184, "runtime": 0.5972771329834359}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 713, "makespan": 46, "avg_agents_density": 0.09938775651902537, "runtime": 0.5525034750608029}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 772, "makespan": 48, "avg_agents_density": 0.11001160767169157, "runtime": 1.2892659109493252}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 984, "makespan": 77, "avg_agents_density": 0.10232523626116323, "runtime": 1.69332157097233}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 442, "makespan": 32, "avg_agents_density": 0.09213752068782843, "runtime": 0.3579359069408383}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 779, "makespan": 42, "avg_agents_density": 0.10076438149645342, "runtime": 0.7396367330366047}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1024, "makespan": 64, "avg_agents_density": 0.0892463139356899, "runtime": 1.1002551549318014}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1187, "makespan": 63, "avg_agents_density": 0.09566547203424139, "runtime": 0.34367831198323984}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 931, "makespan": 52, "avg_agents_density": 0.10582460787871814, "runtime": 0.1680464160745032}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 793, "makespan": 43, "avg_agents_density": 0.11682803518296003, "runtime": 0.32822623597166967}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 571, "makespan": 29, "avg_agents_density": 0.11267099058005924, "runtime": 0.28791487296984997}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1593, "makespan": 53, "avg_agents_density": 0.1472411392476507, "runtime": 1.6316139359551016}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2025, "makespan": 70, "avg_agents_density": 0.1664644913057115, "runtime": 2.0020420369837666}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1645, "makespan": 57, "avg_agents_density": 0.147772231280096, "runtime": 1.5893497959914384}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1513, "makespan": 60, "avg_agents_density": 0.16299038541885932, "runtime": 1.6135880319779972}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1528, "makespan": 60, "avg_agents_density": 0.1494757911361288, "runtime": 1.5562822269712342}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3276, "makespan": 128, "avg_agents_density": 0.15682576629715408, "runtime": 3.4075756909587653}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 1736, "makespan": 81, "avg_agents_density": 0.14666899312956516, "runtime": 2.3074898369814036}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3404, "makespan": 128, "avg_agents_density": 0.16178195694938888, "runtime": 3.491426753986161}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2269, "makespan": 75, "avg_agents_density": 0.1717309154002129, "runtime": 1.9523967590357643}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1630, "makespan": 85, "avg_agents_density": 0.17436878224423913, "runtime": 2.225402883006609}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1788, "makespan": 76, "avg_agents_density": 0.13045752178207243, "runtime": 1.9722885890078032}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.6458333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4161, "makespan": 128, "avg_agents_density": 0.2193975430333854, "runtime": 3.500519574008649}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1996, "makespan": 66, "avg_agents_density": 0.17343352931534609, "runtime": 1.8763705669698538}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1470, "makespan": 45, "avg_agents_density": 0.14915091081240525, "runtime": 1.4541335069661727}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1423, "makespan": 50, "avg_agents_density": 0.17923025513989982, "runtime": 1.3337586980196647}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1766, "makespan": 65, "avg_agents_density": 0.16791893808418867, "runtime": 2.095926735899411}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2285, "makespan": 82, "avg_agents_density": 0.15813427488970438, "runtime": 2.0651149799959967}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1360, "makespan": 64, "avg_agents_density": 0.12095673076480429, "runtime": 1.7717059730639448}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 2857, "makespan": 121, "avg_agents_density": 0.1623203722589398, "runtime": 3.187356643989915}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.7916666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4557, "makespan": 128, "avg_agents_density": 0.16650062442269095, "runtime": 2.7244006079999963}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2361, "makespan": 128, "avg_agents_density": 0.14690498274370017, "runtime": 2.650480090000201}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2017, "makespan": 63, "avg_agents_density": 0.16225721051523775, "runtime": 1.3794427500251913}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1313, "makespan": 58, "avg_agents_density": 0.1476780162809139, "runtime": 1.6058593510388164}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1792, "makespan": 70, "avg_agents_density": 0.1563512528132286, "runtime": 1.5258882249763701}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2355, "makespan": 82, "avg_agents_density": 0.16069634849389794, "runtime": 2.271773047032184}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 719, "makespan": 43, "avg_agents_density": 0.13174714844724192, "runtime": 1.1705078359373147}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1220, "makespan": 51, "avg_agents_density": 0.13634581367545928, "runtime": 1.5477105049358215}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 2478, "makespan": 122, "avg_agents_density": 0.12978715354542758, "runtime": 3.1916713318787515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 2799, "makespan": 98, "avg_agents_density": 0.14847274561953358, "runtime": 2.5020627031335607}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 2965, "makespan": 121, "avg_agents_density": 0.16671331741678033, "runtime": 3.039110169891501}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1868, "makespan": 92, "avg_agents_density": 0.1795186104977375, "runtime": 2.5014194570394466}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 855, "makespan": 31, "avg_agents_density": 0.1409392001647949, "runtime": 0.6778201460110722}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3228, "makespan": 128, "avg_agents_density": 0.18409353610072246, "runtime": 4.772263823018875}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3993, "makespan": 101, "avg_agents_density": 0.22020241489311373, "runtime": 3.7018378200300504}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 3053, "makespan": 95, "avg_agents_density": 0.194792567463695, "runtime": 3.4808039859344717}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3069, "makespan": 84, "avg_agents_density": 0.20030766370761804, "runtime": 2.955605895986082}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4929, "makespan": 128, "avg_agents_density": 0.2202322228277557, "runtime": 4.605147203968954}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 6562, "makespan": 128, "avg_agents_density": 0.22382322255013362, "runtime": 4.586309501057258}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.671875, "CSR": 0.0, "ep_length": 128, "SoC": 4561, "makespan": 128, "avg_agents_density": 0.23615148188660212, "runtime": 4.215779814097914}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 128, "SoC": 7090, "makespan": 128, "avg_agents_density": 0.23926904168183152, "runtime": 4.214993786023115}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 3886, "makespan": 106, "avg_agents_density": 0.20316002986296192, "runtime": 3.4830990340851713}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3338, "makespan": 94, "avg_agents_density": 0.22607015654044893, "runtime": 3.0030854690703563}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 128, "SoC": 4645, "makespan": 128, "avg_agents_density": 0.21112751163076163, "runtime": 4.140200263995212}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.609375, "CSR": 0.0, "ep_length": 128, "SoC": 6827, "makespan": 128, "avg_agents_density": 0.3089988055293533, "runtime": 4.162213457995676}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4325, "makespan": 128, "avg_agents_density": 0.20225013788102822, "runtime": 4.168782732973341}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2446, "makespan": 56, "avg_agents_density": 0.1942924334238675, "runtime": 1.7838782430335414}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2719, "makespan": 68, "avg_agents_density": 0.2238972717880939, "runtime": 2.2544122689869255}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 4304, "makespan": 104, "avg_agents_density": 0.20959997769099484, "runtime": 3.4250913769792533}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 4670, "makespan": 122, "avg_agents_density": 0.21485462289057988, "runtime": 3.964650296999025}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2267, "makespan": 61, "avg_agents_density": 0.15487094824953082, "runtime": 1.9817515999166062}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 6197, "makespan": 128, "avg_agents_density": 0.18853458127319495, "runtime": 3.97207955691556}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.609375, "CSR": 0.0, "ep_length": 128, "SoC": 6549, "makespan": 128, "avg_agents_density": 0.23835469694760225, "runtime": 3.997596888933913}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3991, "makespan": 128, "avg_agents_density": 0.1857006119521524, "runtime": 3.940320213951054}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 4001, "makespan": 99, "avg_agents_density": 0.2122813059900928, "runtime": 3.166860430937959}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2321, "makespan": 69, "avg_agents_density": 0.19495916684791095, "runtime": 2.2639220540295355}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 4118, "makespan": 111, "avg_agents_density": 0.22646214326908123, "runtime": 3.483555695900577}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5417, "makespan": 128, "avg_agents_density": 0.19368865739472088, "runtime": 4.067762979015242}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1067, "makespan": 41, "avg_agents_density": 0.1781052927697917, "runtime": 1.3693245530448621}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 3232, "makespan": 100, "avg_agents_density": 0.18353340511313138, "runtime": 3.1472217348928098}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3100, "makespan": 84, "avg_agents_density": 0.17770002923911185, "runtime": 2.622164735934348}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 7002, "makespan": 128, "avg_agents_density": 0.2628472436842117, "runtime": 4.104996486159507}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5578, "makespan": 128, "avg_agents_density": 0.21523371088383653, "runtime": 4.057781129988143}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4435, "makespan": 128, "avg_agents_density": 0.23119778186127646, "runtime": 4.160843383011525}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1740, "makespan": 56, "avg_agents_density": 0.19409472545774567, "runtime": 2.113543064959231}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-32000"}]