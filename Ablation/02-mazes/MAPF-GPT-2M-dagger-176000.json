[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 746, "makespan": 44, "avg_agents_density": 0.09609247115725993, "runtime": 1.3156532470311504}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 721, "makespan": 41, "avg_agents_density": 0.12320921214668375, "runtime": 1.2222429559915327}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 766, "makespan": 49, "avg_agents_density": 0.08907747263276235, "runtime": 1.3965013150300365}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 635, "makespan": 32, "avg_agents_density": 0.11725186314347462, "runtime": 0.9825291429297067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 885, "makespan": 47, "avg_agents_density": 0.10271238426568462, "runtime": 1.4599342330329819}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1060, "makespan": 67, "avg_agents_density": 0.10448297483016851, "runtime": 2.0599104550492484}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1002, "makespan": 63, "avg_agents_density": 0.10340027246198671, "runtime": 1.984333482934744}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1242, "makespan": 62, "avg_agents_density": 0.10650891945386437, "runtime": 2.162983564994647}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1029, "makespan": 54, "avg_agents_density": 0.10835524758766744, "runtime": 1.725090149033349}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 660, "makespan": 41, "avg_agents_density": 0.13271416017342275, "runtime": 0.5537869179388508}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 837, "makespan": 55, "avg_agents_density": 0.08718897003631874, "runtime": 1.6130766848946223}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1348, "makespan": 65, "avg_agents_density": 0.141947889969996, "runtime": 2.066313714007265}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 829, "makespan": 46, "avg_agents_density": 0.10633412743045985, "runtime": 1.5343869680073112}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 664, "makespan": 47, "avg_agents_density": 0.1140949849658562, "runtime": 1.7644204839598387}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 720, "makespan": 41, "avg_agents_density": 0.12196300252512504, "runtime": 1.3126972259633476}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 835, "makespan": 43, "avg_agents_density": 0.10854292483856001, "runtime": 0.3620543809083756}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 900, "makespan": 56, "avg_agents_density": 0.10353186920558852, "runtime": 1.708838857957744}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 685, "makespan": 46, "avg_agents_density": 0.09177424380733283, "runtime": 1.3385884300805628}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1212, "makespan": 61, "avg_agents_density": 0.11958643320459593, "runtime": 1.8094062430318445}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1086, "makespan": 54, "avg_agents_density": 0.11040775747621004, "runtime": 1.494675247988198}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 998, "makespan": 85, "avg_agents_density": 0.09236045719551027, "runtime": 1.2983972329384414}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 997, "makespan": 47, "avg_agents_density": 0.11550833855058425, "runtime": 0.23927245392405894}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 639, "makespan": 39, "avg_agents_density": 0.09784317021301756, "runtime": 0.809147563049919}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 664, "makespan": 31, "avg_agents_density": 0.12078866242887538, "runtime": 0.9520791960094357}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 831, "makespan": 62, "avg_agents_density": 0.09869172003001299, "runtime": 1.8849223100114614}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 454, "makespan": 33, "avg_agents_density": 0.0949525493254989, "runtime": 0.853728629037505}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 709, "makespan": 40, "avg_agents_density": 0.09449402257791395, "runtime": 1.2287555459770374}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 993, "makespan": 55, "avg_agents_density": 0.09089271153048126, "runtime": 1.5016605719429208}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1182, "makespan": 66, "avg_agents_density": 0.09430625848048091, "runtime": 0.918922978991759}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 856, "makespan": 43, "avg_agents_density": 0.11030572683454204, "runtime": 0.3899546860193368}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 701, "makespan": 40, "avg_agents_density": 0.11444368712202364, "runtime": 0.14358559898391832}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 504, "makespan": 30, "avg_agents_density": 0.10952653730192329, "runtime": 0.4642613479663851}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1577, "makespan": 65, "avg_agents_density": 0.1478788980636322, "runtime": 2.831600953009911}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1846, "makespan": 72, "avg_agents_density": 0.1603275427328896, "runtime": 2.761398963004467}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1289, "makespan": 50, "avg_agents_density": 0.14328441120936433, "runtime": 1.661532201935188}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1336, "makespan": 49, "avg_agents_density": 0.1679990483395637, "runtime": 1.6917224329954479}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1423, "makespan": 50, "avg_agents_density": 0.14384148136439184, "runtime": 2.0069434179895325}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 2479, "makespan": 93, "avg_agents_density": 0.15250414440865756, "runtime": 3.906053202066687}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1334, "makespan": 51, "avg_agents_density": 0.14468763067417398, "runtime": 1.9780679599789437}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3091, "makespan": 128, "avg_agents_density": 0.15487937421528947, "runtime": 5.544188652085722}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1695, "makespan": 57, "avg_agents_density": 0.1702814038983265, "runtime": 2.441994419961702}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1472, "makespan": 59, "avg_agents_density": 0.17342213927601488, "runtime": 1.9854189869947731}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 2583, "makespan": 126, "avg_agents_density": 0.13373643097688914, "runtime": 5.139676208986202}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.5208333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3703, "makespan": 128, "avg_agents_density": 0.3046104295645975, "runtime": 5.5406709350208985}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1441, "makespan": 53, "avg_agents_density": 0.16042385584172184, "runtime": 2.43144768102502}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1397, "makespan": 55, "avg_agents_density": 0.15314420958047784, "runtime": 2.1745701810577884}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1254, "makespan": 53, "avg_agents_density": 0.17521066871351415, "runtime": 1.871446892968379}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1638, "makespan": 55, "avg_agents_density": 0.16737589084177348, "runtime": 2.308103731047595}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1566, "makespan": 59, "avg_agents_density": 0.15750287636450938, "runtime": 1.921460325960652}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1200, "makespan": 57, "avg_agents_density": 0.12366264924707361, "runtime": 1.958479254055419}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2744, "makespan": 78, "avg_agents_density": 0.1838590324520585, "runtime": 2.96728929701203}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4519, "makespan": 128, "avg_agents_density": 0.19784747460202118, "runtime": 3.1438308599754237}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1534, "makespan": 56, "avg_agents_density": 0.14126229610972765, "runtime": 1.8074908489506925}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1588, "makespan": 52, "avg_agents_density": 0.15997541568205484, "runtime": 1.6402693560085027}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1152, "makespan": 47, "avg_agents_density": 0.14750690507364433, "runtime": 1.5305770409904653}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1508, "makespan": 51, "avg_agents_density": 0.16758541727466197, "runtime": 1.6684088239562698}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1809, "makespan": 79, "avg_agents_density": 0.1536673834021401, "runtime": 2.760978810081724}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 658, "makespan": 32, "avg_agents_density": 0.13316714807172014, "runtime": 1.0819031720166095}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1227, "makespan": 50, "avg_agents_density": 0.13202008335051552, "runtime": 2.1298691010306356}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 2076, "makespan": 94, "avg_agents_density": 0.13467906719395525, "runtime": 3.2439365140598966}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2689, "makespan": 88, "avg_agents_density": 0.15778703236972322, "runtime": 2.769235442916397}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2117, "makespan": 76, "avg_agents_density": 0.15509411956056743, "runtime": 2.711505993094761}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1708, "makespan": 61, "avg_agents_density": 0.18114369543986844, "runtime": 2.165171893982915}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 858, "makespan": 31, "avg_agents_density": 0.1468620813458861, "runtime": 1.2318513840436935}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 2546, "makespan": 120, "avg_agents_density": 0.18089681174769254, "runtime": 5.194364493072499}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 3552, "makespan": 78, "avg_agents_density": 0.22755323188736612, "runtime": 4.571495396987302}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3348, "makespan": 128, "avg_agents_density": 0.18984035617426287, "runtime": 5.456017332107876}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 2749, "makespan": 99, "avg_agents_density": 0.19419571854469275, "runtime": 5.363599128148053}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4611, "makespan": 128, "avg_agents_density": 0.22284774879287308, "runtime": 5.685565445921384}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.703125, "CSR": 0.0, "ep_length": 128, "SoC": 6504, "makespan": 128, "avg_agents_density": 0.23192745144228144, "runtime": 6.559645688001183}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2492, "makespan": 75, "avg_agents_density": 0.19242691262164313, "runtime": 3.25819334598782}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4803, "makespan": 128, "avg_agents_density": 0.22220822707500099, "runtime": 5.077064331941074}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2876, "makespan": 82, "avg_agents_density": 0.2108712562359436, "runtime": 3.3630488379712915}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2253, "makespan": 68, "avg_agents_density": 0.21535603823731717, "runtime": 2.6959995570214232}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5002, "makespan": 128, "avg_agents_density": 0.1909921428259797, "runtime": 5.2252728949679295}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 128, "SoC": 7021, "makespan": 128, "avg_agents_density": 0.40659090565599265, "runtime": 5.17335067584645}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2726, "makespan": 89, "avg_agents_density": 0.19882724029212803, "runtime": 3.412038966009277}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2117, "makespan": 67, "avg_agents_density": 0.19008075481817532, "runtime": 2.7823289039661177}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 2436, "makespan": 99, "avg_agents_density": 0.20874724560589994, "runtime": 5.127558892956586}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2787, "makespan": 81, "avg_agents_density": 0.20623662193609263, "runtime": 3.29506149001827}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.515625, "CSR": 0.0, "ep_length": 128, "SoC": 5746, "makespan": 128, "avg_agents_density": 0.2644121271033809, "runtime": 5.356510920071742}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1703, "makespan": 49, "avg_agents_density": 0.15426856078329151, "runtime": 1.8837888749985723}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5309, "makespan": 128, "avg_agents_density": 0.18747265458349513, "runtime": 5.6167570690013235}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 6933, "makespan": 128, "avg_agents_density": 0.2133129782118557, "runtime": 5.790388763038209}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 3303, "makespan": 89, "avg_agents_density": 0.18978772978909825, "runtime": 3.9187294931325596}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2692, "makespan": 73, "avg_agents_density": 0.2117424713125152, "runtime": 3.1587361070123734}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2003, "makespan": 58, "avg_agents_density": 0.18743747161872426, "runtime": 2.3503741549357073}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3393, "makespan": 128, "avg_agents_density": 0.1895899074495857, "runtime": 5.3285533350281185}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4150, "makespan": 128, "avg_agents_density": 0.19850779446273906, "runtime": 5.352798440959305}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 967, "makespan": 38, "avg_agents_density": 0.18044476046445468, "runtime": 1.6110407280357322}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1838, "makespan": 48, "avg_agents_density": 0.17851749088475258, "runtime": 1.9762075259786798}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3467, "makespan": 128, "avg_agents_density": 0.17479241918578672, "runtime": 5.215669790079119}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5108, "makespan": 128, "avg_agents_density": 0.20280383060074544, "runtime": 5.1550316529901465}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 3151, "makespan": 80, "avg_agents_density": 0.20644785811968025, "runtime": 3.038205426040804}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3737, "makespan": 128, "avg_agents_density": 0.21810847427231647, "runtime": 5.351495607974357}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1564, "makespan": 50, "avg_agents_density": 0.18550174618215112, "runtime": 2.8478795240080217}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-176000"}]