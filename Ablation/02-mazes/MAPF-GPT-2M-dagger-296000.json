[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 768, "makespan": 41, "avg_agents_density": 0.09620714505499225, "runtime": 0.8716047328925924}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 985, "makespan": 57, "avg_agents_density": 0.12123271573602544, "runtime": 0.9888173849903978}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 845, "makespan": 59, "avg_agents_density": 0.08953717927940898, "runtime": 1.8145618840353563}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 622, "makespan": 40, "avg_agents_density": 0.10545094506055275, "runtime": 1.5439150110032642}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 997, "makespan": 59, "avg_agents_density": 0.11513088583828113, "runtime": 2.390653117952752}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1082, "makespan": 79, "avg_agents_density": 0.1017401991321055, "runtime": 2.053720220006653}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 766, "makespan": 42, "avg_agents_density": 0.09917448454269691, "runtime": 1.8633776060451055}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 1380, "makespan": 114, "avg_agents_density": 0.10846648532519121, "runtime": 4.1507205449888716}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1023, "makespan": 46, "avg_agents_density": 0.10924016963062291, "runtime": 1.8337754410604248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 776, "makespan": 42, "avg_agents_density": 0.1293115662147016, "runtime": 1.057463693941827}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 762, "makespan": 41, "avg_agents_density": 0.08724261191539459, "runtime": 1.0511061090801377}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1070, "makespan": 51, "avg_agents_density": 0.14031319810727166, "runtime": 2.0882600559998536}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 715, "makespan": 35, "avg_agents_density": 0.11279906539286014, "runtime": 1.0951030459691538}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 685, "makespan": 39, "avg_agents_density": 0.10971751799765508, "runtime": 1.672636894058087}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 683, "makespan": 38, "avg_agents_density": 0.12508764410998227, "runtime": 0.5787231139838696}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 913, "makespan": 57, "avg_agents_density": 0.10926236876682296, "runtime": 0.9020825070183491}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 824, "makespan": 46, "avg_agents_density": 0.11422928988809614, "runtime": 1.496555321937194}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 648, "makespan": 43, "avg_agents_density": 0.08937321844861505, "runtime": 1.397646747995168}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 127, "SoC": 1389, "makespan": 127, "avg_agents_density": 0.11398715931159639, "runtime": 4.702818638048484}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 1402, "makespan": 93, "avg_agents_density": 0.10397653765477166, "runtime": 1.8147092339786468}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1102, "makespan": 78, "avg_agents_density": 0.09171165493668913, "runtime": 1.4996332220034674}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 862, "makespan": 43, "avg_agents_density": 0.11579970295655219, "runtime": 0.8164595840062248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 620, "makespan": 34, "avg_agents_density": 0.09349569965880533, "runtime": 0.5462628319655778}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 694, "makespan": 49, "avg_agents_density": 0.11049712619475668, "runtime": 2.0589040699996985}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 794, "makespan": 58, "avg_agents_density": 0.09736473170059069, "runtime": 1.7424464909709059}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 421, "makespan": 29, "avg_agents_density": 0.0945350481972253, "runtime": 0.7747540759883123}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 801, "makespan": 44, "avg_agents_density": 0.09537869792739423, "runtime": 1.1087574279808905}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 918, "makespan": 47, "avg_agents_density": 0.08787748006480989, "runtime": 1.2256954520271393}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1244, "makespan": 75, "avg_agents_density": 0.08540858587575105, "runtime": 1.460857114099781}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 881, "makespan": 52, "avg_agents_density": 0.11206533107213083, "runtime": 0.32722977601224557}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 667, "makespan": 34, "avg_agents_density": 0.11939997765620475, "runtime": 0.5314913600595901}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 553, "makespan": 37, "avg_agents_density": 0.1129343214576641, "runtime": 0.7122456209763186}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1669, "makespan": 64, "avg_agents_density": 0.13661759830637113, "runtime": 2.7469912630185718}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1896, "makespan": 70, "avg_agents_density": 0.15419010330393249, "runtime": 2.3105583030119305}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1511, "makespan": 72, "avg_agents_density": 0.13792993660508102, "runtime": 2.275876050029183}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1265, "makespan": 50, "avg_agents_density": 0.1573418949346811, "runtime": 1.5988408559787786}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1604, "makespan": 49, "avg_agents_density": 0.15008145673369747, "runtime": 1.8375996769609628}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2154, "makespan": 67, "avg_agents_density": 0.1668995436468721, "runtime": 2.2718776500114473}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1093, "makespan": 41, "avg_agents_density": 0.1428187779174061, "runtime": 1.3239116980985273}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3054, "makespan": 128, "avg_agents_density": 0.14900552161579633, "runtime": 5.531151567076449}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1630, "makespan": 56, "avg_agents_density": 0.17515991852452464, "runtime": 1.8011350250599207}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1249, "makespan": 43, "avg_agents_density": 0.17974725026781058, "runtime": 1.616599235945614}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1290, "makespan": 52, "avg_agents_density": 0.1276982775705058, "runtime": 1.7819455560238566}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4019, "makespan": 128, "avg_agents_density": 0.24858851909061602, "runtime": 5.166674261025037}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1382, "makespan": 59, "avg_agents_density": 0.1621108214300109, "runtime": 3.039067908975994}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1219, "makespan": 47, "avg_agents_density": 0.15496692755828043, "runtime": 2.17341642100655}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1754, "makespan": 73, "avg_agents_density": 0.17075865233715656, "runtime": 2.281583132906235}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1540, "makespan": 51, "avg_agents_density": 0.1589133155968814, "runtime": 2.535209942041547}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1623, "makespan": 58, "avg_agents_density": 0.1613860074046087, "runtime": 1.813185069084284}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1108, "makespan": 63, "avg_agents_density": 0.12012913416158322, "runtime": 2.0470837749599013}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3302, "makespan": 128, "avg_agents_density": 0.15394330081651728, "runtime": 4.330422278071637}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3250, "makespan": 128, "avg_agents_density": 0.16316567030806536, "runtime": 4.862838024026132}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1522, "makespan": 56, "avg_agents_density": 0.14153780443861694, "runtime": 2.069849503954174}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1792, "makespan": 54, "avg_agents_density": 0.1515126825767768, "runtime": 2.2024441109824693}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1059, "makespan": 44, "avg_agents_density": 0.14825973156344402, "runtime": 1.4235572189791128}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1628, "makespan": 57, "avg_agents_density": 0.16872220255748516, "runtime": 2.223316071977024}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1658, "makespan": 70, "avg_agents_density": 0.14869365016267988, "runtime": 2.214290131960297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 643, "makespan": 34, "avg_agents_density": 0.1324195831740935, "runtime": 1.1195620460202917}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1117, "makespan": 46, "avg_agents_density": 0.13229477493311612, "runtime": 2.0959661419765325}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1836, "makespan": 68, "avg_agents_density": 0.13460737797474506, "runtime": 2.6938571129285265}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 2441, "makespan": 109, "avg_agents_density": 0.14827592435861786, "runtime": 3.6178386140381917}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2380, "makespan": 128, "avg_agents_density": 0.14951746851751485, "runtime": 4.842951084981905}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1419, "makespan": 47, "avg_agents_density": 0.17789444302299717, "runtime": 1.5118674140539952}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 865, "makespan": 34, "avg_agents_density": 0.14510186777894465, "runtime": 1.2337362809921615}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2452, "makespan": 66, "avg_agents_density": 0.18285783500075362, "runtime": 3.185339242001646}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 3088, "makespan": 70, "avg_agents_density": 0.2186007858114268, "runtime": 3.7834785310114967}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 128, "SoC": 4921, "makespan": 128, "avg_agents_density": 0.2256070040696468, "runtime": 6.4053037460835185}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2326, "makespan": 61, "avg_agents_density": 0.201072581242864, "runtime": 3.783080089982832}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 4599, "makespan": 120, "avg_agents_density": 0.2436456614241849, "runtime": 5.715262023106334}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 5750, "makespan": 128, "avg_agents_density": 0.21686607861442733, "runtime": 5.997920225025155}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2368, "makespan": 74, "avg_agents_density": 0.18527236229144817, "runtime": 3.062752474070294}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 5707, "makespan": 128, "avg_agents_density": 0.24862818858357416, "runtime": 6.069222913036356}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 3455, "makespan": 123, "avg_agents_density": 0.20015118051674072, "runtime": 5.86772642096912}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2249, "makespan": 58, "avg_agents_density": 0.21533342279889625, "runtime": 2.348416698980145}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4333, "makespan": 128, "avg_agents_density": 0.18143719451328952, "runtime": 5.939128545927815}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 128, "SoC": 6645, "makespan": 128, "avg_agents_density": 0.35229027685121783, "runtime": 5.305996090071858}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3457, "makespan": 128, "avg_agents_density": 0.1994404901576962, "runtime": 6.136408403152018}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2018, "makespan": 58, "avg_agents_density": 0.18902155476360433, "runtime": 2.5321248358959565}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2933, "makespan": 128, "avg_agents_density": 0.21500598786052116, "runtime": 6.161754833970917}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 3493, "makespan": 91, "avg_agents_density": 0.21047847739688996, "runtime": 4.0151055439782795}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 6090, "makespan": 128, "avg_agents_density": 0.29552868013030453, "runtime": 6.1507910350192105}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1797, "makespan": 68, "avg_agents_density": 0.15116431220834786, "runtime": 3.3559960769634927}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5848, "makespan": 128, "avg_agents_density": 0.1939801371178404, "runtime": 5.550412223965395}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 128, "SoC": 5938, "makespan": 128, "avg_agents_density": 0.24410748910360414, "runtime": 6.0417460929602385}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 3740, "makespan": 119, "avg_agents_density": 0.18655119148625823, "runtime": 5.568663364989334}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3458, "makespan": 128, "avg_agents_density": 0.1996158655910912, "runtime": 5.764365075039677}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1653, "makespan": 51, "avg_agents_density": 0.18554873961814464, "runtime": 2.2349301930662477}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 3510, "makespan": 128, "avg_agents_density": 0.19336039649488593, "runtime": 6.270365658085211}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 3942, "makespan": 128, "avg_agents_density": 0.1949298340542402, "runtime": 5.996230954013299}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 890, "makespan": 30, "avg_agents_density": 0.18382368251233044, "runtime": 1.5836735600314569}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2008, "makespan": 58, "avg_agents_density": 0.17721566057612972, "runtime": 2.6202925919933477}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 3702, "makespan": 114, "avg_agents_density": 0.17197852927344817, "runtime": 5.319068249023985}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 5023, "makespan": 128, "avg_agents_density": 0.20513180671829734, "runtime": 6.349644472022192}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 3368, "makespan": 100, "avg_agents_density": 0.1985733722809918, "runtime": 4.682034141980694}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3323, "makespan": 128, "avg_agents_density": 0.2235178322851335, "runtime": 5.365619726086152}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1364, "makespan": 50, "avg_agents_density": 0.18509006727638094, "runtime": 2.876508645960712}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-296000"}]