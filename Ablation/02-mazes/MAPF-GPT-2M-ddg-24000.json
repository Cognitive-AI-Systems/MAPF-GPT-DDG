[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 802, "makespan": 39, "avg_agents_density": 0.09991710741218057, "runtime": 0.9619005261920393}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 903, "makespan": 48, "avg_agents_density": 0.12562863852053613, "runtime": 0.4195772130624391}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1229, "makespan": 128, "avg_agents_density": 0.08083915377726027, "runtime": 1.7131990023772232}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 695, "makespan": 36, "avg_agents_density": 0.10445556960602093, "runtime": 0.838878282927908}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 948, "makespan": 49, "avg_agents_density": 0.10874614083012729, "runtime": 1.084804683108814}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1210, "makespan": 69, "avg_agents_density": 0.10993999405026078, "runtime": 1.384915256232489}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 866, "makespan": 62, "avg_agents_density": 0.10089586193571887, "runtime": 1.2226034860359505}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1293, "makespan": 66, "avg_agents_density": 0.11847722771716479, "runtime": 1.3587855829973705}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1005, "makespan": 55, "avg_agents_density": 0.11201874828265442, "runtime": 1.2498063806560822}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 663, "makespan": 40, "avg_agents_density": 0.12681739061794176, "runtime": 0.6588001741911285}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1094, "makespan": 58, "avg_agents_density": 0.0949533759950657, "runtime": 0.7138556317659095}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1323, "makespan": 79, "avg_agents_density": 0.1454603573080032, "runtime": 1.3933595111011527}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 805, "makespan": 43, "avg_agents_density": 0.1067506970092579, "runtime": 0.9288211728562601}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 802, "makespan": 50, "avg_agents_density": 0.10865140556885741, "runtime": 1.2953048539347947}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1046, "makespan": 78, "avg_agents_density": 0.11031814828958396, "runtime": 1.3769131569424644}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1069, "makespan": 52, "avg_agents_density": 0.11355861548853873, "runtime": 0.7748911347007379}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1085, "makespan": 50, "avg_agents_density": 0.12695922027695103, "runtime": 0.8540007030242123}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 812, "makespan": 48, "avg_agents_density": 0.0893745460041468, "runtime": 0.9611644321121275}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1226, "makespan": 60, "avg_agents_density": 0.12269321349940433, "runtime": 1.4715075383428484}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1399, "makespan": 78, "avg_agents_density": 0.1130486010143819, "runtime": 0.5558801938896067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 926, "makespan": 52, "avg_agents_density": 0.09675220386050688, "runtime": 0.3595857803011313}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1214, "makespan": 70, "avg_agents_density": 0.10999516438934094, "runtime": 0.9034848866867833}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 727, "makespan": 49, "avg_agents_density": 0.09403620459626151, "runtime": 0.6599210858112201}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 869, "makespan": 46, "avg_agents_density": 0.11553025577703674, "runtime": 1.0383649239083752}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 877, "makespan": 45, "avg_agents_density": 0.10092657650684211, "runtime": 1.0042887369636446}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 437, "makespan": 30, "avg_agents_density": 0.09400498026317143, "runtime": 0.4643754739081487}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 789, "makespan": 43, "avg_agents_density": 0.09979787105550762, "runtime": 0.7589210800360888}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1451, "makespan": 82, "avg_agents_density": 0.09534792214008665, "runtime": 1.8217185666435398}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1316, "makespan": 67, "avg_agents_density": 0.09510355258843546, "runtime": 0.34625716391019523}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1172, "makespan": 62, "avg_agents_density": 0.10595124934502498, "runtime": 0.3687650290085003}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 700, "makespan": 41, "avg_agents_density": 0.11537028589193095, "runtime": 0.3764611539663747}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 631, "makespan": 39, "avg_agents_density": 0.11286943269680254, "runtime": 0.4429125791066326}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1321, "makespan": 48, "avg_agents_density": 0.14483212728897835, "runtime": 1.4591127642197534}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1755, "makespan": 66, "avg_agents_density": 0.152898586363665, "runtime": 1.6049115557107143}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1930, "makespan": 128, "avg_agents_density": 0.1358548906000927, "runtime": 3.0276878741569817}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1457, "makespan": 53, "avg_agents_density": 0.1582386228260525, "runtime": 1.2304094652063213}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2491, "makespan": 83, "avg_agents_density": 0.17249619907048028, "runtime": 2.180627249821555}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2769, "makespan": 102, "avg_agents_density": 0.15983924650525547, "runtime": 2.575439662032295}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1488, "makespan": 52, "avg_agents_density": 0.14902008233999878, "runtime": 1.2469183179200627}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4317, "makespan": 128, "avg_agents_density": 0.18566300338142738, "runtime": 3.4424581317580305}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2284, "makespan": 84, "avg_agents_density": 0.1784574676454241, "runtime": 2.0620102372486144}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1617, "makespan": 60, "avg_agents_density": 0.1809348277269541, "runtime": 1.5527982729836367}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 1966, "makespan": 97, "avg_agents_density": 0.1311492188604014, "runtime": 2.517214426654391}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 128, "SoC": 5040, "makespan": 128, "avg_agents_density": 0.3464745526741082, "runtime": 3.2107220754842274}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2139, "makespan": 63, "avg_agents_density": 0.16786865131962547, "runtime": 1.7896010632393882}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1403, "makespan": 53, "avg_agents_density": 0.14961154738513122, "runtime": 1.4823893460561521}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1408, "makespan": 54, "avg_agents_density": 0.16902444911053913, "runtime": 1.2797528840019368}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1962, "makespan": 63, "avg_agents_density": 0.172417657167484, "runtime": 1.8428565298090689}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2933, "makespan": 128, "avg_agents_density": 0.1553536209805235, "runtime": 3.1333199859946035}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1129, "makespan": 44, "avg_agents_density": 0.12196499635902666, "runtime": 1.0727238387917168}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3297, "makespan": 128, "avg_agents_density": 0.153453496626017, "runtime": 3.460648119216785}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 4466, "makespan": 128, "avg_agents_density": 0.20357173847620905, "runtime": 2.959802146127913}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2751, "makespan": 128, "avg_agents_density": 0.14794562597410943, "runtime": 2.472854924912099}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2311, "makespan": 82, "avg_agents_density": 0.16935320027713538, "runtime": 1.8379580839537084}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1202, "makespan": 55, "avg_agents_density": 0.13663692534508845, "runtime": 1.3540047463029623}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1696, "makespan": 55, "avg_agents_density": 0.18376187116275, "runtime": 1.3092368441284634}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 2213, "makespan": 115, "avg_agents_density": 0.15290253562295048, "runtime": 2.8171432075905614}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 701, "makespan": 34, "avg_agents_density": 0.13404944322273835, "runtime": 0.8140215728781186}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1192, "makespan": 47, "avg_agents_density": 0.13859528662571705, "runtime": 1.3875161508913152}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 2248, "makespan": 90, "avg_agents_density": 0.12802173187083643, "runtime": 2.1966740788775496}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3216, "makespan": 128, "avg_agents_density": 0.15339972363388854, "runtime": 3.112069378083106}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2990, "makespan": 128, "avg_agents_density": 0.1692067877019367, "runtime": 3.0481176740140654}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1851, "makespan": 92, "avg_agents_density": 0.17150480613320787, "runtime": 2.2463360920664854}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 983, "makespan": 36, "avg_agents_density": 0.15047141308401313, "runtime": 0.9114419310353696}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2766, "makespan": 73, "avg_agents_density": 0.1810760919571712, "runtime": 2.6048602672526613}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 5514, "makespan": 128, "avg_agents_density": 0.25896314178180846, "runtime": 4.468182856449857}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3488, "makespan": 128, "avg_agents_density": 0.19196065284348754, "runtime": 4.18508939089952}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2958, "makespan": 88, "avg_agents_density": 0.2059153619275005, "runtime": 3.139157445228193}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.515625, "CSR": 0.0, "ep_length": 128, "SoC": 5401, "makespan": 128, "avg_agents_density": 0.2922661748874074, "runtime": 4.529563009971753}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.453125, "CSR": 0.0, "ep_length": 128, "SoC": 6246, "makespan": 128, "avg_agents_density": 0.30326213655377326, "runtime": 4.365344057732727}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.703125, "CSR": 0.0, "ep_length": 128, "SoC": 4280, "makespan": 128, "avg_agents_density": 0.21017639431854754, "runtime": 4.114083664782811}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 6654, "makespan": 128, "avg_agents_density": 0.2542471166605977, "runtime": 4.082758904143702}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5531, "makespan": 128, "avg_agents_density": 0.23794560694685382, "runtime": 3.98751605610596}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 3232, "makespan": 93, "avg_agents_density": 0.21804773132197364, "runtime": 3.0097759679774754}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 3693, "makespan": 107, "avg_agents_density": 0.18136538084807013, "runtime": 3.469134788203519}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 128, "SoC": 7052, "makespan": 128, "avg_agents_density": 0.35060534462134185, "runtime": 4.146751855965704}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4253, "makespan": 128, "avg_agents_density": 0.21894207830088513, "runtime": 4.088898620568216}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2425, "makespan": 62, "avg_agents_density": 0.1916011472786882, "runtime": 2.0084315912099555}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5180, "makespan": 128, "avg_agents_density": 0.24819739208226407, "runtime": 4.16905931715155}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 6198, "makespan": 128, "avg_agents_density": 0.2841280546813077, "runtime": 3.8929163502180018}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 128, "SoC": 6937, "makespan": 128, "avg_agents_density": 0.24753527697971056, "runtime": 3.912750032322947}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1872, "makespan": 49, "avg_agents_density": 0.1510806994625419, "runtime": 1.5380781728890724}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5766, "makespan": 128, "avg_agents_density": 0.20615948733744702, "runtime": 3.5860169489169493}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.453125, "CSR": 0.0, "ep_length": 128, "SoC": 5935, "makespan": 128, "avg_agents_density": 0.26499986761137456, "runtime": 3.736474593402818}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4590, "makespan": 128, "avg_agents_density": 0.1886642743663474, "runtime": 3.7702530118403956}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4380, "makespan": 128, "avg_agents_density": 0.20295463244349288, "runtime": 3.687917690316681}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2154, "makespan": 65, "avg_agents_density": 0.18504959667605583, "runtime": 1.910480219812598}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3569, "makespan": 128, "avg_agents_density": 0.2001404725293468, "runtime": 3.9191208803677}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 4092, "makespan": 128, "avg_agents_density": 0.19189149789428508, "runtime": 3.807893115154002}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 936, "makespan": 31, "avg_agents_density": 0.1819549822146258, "runtime": 0.9958638100652024}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2114, "makespan": 60, "avg_agents_density": 0.17574460357229374, "runtime": 1.7942586137214676}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4454, "makespan": 128, "avg_agents_density": 0.17536413190116976, "runtime": 3.8141344660543837}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 5418, "makespan": 128, "avg_agents_density": 0.2407443184638055, "runtime": 3.893614450120367}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 128, "SoC": 6292, "makespan": 128, "avg_agents_density": 0.32976943977386736, "runtime": 3.971326347440481}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5042, "makespan": 128, "avg_agents_density": 0.23709377566201406, "runtime": 4.114046415837947}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2227, "makespan": 69, "avg_agents_density": 0.2032400319783257, "runtime": 2.5342628632788546}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-24000"}]