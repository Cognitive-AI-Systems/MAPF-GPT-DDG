[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 684, "makespan": 38, "avg_agents_density": 0.09997552137697309, "runtime": 0.7578176529787015}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 960, "makespan": 51, "avg_agents_density": 0.11655995993092572, "runtime": 1.0503787740017287}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 922, "makespan": 57, "avg_agents_density": 0.08610577474234087, "runtime": 1.0999725790898083}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 791, "makespan": 42, "avg_agents_density": 0.10627414685196734, "runtime": 0.8913682849524776}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 868, "makespan": 54, "avg_agents_density": 0.10487967745656909, "runtime": 1.113656098037609}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1011, "makespan": 53, "avg_agents_density": 0.11264403052864523, "runtime": 1.0600051139335847}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 775, "makespan": 41, "avg_agents_density": 0.10197177866405793, "runtime": 0.3600928619271144}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1474, "makespan": 91, "avg_agents_density": 0.10264301732272274, "runtime": 2.058288358952268}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1025, "makespan": 55, "avg_agents_density": 0.10814417307356927, "runtime": 0.6475388789403951}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 819, "makespan": 46, "avg_agents_density": 0.11773912177458225, "runtime": 0.5829771789722145}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 800, "makespan": 46, "avg_agents_density": 0.08899282646011526, "runtime": 1.0275917569815647}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1219, "makespan": 74, "avg_agents_density": 0.13808845776711112, "runtime": 1.5058881830336759}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 719, "makespan": 37, "avg_agents_density": 0.10806103832027299, "runtime": 0.811996399963391}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 778, "makespan": 50, "avg_agents_density": 0.109246710034469, "runtime": 1.0817770019784803}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 806, "makespan": 52, "avg_agents_density": 0.12270736057191747, "runtime": 0.987237109002308}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1042, "makespan": 50, "avg_agents_density": 0.11754223740436318, "runtime": 0.4495883849886013}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1012, "makespan": 56, "avg_agents_density": 0.113012315829461, "runtime": 0.37530383096600417}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 752, "makespan": 49, "avg_agents_density": 0.0912624873395456, "runtime": 0.9851871550199576}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1382, "makespan": 85, "avg_agents_density": 0.11932498729881993, "runtime": 1.7060492129530758}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1127, "makespan": 60, "avg_agents_density": 0.10492954035397754, "runtime": 0.6528191289835377}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 801, "makespan": 46, "avg_agents_density": 0.09681821215984968, "runtime": 0.9211901250091614}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1021, "makespan": 54, "avg_agents_density": 0.11198545681171604, "runtime": 0.36968233800143935}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 639, "makespan": 40, "avg_agents_density": 0.09516476667467583, "runtime": 0.45805827497679275}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 770, "makespan": 44, "avg_agents_density": 0.11555547168781681, "runtime": 0.9161827539501246}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 888, "makespan": 50, "avg_agents_density": 0.10328963411761762, "runtime": 1.0055526019859826}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 430, "makespan": 31, "avg_agents_density": 0.09098204272390335, "runtime": 0.16743084602057934}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 774, "makespan": 53, "avg_agents_density": 0.09528717421184353, "runtime": 0.9332601609785343}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 866, "makespan": 49, "avg_agents_density": 0.09169178968775217, "runtime": 0.7495914999308297}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1077, "makespan": 67, "avg_agents_density": 0.0941873742253431, "runtime": 0.5296598320419434}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 950, "makespan": 44, "avg_agents_density": 0.11500544081474338, "runtime": 0.8237928299931809}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 751, "makespan": 39, "avg_agents_density": 0.11182363953943959, "runtime": 0.20057037301012315}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 542, "makespan": 36, "avg_agents_density": 0.11131740936797611, "runtime": 0.3381366839748807}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1626, "makespan": 55, "avg_agents_density": 0.15092837692497227, "runtime": 1.64018251701782}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1735, "makespan": 59, "avg_agents_density": 0.1510699254889085, "runtime": 1.457600561043364}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1513, "makespan": 53, "avg_agents_density": 0.14549961593976676, "runtime": 1.5054779759666417}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1421, "makespan": 50, "avg_agents_density": 0.1579226549291034, "runtime": 1.3378013840410858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1864, "makespan": 74, "avg_agents_density": 0.15884507397044376, "runtime": 2.0173980488907546}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2169, "makespan": 67, "avg_agents_density": 0.1579292868876641, "runtime": 1.8443269340496045}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 2222, "makespan": 103, "avg_agents_density": 0.14687132843198747, "runtime": 2.318324094012496}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3276, "makespan": 128, "avg_agents_density": 0.15215481328743158, "runtime": 3.4056060189614072}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1747, "makespan": 50, "avg_agents_density": 0.1742051498105376, "runtime": 1.3407652689929819}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1694, "makespan": 61, "avg_agents_density": 0.1715335810697679, "runtime": 1.6261067930754507}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1400, "makespan": 48, "avg_agents_density": 0.13036269949197013, "runtime": 1.3996181649854407}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2635, "makespan": 80, "avg_agents_density": 0.21454253750110364, "runtime": 2.2342363020579796}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1616, "makespan": 54, "avg_agents_density": 0.16521543490349866, "runtime": 1.5392198589543113}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1424, "makespan": 52, "avg_agents_density": 0.14516636215156703, "runtime": 1.4786947130778572}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1597, "makespan": 52, "avg_agents_density": 0.174195533319873, "runtime": 1.330520133007667}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1871, "makespan": 60, "avg_agents_density": 0.17838934453913924, "runtime": 1.7109562230471056}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2067, "makespan": 78, "avg_agents_density": 0.16125591854400642, "runtime": 1.564329182889196}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1224, "makespan": 53, "avg_agents_density": 0.12360331913902906, "runtime": 1.3867932279244997}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2331, "makespan": 75, "avg_agents_density": 0.16487454071931093, "runtime": 1.9753517539793393}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 3297, "makespan": 107, "avg_agents_density": 0.1771468290238231, "runtime": 2.1235415089176968}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1943, "makespan": 85, "avg_agents_density": 0.1419911239947327, "runtime": 2.0869670300307916}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2426, "makespan": 73, "avg_agents_density": 0.16528666996791008, "runtime": 1.6112930750095984}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1260, "makespan": 51, "avg_agents_density": 0.14011791292292392, "runtime": 1.216890318042715}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1495, "makespan": 48, "avg_agents_density": 0.165071244133562, "runtime": 1.0057793030428002}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2307, "makespan": 81, "avg_agents_density": 0.14641184442291072, "runtime": 2.0080516680172877}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 695, "makespan": 33, "avg_agents_density": 0.13312146694039173, "runtime": 0.8845012770034373}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1213, "makespan": 43, "avg_agents_density": 0.13679792124204093, "runtime": 1.1615523710061098}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2274, "makespan": 73, "avg_agents_density": 0.1418410717045846, "runtime": 1.664421318055247}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2656, "makespan": 85, "avg_agents_density": 0.14063234409865574, "runtime": 1.8333597040327732}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2396, "makespan": 79, "avg_agents_density": 0.16224782624945527, "runtime": 2.1208043340448057}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1821, "makespan": 65, "avg_agents_density": 0.17855441577515352, "runtime": 1.6207523749762913}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 902, "makespan": 42, "avg_agents_density": 0.13860621765861242, "runtime": 0.8126575669739395}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 4182, "makespan": 106, "avg_agents_density": 0.19969125024359133, "runtime": 3.7593497439083876}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 3090, "makespan": 69, "avg_agents_density": 0.2042552222284847, "runtime": 2.5376655199943343}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2704, "makespan": 67, "avg_agents_density": 0.20315119402587156, "runtime": 2.4511959929950535}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2375, "makespan": 71, "avg_agents_density": 0.20462891221714188, "runtime": 2.668622628902085}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3657, "makespan": 99, "avg_agents_density": 0.20926647057797013, "runtime": 3.591059911006596}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 5514, "makespan": 128, "avg_agents_density": 0.22002961481313063, "runtime": 4.374224398954539}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 3871, "makespan": 126, "avg_agents_density": 0.191129673501782, "runtime": 4.0599474659975385}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 5000, "makespan": 128, "avg_agents_density": 0.20343442735564218, "runtime": 4.111809715948766}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3565, "makespan": 102, "avg_agents_density": 0.19858955671731932, "runtime": 3.2449651490169344}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3026, "makespan": 84, "avg_agents_density": 0.2154721073024569, "runtime": 2.7240390790539095}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2696, "makespan": 84, "avg_agents_density": 0.16983389677090382, "runtime": 2.7227657240146073}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 128, "SoC": 6469, "makespan": 128, "avg_agents_density": 0.32877239145280246, "runtime": 4.0891782199032605}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 3853, "makespan": 122, "avg_agents_density": 0.2048631254912078, "runtime": 3.8971228490408976}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2828, "makespan": 80, "avg_agents_density": 0.19381271275971315, "runtime": 2.5545102980395313}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 3181, "makespan": 79, "avg_agents_density": 0.21054335898935875, "runtime": 2.828707814041991}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 3280, "makespan": 74, "avg_agents_density": 0.21830087226384393, "runtime": 2.3466109199944185}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 6550, "makespan": 128, "avg_agents_density": 0.2500814262987872, "runtime": 4.062913708970882}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1863, "makespan": 62, "avg_agents_density": 0.15116505653750384, "runtime": 1.9707757900177967}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 5825, "makespan": 128, "avg_agents_density": 0.22214297591058133, "runtime": 3.6376727899041725}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.609375, "CSR": 0.0, "ep_length": 128, "SoC": 7044, "makespan": 128, "avg_agents_density": 0.22160051630034805, "runtime": 3.6139828690938884}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2601, "makespan": 67, "avg_agents_density": 0.19618871944265565, "runtime": 2.1033981649088673}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 3334, "makespan": 80, "avg_agents_density": 0.21413417273700514, "runtime": 2.3754551709716907}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1754, "makespan": 52, "avg_agents_density": 0.1866171645263841, "runtime": 1.556256443975144}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 4049, "makespan": 99, "avg_agents_density": 0.2029801723164314, "runtime": 3.1498209989076713}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 3862, "makespan": 128, "avg_agents_density": 0.19190764433535973, "runtime": 3.768818026059307}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1029, "makespan": 38, "avg_agents_density": 0.17781310386603433, "runtime": 1.203936054953374}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2151, "makespan": 67, "avg_agents_density": 0.1768405749715407, "runtime": 2.0479410320840543}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3567, "makespan": 102, "avg_agents_density": 0.17323352894926417, "runtime": 3.2319924689654727}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 6800, "makespan": 128, "avg_agents_density": 0.24025809211031707, "runtime": 4.049509741947986}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 3716, "makespan": 95, "avg_agents_density": 0.20687536935563258, "runtime": 3.022555645002285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2880, "makespan": 84, "avg_agents_density": 0.23217045321682134, "runtime": 2.6843095569784055}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1617, "makespan": 53, "avg_agents_density": 0.19002412727701276, "runtime": 1.9323134839942213}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-48000"}]