[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 714, "makespan": 48, "avg_agents_density": 0.09443754638091988, "runtime": 1.4958225090667838}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 793, "makespan": 37, "avg_agents_density": 0.12052282234218788, "runtime": 1.1269012859556824}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 837, "makespan": 57, "avg_agents_density": 0.08470382075548552, "runtime": 0.9116019650973612}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 720, "makespan": 41, "avg_agents_density": 0.10499433758420511, "runtime": 1.4290209279861301}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 881, "makespan": 57, "avg_agents_density": 0.10519831281260485, "runtime": 1.7724228130246047}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1196, "makespan": 65, "avg_agents_density": 0.09755109619156896, "runtime": 2.2445493310515303}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 675, "makespan": 37, "avg_agents_density": 0.09987260347126471, "runtime": 0.6169227569771465}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1171, "makespan": 58, "avg_agents_density": 0.10484741403177505, "runtime": 2.131419000972528}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 958, "makespan": 45, "avg_agents_density": 0.11364818846259385, "runtime": 1.2650912540993886}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 754, "makespan": 44, "avg_agents_density": 0.11854800489447147, "runtime": 1.3358121549681528}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 848, "makespan": 53, "avg_agents_density": 0.09153247013302802, "runtime": 1.6897981099173194}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1414, "makespan": 75, "avg_agents_density": 0.14821920328414737, "runtime": 2.2819120030180784}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 692, "makespan": 38, "avg_agents_density": 0.10586880271002548, "runtime": 1.3369306250096997}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 640, "makespan": 49, "avg_agents_density": 0.10839064316626593, "runtime": 1.7113261190388585}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 803, "makespan": 41, "avg_agents_density": 0.12124790464593745, "runtime": 1.2611922409851104}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 979, "makespan": 53, "avg_agents_density": 0.10679789387608464, "runtime": 0.9027706800261512}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 851, "makespan": 76, "avg_agents_density": 0.10271733634906799, "runtime": 1.186415830918122}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 786, "makespan": 50, "avg_agents_density": 0.09088321550435317, "runtime": 1.4887623110116692}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1216, "makespan": 57, "avg_agents_density": 0.11421826235478445, "runtime": 1.7928210660029436}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1069, "makespan": 51, "avg_agents_density": 0.1104521751003808, "runtime": 0.7847093359741848}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 883, "makespan": 53, "avg_agents_density": 0.08706056156536396, "runtime": 1.5539885540201794}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 821, "makespan": 45, "avg_agents_density": 0.11248487447156569, "runtime": 0.6726803930214373}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 609, "makespan": 36, "avg_agents_density": 0.0927702456638433, "runtime": 1.1836400130414404}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 693, "makespan": 46, "avg_agents_density": 0.10852706155789575, "runtime": 1.7615750330442097}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 943, "makespan": 50, "avg_agents_density": 0.09619654094319563, "runtime": 1.7281484600243857}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 429, "makespan": 29, "avg_agents_density": 0.09393701702238628, "runtime": 0.3636243080254644}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 636, "makespan": 35, "avg_agents_density": 0.0939659366021973, "runtime": 0.6481009219714906}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 827, "makespan": 46, "avg_agents_density": 0.09076135678853775, "runtime": 1.4906371379911434}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1150, "makespan": 63, "avg_agents_density": 0.09387322805172435, "runtime": 0.8041955499793403}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 835, "makespan": 44, "avg_agents_density": 0.10943531854201635, "runtime": 0.7792015890736366}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 695, "makespan": 40, "avg_agents_density": 0.11731469070221871, "runtime": 0.6746013470547041}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 547, "makespan": 27, "avg_agents_density": 0.1152324940742285, "runtime": 0.6368265189667}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1610, "makespan": 50, "avg_agents_density": 0.14681292450192837, "runtime": 1.9316619990131585}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1772, "makespan": 65, "avg_agents_density": 0.1655052925607419, "runtime": 2.644265284019639}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1290, "makespan": 48, "avg_agents_density": 0.14818922479609953, "runtime": 1.7771383769722888}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1289, "makespan": 43, "avg_agents_density": 0.1656586431185529, "runtime": 1.5819422060449142}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1429, "makespan": 61, "avg_agents_density": 0.1435166593931225, "runtime": 1.9505906269914703}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2067, "makespan": 81, "avg_agents_density": 0.1565141670884185, "runtime": 2.6948230340058217}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1213, "makespan": 46, "avg_agents_density": 0.14554722579988894, "runtime": 1.7175339460081887}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 127, "SoC": 2891, "makespan": 127, "avg_agents_density": 0.14936341197461867, "runtime": 4.46832549397368}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1471, "makespan": 53, "avg_agents_density": 0.16683779548800534, "runtime": 1.7950156730221352}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1346, "makespan": 62, "avg_agents_density": 0.17474849241623838, "runtime": 2.1249279220210155}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1427, "makespan": 71, "avg_agents_density": 0.1283745332642797, "runtime": 2.406518228017376}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 0.4791666666666667, "CSR": 0.0, "ep_length": 128, "SoC": 4677, "makespan": 128, "avg_agents_density": 0.3124255889425375, "runtime": 4.466787113036844}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1399, "makespan": 48, "avg_agents_density": 0.17184166705432422, "runtime": 1.941618943004869}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1288, "makespan": 48, "avg_agents_density": 0.15022136537745637, "runtime": 1.8803535969636869}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1331, "makespan": 50, "avg_agents_density": 0.1802333258963291, "runtime": 1.7538338489684975}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1558, "makespan": 48, "avg_agents_density": 0.15522616801813852, "runtime": 1.8291753419471206}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 3666, "makespan": 108, "avg_agents_density": 0.21069514312471008, "runtime": 3.618502814002568}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1240, "makespan": 51, "avg_agents_density": 0.1254756413620435, "runtime": 1.9752491869585356}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2098, "makespan": 76, "avg_agents_density": 0.1600383447605682, "runtime": 2.4410629171470646}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 3094, "makespan": 91, "avg_agents_density": 0.18095693652234374, "runtime": 2.902921202025027}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1651, "makespan": 62, "avg_agents_density": 0.1444733533444577, "runtime": 2.1731237259227782}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1852, "makespan": 62, "avg_agents_density": 0.16375826408621763, "runtime": 1.9795167261327151}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1144, "makespan": 42, "avg_agents_density": 0.15603580831077954, "runtime": 1.645300547053921}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1660, "makespan": 50, "avg_agents_density": 0.17043590928724192, "runtime": 1.713306790945353}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 2270, "makespan": 99, "avg_agents_density": 0.14995787015202805, "runtime": 3.8606130810221657}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 650, "makespan": 29, "avg_agents_density": 0.1370358547053649, "runtime": 1.1207058019499527}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1242, "makespan": 48, "avg_agents_density": 0.13167440797249497, "runtime": 1.8484477479360066}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1596, "makespan": 55, "avg_agents_density": 0.1326826749453009, "runtime": 2.1041132470272714}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2124, "makespan": 69, "avg_agents_density": 0.13862408550343583, "runtime": 2.4203246870456496}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1685, "makespan": 52, "avg_agents_density": 0.16179030603257644, "runtime": 2.0577416590385837}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1283, "makespan": 45, "avg_agents_density": 0.18091379185622822, "runtime": 1.5114083860680694}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 868, "makespan": 34, "avg_agents_density": 0.14807914679300968, "runtime": 1.150018844025908}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2466, "makespan": 61, "avg_agents_density": 0.1822877124759255, "runtime": 4.376771427952917}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 3007, "makespan": 75, "avg_agents_density": 0.2053530219350916, "runtime": 4.47605204602587}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 2913, "makespan": 93, "avg_agents_density": 0.19736464444547705, "runtime": 5.791512971991324}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2168, "makespan": 58, "avg_agents_density": 0.20271572672547628, "runtime": 3.0888670909480425}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2838, "makespan": 83, "avg_agents_density": 0.20520757762395758, "runtime": 4.444267968836357}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 4285, "makespan": 113, "avg_agents_density": 0.20422748563416035, "runtime": 6.194599915921572}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 2902, "makespan": 100, "avg_agents_density": 0.18636012725402734, "runtime": 4.345390637943638}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 5252, "makespan": 128, "avg_agents_density": 0.2421559233613798, "runtime": 5.641872433028766}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2506, "makespan": 62, "avg_agents_density": 0.19772501125770733, "runtime": 2.5480072609934723}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 2995, "makespan": 109, "avg_agents_density": 0.2148033457116223, "runtime": 4.756799681010307}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 2128, "makespan": 54, "avg_agents_density": 0.16634365023897793, "runtime": 2.3869068439526018}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 128, "SoC": 6476, "makespan": 128, "avg_agents_density": 0.33971275063380335, "runtime": 6.220828663033899}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2575, "makespan": 81, "avg_agents_density": 0.20330009755123646, "runtime": 3.573965703137219}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1868, "makespan": 41, "avg_agents_density": 0.18558552915831814, "runtime": 1.7646325380483177}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2601, "makespan": 62, "avg_agents_density": 0.21657373319975587, "runtime": 4.516950953111518}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2268, "makespan": 60, "avg_agents_density": 0.1950239138039542, "runtime": 2.3377590219315607}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5840, "makespan": 128, "avg_agents_density": 0.25375406275132534, "runtime": 5.180102786995121}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1932, "makespan": 59, "avg_agents_density": 0.15039020017707455, "runtime": 2.3504867120063864}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4841, "makespan": 128, "avg_agents_density": 0.1826499621871953, "runtime": 4.8183087440847885}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 5322, "makespan": 110, "avg_agents_density": 0.2077399399185044, "runtime": 4.105431694973959}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 3117, "makespan": 119, "avg_agents_density": 0.1823255092387096, "runtime": 4.583599249963299}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2732, "makespan": 66, "avg_agents_density": 0.20489844414815248, "runtime": 2.551110160013195}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1645, "makespan": 49, "avg_agents_density": 0.18562409731444732, "runtime": 1.9466706330276793}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 3056, "makespan": 128, "avg_agents_density": 0.18711815654972136, "runtime": 5.245020812973962}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 127, "SoC": 3218, "makespan": 127, "avg_agents_density": 0.19341089228232483, "runtime": 4.903648371968302}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 936, "makespan": 30, "avg_agents_density": 0.18330522932360407, "runtime": 1.3195789790188428}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1902, "makespan": 48, "avg_agents_density": 0.18460308443416384, "runtime": 1.816164899020805}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3004, "makespan": 94, "avg_agents_density": 0.1747910480437098, "runtime": 4.1445549050258705}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4435, "makespan": 128, "avg_agents_density": 0.18582911358206303, "runtime": 5.006741884048097}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 3240, "makespan": 77, "avg_agents_density": 0.21800116468517225, "runtime": 3.346431953992578}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 3057, "makespan": 69, "avg_agents_density": 0.22999051295108405, "runtime": 2.846500350991846}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1972, "makespan": 71, "avg_agents_density": 0.19907313835605012, "runtime": 4.824577223000233}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-368000"}]