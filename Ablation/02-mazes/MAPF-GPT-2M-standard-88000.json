[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 805, "makespan": 113, "avg_agents_density": 0.09643241497417476, "runtime": 2.1319548031897284}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 871, "makespan": 49, "avg_agents_density": 0.12602039126012618, "runtime": 0.491593409125926}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 945, "makespan": 64, "avg_agents_density": 0.0843037315594612, "runtime": 0.6037918017245829}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 630, "makespan": 42, "avg_agents_density": 0.11139639939799122, "runtime": 0.8866050170036033}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 911, "makespan": 54, "avg_agents_density": 0.11101233594455992, "runtime": 1.123463820113102}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1122, "makespan": 71, "avg_agents_density": 0.11266243947294126, "runtime": 1.429491564806085}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 799, "makespan": 56, "avg_agents_density": 0.09997586988202839, "runtime": 1.1429603158903774}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 1445, "makespan": 99, "avg_agents_density": 0.10479248447565082, "runtime": 2.1696318399335723}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 927, "makespan": 68, "avg_agents_density": 0.10719068227811418, "runtime": 1.4644602260086685}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 662, "makespan": 38, "avg_agents_density": 0.1366715769864787, "runtime": 0.46065688505768776}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 818, "makespan": 42, "avg_agents_density": 0.0910437370406968, "runtime": 0.7618735260330141}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 1494, "makespan": 115, "avg_agents_density": 0.1388220490968852, "runtime": 2.0237952771421988}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 985, "makespan": 113, "avg_agents_density": 0.10053299756749462, "runtime": 2.4286665270046797}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 595, "makespan": 33, "avg_agents_density": 0.10929397784054022, "runtime": 0.7112241000286303}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 912, "makespan": 74, "avg_agents_density": 0.11688801456470621, "runtime": 1.297439485002542}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 850, "makespan": 43, "avg_agents_density": 0.11282163828237536, "runtime": 0.405447691999143}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 874, "makespan": 63, "avg_agents_density": 0.10951654330842663, "runtime": 1.2338999040075578}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 801, "makespan": 51, "avg_agents_density": 0.0925370514597971, "runtime": 1.0158200329751708}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 1715, "makespan": 98, "avg_agents_density": 0.12921551653894664, "runtime": 1.9920044948812574}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1689, "makespan": 128, "avg_agents_density": 0.11386653557663387, "runtime": 0.8627393170027062}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 965, "makespan": 128, "avg_agents_density": 0.0880249967930182, "runtime": 1.0022370429360308}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1043, "makespan": 58, "avg_agents_density": 0.10795712678283656, "runtime": 0.4807195770845283}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 649, "makespan": 43, "avg_agents_density": 0.0947377543606429, "runtime": 0.41659141503623687}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 792, "makespan": 49, "avg_agents_density": 0.11329791737946411, "runtime": 1.0680911160889082}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 935, "makespan": 128, "avg_agents_density": 0.10005262054122831, "runtime": 2.7299904748797417}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 433, "makespan": 28, "avg_agents_density": 0.09697419636482857, "runtime": 0.4505085229757242}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 719, "makespan": 42, "avg_agents_density": 0.09572619885191959, "runtime": 0.789005922008073}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 822, "makespan": 47, "avg_agents_density": 0.08263788111264685, "runtime": 0.8943666980194394}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 1229, "makespan": 97, "avg_agents_density": 0.09555670611455815, "runtime": 0.320361770078307}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 852, "makespan": 47, "avg_agents_density": 0.10558479742666131, "runtime": 0.24842355895088986}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 625, "makespan": 32, "avg_agents_density": 0.11494420474675224, "runtime": 0.24169685709057376}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 565, "makespan": 35, "avg_agents_density": 0.10778078602033242, "runtime": 0.3350241020671092}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1545, "makespan": 55, "avg_agents_density": 0.1444506166611401, "runtime": 1.6523607029521372}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2131, "makespan": 128, "avg_agents_density": 0.15456529734230004, "runtime": 3.059526718192501}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1523, "makespan": 74, "avg_agents_density": 0.13546817344095585, "runtime": 1.773962436040165}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1730, "makespan": 71, "avg_agents_density": 0.16862709398514034, "runtime": 1.6524222518492024}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1831, "makespan": 87, "avg_agents_density": 0.1490117026233032, "runtime": 2.319428888062248}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 2673, "makespan": 104, "avg_agents_density": 0.1580016494545841, "runtime": 2.648024280060781}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1155, "makespan": 44, "avg_agents_density": 0.14290452470581705, "runtime": 1.0526464910071809}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.7916666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3251, "makespan": 128, "avg_agents_density": 0.1527556400159331, "runtime": 3.3575842678546906}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1570, "makespan": 54, "avg_agents_density": 0.183249449990053, "runtime": 1.3738909759558737}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1211, "makespan": 41, "avg_agents_density": 0.18317818113291123, "runtime": 1.0386070129752625}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1354, "makespan": 60, "avg_agents_density": 0.1244564583871439, "runtime": 1.5283646929601673}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2719, "makespan": 128, "avg_agents_density": 0.21251056684174385, "runtime": 3.2301561060303356}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1513, "makespan": 65, "avg_agents_density": 0.16129862307419982, "runtime": 1.8911387968691997}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1401, "makespan": 54, "avg_agents_density": 0.15296026342604288, "runtime": 1.5290083278960083}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1650, "makespan": 56, "avg_agents_density": 0.18143056796466475, "runtime": 1.350444643816445}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1601, "makespan": 62, "avg_agents_density": 0.16328089314376223, "runtime": 1.8417368561204057}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2049, "makespan": 70, "avg_agents_density": 0.17597809339789347, "runtime": 1.6158836700196844}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1191, "makespan": 47, "avg_agents_density": 0.12546418010905339, "runtime": 1.1447206939919852}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2939, "makespan": 128, "avg_agents_density": 0.15348370758813312, "runtime": 3.4338596437883098}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 128, "SoC": 4657, "makespan": 128, "avg_agents_density": 0.26397197858728744, "runtime": 2.5164499459206127}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2775, "makespan": 128, "avg_agents_density": 0.14710073297455492, "runtime": 2.5981735450041015}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2296, "makespan": 74, "avg_agents_density": 0.17293044814696432, "runtime": 1.525620360916946}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1137, "makespan": 42, "avg_agents_density": 0.15371330957908907, "runtime": 1.0041265561012551}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1547, "makespan": 60, "avg_agents_density": 0.1669316151414068, "runtime": 1.2619867918256205}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2798, "makespan": 128, "avg_agents_density": 0.1592410517971115, "runtime": 2.9456989381287713}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 650, "makespan": 29, "avg_agents_density": 0.13707638328198019, "runtime": 0.6882008030370343}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1400, "makespan": 80, "avg_agents_density": 0.12962179637571325, "runtime": 2.3818600719678216}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1899, "makespan": 128, "avg_agents_density": 0.1348992714516463, "runtime": 2.956491703982465}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 2858, "makespan": 122, "avg_agents_density": 0.1460715090690576, "runtime": 2.686990158079425}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 3486, "makespan": 128, "avg_agents_density": 0.19333659437395714, "runtime": 2.8971850341476966}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1902, "makespan": 83, "avg_agents_density": 0.1748937644790848, "runtime": 1.8471756959042978}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 836, "makespan": 32, "avg_agents_density": 0.14699378102283853, "runtime": 0.7337068850465585}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 4383, "makespan": 128, "avg_agents_density": 0.2230569805563769, "runtime": 4.129457460308913}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 128, "SoC": 6076, "makespan": 128, "avg_agents_density": 0.2931877276461901, "runtime": 4.3518318309797905}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 2969, "makespan": 128, "avg_agents_density": 0.1919364702150036, "runtime": 4.27739053289406}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 4790, "makespan": 128, "avg_agents_density": 0.24227244411030324, "runtime": 4.33359593199566}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 125, "SoC": 2954, "makespan": 125, "avg_agents_density": 0.18953861952356646, "runtime": 4.264072278019739}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4873, "makespan": 128, "avg_agents_density": 0.20933361588380975, "runtime": 4.259650605090428}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 3915, "makespan": 128, "avg_agents_density": 0.19640483379674722, "runtime": 4.007704873860348}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.390625, "CSR": 0.0, "ep_length": 128, "SoC": 6349, "makespan": 128, "avg_agents_density": 0.30060716104048707, "runtime": 3.9892896741221193}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 6131, "makespan": 128, "avg_agents_density": 0.2750458265262206, "runtime": 3.887805825826945}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 3193, "makespan": 115, "avg_agents_density": 0.22810331967058645, "runtime": 3.6080443848040886}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 3675, "makespan": 128, "avg_agents_density": 0.1894671344150887, "runtime": 3.9915812197723426}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.328125, "CSR": 0.0, "ep_length": 128, "SoC": 7023, "makespan": 128, "avg_agents_density": 0.3662499409940428, "runtime": 4.010359771869844}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3735, "makespan": 128, "avg_agents_density": 0.20311458720147824, "runtime": 4.01094066517544}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2140, "makespan": 56, "avg_agents_density": 0.1965532674513394, "runtime": 1.7507793131517246}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3609, "makespan": 128, "avg_agents_density": 0.22325659787094754, "runtime": 4.056491339899367}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5466, "makespan": 128, "avg_agents_density": 0.218600295481861, "runtime": 3.825828184199054}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4609, "makespan": 128, "avg_agents_density": 0.20920541060607434, "runtime": 3.838120719883591}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1804, "makespan": 56, "avg_agents_density": 0.1536042493644601, "runtime": 1.7561570400430355}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 6268, "makespan": 128, "avg_agents_density": 0.19526440282007212, "runtime": 3.659714223991614}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 128, "SoC": 6147, "makespan": 128, "avg_agents_density": 0.2671650260232435, "runtime": 3.6473095690016635}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 4326, "makespan": 128, "avg_agents_density": 0.19613380614479586, "runtime": 3.663082315964857}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 4168, "makespan": 118, "avg_agents_density": 0.22149271041025734, "runtime": 3.4103831139800604}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1838, "makespan": 59, "avg_agents_density": 0.19344495618844512, "runtime": 1.765595526987454}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4735, "makespan": 128, "avg_agents_density": 0.20483026654511124, "runtime": 3.87784239006578}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 4122, "makespan": 128, "avg_agents_density": 0.1955857105602706, "runtime": 3.7817407226830255}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 907, "makespan": 29, "avg_agents_density": 0.18214139467382845, "runtime": 0.9080916310485918}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2201, "makespan": 67, "avg_agents_density": 0.1739278022140912, "runtime": 1.9743504670332186}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 4853, "makespan": 128, "avg_agents_density": 0.1904287236688075, "runtime": 3.8276589709566906}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 5115, "makespan": 128, "avg_agents_density": 0.2078128853602793, "runtime": 3.8333577700541355}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4717, "makespan": 128, "avg_agents_density": 0.22070250339281083, "runtime": 3.816136246023234}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 2934, "makespan": 105, "avg_agents_density": 0.22342030709239, "runtime": 3.2901785660360474}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-88000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2423, "makespan": 75, "avg_agents_density": 0.1982613493515907, "runtime": 2.666896201844793}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-88000"}]