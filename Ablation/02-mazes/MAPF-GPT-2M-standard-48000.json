[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 703, "makespan": 32, "avg_agents_density": 0.1020029064324939, "runtime": 0.5212430590181611}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1169, "makespan": 62, "avg_agents_density": 0.1272072619079546, "runtime": 0.8953702519647777}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 1134, "makespan": 128, "avg_agents_density": 0.08366229540601522, "runtime": 1.2625095221155789}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 756, "makespan": 53, "avg_agents_density": 0.10605263160404696, "runtime": 1.044544038042659}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 1066, "makespan": 116, "avg_agents_density": 0.09866749020237181, "runtime": 2.3049606429121923}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1869, "makespan": 128, "avg_agents_density": 0.10509127523046079, "runtime": 2.530372620880371}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 857, "makespan": 72, "avg_agents_density": 0.09672311485359793, "runtime": 1.3964789709425531}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 124, "SoC": 1436, "makespan": 124, "avg_agents_density": 0.1020670355659395, "runtime": 2.5257911809603684}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 1406, "makespan": 117, "avg_agents_density": 0.11294212506311621, "runtime": 2.4326061320025474}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 787, "makespan": 40, "avg_agents_density": 0.1354901924036095, "runtime": 0.7960646630672272}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 823, "makespan": 42, "avg_agents_density": 0.08420977402961224, "runtime": 0.7658851809392218}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1823, "makespan": 128, "avg_agents_density": 0.13711113777169892, "runtime": 2.1341709761181846}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 745, "makespan": 57, "avg_agents_density": 0.10467913080021031, "runtime": 1.145388903823914}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 682, "makespan": 43, "avg_agents_density": 0.10738200117236026, "runtime": 0.9493189639761113}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 920, "makespan": 128, "avg_agents_density": 0.10935028714674236, "runtime": 2.057180261122994}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1101, "makespan": 64, "avg_agents_density": 0.11214022221371278, "runtime": 1.2584415472229011}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 953, "makespan": 128, "avg_agents_density": 0.10412949845535178, "runtime": 2.015336192853283}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 704, "makespan": 41, "avg_agents_density": 0.09124778654844172, "runtime": 0.7808416501211468}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 2401, "makespan": 128, "avg_agents_density": 0.13256116223048164, "runtime": 2.273690392175922}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 2386, "makespan": 128, "avg_agents_density": 0.13515232913456127, "runtime": 0.5857237560267095}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1094, "makespan": 66, "avg_agents_density": 0.09829813100931607, "runtime": 0.7207152589398902}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 895, "makespan": 48, "avg_agents_density": 0.11735640182847272, "runtime": 0.8784645288833417}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 912, "makespan": 108, "avg_agents_density": 0.09137386528105289, "runtime": 1.0629769911174662}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 843, "makespan": 50, "avg_agents_density": 0.11106060227742719, "runtime": 0.9537033699452877}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 892, "makespan": 45, "avg_agents_density": 0.1053124381574157, "runtime": 0.8256327221461106}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 485, "makespan": 33, "avg_agents_density": 0.09274653784312904, "runtime": 0.3855446828820277}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 700, "makespan": 39, "avg_agents_density": 0.09618723167781873, "runtime": 0.702818844903959}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1291, "makespan": 128, "avg_agents_density": 0.08420908659219396, "runtime": 1.3334471348498482}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 1772, "makespan": 117, "avg_agents_density": 0.09456863934204804, "runtime": 0.3407947930099908}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1369, "makespan": 128, "avg_agents_density": 0.10330170690527195, "runtime": 0.928071954898769}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 952, "makespan": 55, "avg_agents_density": 0.11405078127154897, "runtime": 0.8787117260508239}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 549, "makespan": 29, "avg_agents_density": 0.11696695786727077, "runtime": 0.21768562303623185}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1742, "makespan": 92, "avg_agents_density": 0.14219779520319303, "runtime": 2.6303115171031095}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2450, "makespan": 102, "avg_agents_density": 0.1560523963961811, "runtime": 2.6027752390364185}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1897, "makespan": 128, "avg_agents_density": 0.1334536262390483, "runtime": 3.2639048370474484}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1456, "makespan": 128, "avg_agents_density": 0.15541748436097882, "runtime": 3.2628399759414606}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 2140, "makespan": 118, "avg_agents_density": 0.14867549627307766, "runtime": 3.007800704013789}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3831, "makespan": 128, "avg_agents_density": 0.15624368764564092, "runtime": 3.258677443896886}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1775, "makespan": 128, "avg_agents_density": 0.139469218336177, "runtime": 3.263096559094265}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 3747, "makespan": 128, "avg_agents_density": 0.170369441121983, "runtime": 3.3814863318693824}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2303, "makespan": 92, "avg_agents_density": 0.1688761753029924, "runtime": 2.4023554411833175}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2250, "makespan": 78, "avg_agents_density": 0.19755921730031337, "runtime": 2.058918686991092}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1785, "makespan": 128, "avg_agents_density": 0.12242302108279317, "runtime": 3.2677950729848817}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 128, "SoC": 5195, "makespan": 128, "avg_agents_density": 0.2741911381303572, "runtime": 3.2581904229300562}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2352, "makespan": 128, "avg_agents_density": 0.1692438754163848, "runtime": 3.3455077481339686}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 1472, "makespan": 104, "avg_agents_density": 0.1530419350345098, "runtime": 2.7755440768960398}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2213, "makespan": 128, "avg_agents_density": 0.1652524329535063, "runtime": 3.2649398300854955}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3010, "makespan": 128, "avg_agents_density": 0.17044450999312763, "runtime": 3.2761894899012987}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2095, "makespan": 79, "avg_agents_density": 0.1546935290137971, "runtime": 2.0050543890101835}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1378, "makespan": 73, "avg_agents_density": 0.11697102639150576, "runtime": 1.8562190970696975}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4147, "makespan": 128, "avg_agents_density": 0.1626332133565825, "runtime": 3.2137774498551153}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 128, "SoC": 5061, "makespan": 128, "avg_agents_density": 0.17954412818251225, "runtime": 2.9805658599943854}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 2923, "makespan": 126, "avg_agents_density": 0.15293630285216242, "runtime": 2.4430919699952938}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2528, "makespan": 128, "avg_agents_density": 0.16500663832725382, "runtime": 2.5425599979644176}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 1453, "makespan": 88, "avg_agents_density": 0.1441677190699519, "runtime": 2.1149907278304454}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1947, "makespan": 77, "avg_agents_density": 0.17113335114991896, "runtime": 1.789037121081492}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 2261, "makespan": 123, "avg_agents_density": 0.1640936721461305, "runtime": 3.132720477966359}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 638, "makespan": 27, "avg_agents_density": 0.138424969565183, "runtime": 0.6837448220176157}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 1470, "makespan": 88, "avg_agents_density": 0.12697103002750476, "runtime": 2.2431628110061865}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 2786, "makespan": 110, "avg_agents_density": 0.13346952573388904, "runtime": 2.8050261588941794}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 3204, "makespan": 128, "avg_agents_density": 0.13483579778347202, "runtime": 3.2567697007907555}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3208, "makespan": 128, "avg_agents_density": 0.16930008131549784, "runtime": 3.00673840806121}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 2476, "makespan": 96, "avg_agents_density": 0.1808281806394948, "runtime": 2.3213499078992754}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1073, "makespan": 41, "avg_agents_density": 0.15334034261554969, "runtime": 1.0436185310245492}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3337, "makespan": 128, "avg_agents_density": 0.18871614300306047, "runtime": 4.160316916852025}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 5829, "makespan": 128, "avg_agents_density": 0.21962993647708506, "runtime": 4.339019307895796}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3347, "makespan": 128, "avg_agents_density": 0.1916064225795313, "runtime": 4.271998330834322}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 3037, "makespan": 93, "avg_agents_density": 0.19879258727139512, "runtime": 3.032513534097234}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 3596, "makespan": 103, "avg_agents_density": 0.19394318241324748, "runtime": 3.3294016019208357}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 6817, "makespan": 128, "avg_agents_density": 0.21370794646336044, "runtime": 4.232993016950786}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 4517, "makespan": 128, "avg_agents_density": 0.2111520747208096, "runtime": 4.000198441877728}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 6552, "makespan": 128, "avg_agents_density": 0.2477787887861152, "runtime": 4.005875814065803}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 5364, "makespan": 128, "avg_agents_density": 0.21100599192524092, "runtime": 4.020705453120172}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3758, "makespan": 128, "avg_agents_density": 0.22719866308518488, "runtime": 4.013192607060773}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 5308, "makespan": 128, "avg_agents_density": 0.20557714525506388, "runtime": 4.007045968231978}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 128, "SoC": 7437, "makespan": 128, "avg_agents_density": 0.3672699267218042, "runtime": 3.995357559120748}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 4115, "makespan": 123, "avg_agents_density": 0.21102799643738362, "runtime": 3.84749118910986}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4383, "makespan": 128, "avg_agents_density": 0.20371800098209636, "runtime": 4.012833001965191}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2796, "makespan": 91, "avg_agents_density": 0.22341424400654186, "runtime": 3.06971809497918}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4777, "makespan": 128, "avg_agents_density": 0.2183552127297036, "runtime": 4.016197148070205}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 6173, "makespan": 128, "avg_agents_density": 0.23239545584767235, "runtime": 4.0010411150578875}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 2289, "makespan": 128, "avg_agents_density": 0.1539427913699869, "runtime": 4.009650039079133}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 6790, "makespan": 128, "avg_agents_density": 0.2086485619975578, "runtime": 3.877437256916892}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.234375, "CSR": 0.0, "ep_length": 128, "SoC": 7286, "makespan": 128, "avg_agents_density": 0.2537426500858544, "runtime": 3.8963802719372325}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 5466, "makespan": 128, "avg_agents_density": 0.18765352214678618, "runtime": 3.690130745933857}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4710, "makespan": 128, "avg_agents_density": 0.21756099402488574, "runtime": 3.666053461172851}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2722, "makespan": 84, "avg_agents_density": 0.2033313665814502, "runtime": 2.5325798210396897}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4068, "makespan": 128, "avg_agents_density": 0.20126454363040192, "runtime": 4.015235230966937}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 4500, "makespan": 128, "avg_agents_density": 0.1976860019824887, "runtime": 3.952028922678437}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1000, "makespan": 40, "avg_agents_density": 0.17526776236763308, "runtime": 1.2518494030809961}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 2900, "makespan": 105, "avg_agents_density": 0.17727771796687133, "runtime": 3.2350164768868126}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4999, "makespan": 128, "avg_agents_density": 0.17359660506900187, "runtime": 4.017337296769256}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.703125, "CSR": 0.0, "ep_length": 128, "SoC": 5952, "makespan": 128, "avg_agents_density": 0.21954653151778614, "runtime": 4.016575233923504}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.453125, "CSR": 0.0, "ep_length": 128, "SoC": 5950, "makespan": 128, "avg_agents_density": 0.2984335240412178, "runtime": 4.004506841156399}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 6066, "makespan": 128, "avg_agents_density": 0.23422128347378673, "runtime": 4.01394139698823}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2199, "makespan": 65, "avg_agents_density": 0.20481948354229465, "runtime": 2.3329574850795325}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-48000"}]