[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 792, "makespan": 46, "avg_agents_density": 0.09611323884371872, "runtime": 0.8822913179901661}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 968, "makespan": 48, "avg_agents_density": 0.12475305010450367, "runtime": 0.9699990310618887}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 846, "makespan": 57, "avg_agents_density": 0.08658117153780355, "runtime": 0.5651811279094545}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 686, "makespan": 39, "avg_agents_density": 0.11221301759139761, "runtime": 0.8637489099928644}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 922, "makespan": 55, "avg_agents_density": 0.1112085224881872, "runtime": 1.0997148889728123}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1290, "makespan": 59, "avg_agents_density": 0.11371990975152096, "runtime": 1.2806567429070128}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 909, "makespan": 66, "avg_agents_density": 0.09748864285031941, "runtime": 1.5365235930366907}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1235, "makespan": 65, "avg_agents_density": 0.11410887954806205, "runtime": 1.4716277859697584}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1183, "makespan": 64, "avg_agents_density": 0.1154285544469316, "runtime": 1.4497161120525561}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 631, "makespan": 43, "avg_agents_density": 0.12387128320841652, "runtime": 0.7851438530051382}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 1147, "makespan": 103, "avg_agents_density": 0.08214458030382879, "runtime": 2.398606537943124}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 1913, "makespan": 121, "avg_agents_density": 0.13696897033030325, "runtime": 2.225342395933694}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 766, "makespan": 42, "avg_agents_density": 0.10667504909387604, "runtime": 1.071673532074783}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 742, "makespan": 39, "avg_agents_density": 0.1115888919875733, "runtime": 0.9301841279957443}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 779, "makespan": 53, "avg_agents_density": 0.11767516707989174, "runtime": 1.0240508649731055}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1069, "makespan": 47, "avg_agents_density": 0.11708515509612456, "runtime": 0.558676833024947}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 838, "makespan": 38, "avg_agents_density": 0.11019071558443297, "runtime": 0.7587666550243739}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 749, "makespan": 54, "avg_agents_density": 0.09235723973176993, "runtime": 0.9815029180172132}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1335, "makespan": 64, "avg_agents_density": 0.11873238410847192, "runtime": 1.4946344110212522}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1579, "makespan": 128, "avg_agents_density": 0.10699230419150288, "runtime": 0.6197595939302118}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 1138, "makespan": 128, "avg_agents_density": 0.0965454002186488, "runtime": 1.840905352117261}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 878, "makespan": 45, "avg_agents_density": 0.1141495935209571, "runtime": 0.3614062789856689}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 703, "makespan": 44, "avg_agents_density": 0.09541735978340178, "runtime": 0.5649847189924913}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 965, "makespan": 52, "avg_agents_density": 0.11789726666143223, "runtime": 1.2198773290438112}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 877, "makespan": 48, "avg_agents_density": 0.1019558363653245, "runtime": 0.9695188329933444}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 442, "makespan": 32, "avg_agents_density": 0.0921365174187867, "runtime": 0.6218455320049543}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 802, "makespan": 40, "avg_agents_density": 0.09906069906071778, "runtime": 0.4670563749532448}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 977, "makespan": 57, "avg_agents_density": 0.08748974620640819, "runtime": 1.258534820008208}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1484, "makespan": 87, "avg_agents_density": 0.09342182980595642, "runtime": 0.2699394250230398}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 935, "makespan": 49, "avg_agents_density": 0.10620956974016481, "runtime": 0.3629496380017372}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 805, "makespan": 49, "avg_agents_density": 0.11232364717646653, "runtime": 0.3180191479914356}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 528, "makespan": 31, "avg_agents_density": 0.11202494262492534, "runtime": 0.31086691601376515}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1654, "makespan": 128, "avg_agents_density": 0.14488834405730583, "runtime": 4.010554509033682}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1822, "makespan": 73, "avg_agents_density": 0.15186001817673003, "runtime": 1.9593045790097676}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1598, "makespan": 57, "avg_agents_density": 0.14207603055813023, "runtime": 1.45288839492423}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1454, "makespan": 48, "avg_agents_density": 0.16906128443612353, "runtime": 1.255880034979782}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1567, "makespan": 54, "avg_agents_density": 0.15526176321263116, "runtime": 1.395824003047892}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2363, "makespan": 128, "avg_agents_density": 0.15662924153645266, "runtime": 3.36856147198705}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1160, "makespan": 44, "avg_agents_density": 0.14063776835398123, "runtime": 1.1633135480224155}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.7708333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4204, "makespan": 128, "avg_agents_density": 0.15467187197795793, "runtime": 3.4119136738736415}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1886, "makespan": 61, "avg_agents_density": 0.1634223675532365, "runtime": 1.5533226720435778}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1783, "makespan": 79, "avg_agents_density": 0.17556659049443843, "runtime": 2.021942126972135}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1431, "makespan": 58, "avg_agents_density": 0.12860005783563278, "runtime": 1.5358723160024965}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 128, "SoC": 4902, "makespan": 128, "avg_agents_density": 0.33513423297380657, "runtime": 3.381020300919772}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1850, "makespan": 63, "avg_agents_density": 0.16589351201364474, "runtime": 1.8831430670252303}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1707, "makespan": 59, "avg_agents_density": 0.15220169663687877, "runtime": 1.6931939649221022}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1457, "makespan": 60, "avg_agents_density": 0.17202643149169197, "runtime": 1.6343461470241891}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1945, "makespan": 74, "avg_agents_density": 0.16538828958031865, "runtime": 1.901285861080396}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1781, "makespan": 53, "avg_agents_density": 0.16830579499153964, "runtime": 1.363479744977667}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1350, "makespan": 64, "avg_agents_density": 0.12744713788075135, "runtime": 1.7220628240611404}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2605, "makespan": 95, "avg_agents_density": 0.16275526839973267, "runtime": 2.4140370359964436}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3736, "makespan": 128, "avg_agents_density": 0.18600477748357772, "runtime": 2.8116839928989066}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1960, "makespan": 87, "avg_agents_density": 0.14460531312455208, "runtime": 2.180447210019338}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1865, "makespan": 63, "avg_agents_density": 0.16473811226106547, "runtime": 1.479325029955362}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1524, "makespan": 62, "avg_agents_density": 0.1538123998581722, "runtime": 1.6104272369557293}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1814, "makespan": 59, "avg_agents_density": 0.18510233648424013, "runtime": 1.3670491679222323}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2208, "makespan": 128, "avg_agents_density": 0.16069305061245087, "runtime": 3.028549015056342}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 669, "makespan": 34, "avg_agents_density": 0.1329197231788437, "runtime": 0.8704183109512087}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1372, "makespan": 58, "avg_agents_density": 0.13093325404395434, "runtime": 1.6165164239646401}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 2880, "makespan": 128, "avg_agents_density": 0.1281017275254288, "runtime": 3.1074434979236685}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 2941, "makespan": 114, "avg_agents_density": 0.14650464623791426, "runtime": 2.7307613819866674}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1958, "makespan": 61, "avg_agents_density": 0.16572327698177594, "runtime": 1.6479957119881874}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2404, "makespan": 128, "avg_agents_density": 0.1810264763379623, "runtime": 3.0828098080237396}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 946, "makespan": 43, "avg_agents_density": 0.1436616327632202, "runtime": 1.055632985997363}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3084, "makespan": 101, "avg_agents_density": 0.18478064414707213, "runtime": 3.7700503110245336}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 3417, "makespan": 82, "avg_agents_density": 0.20900943210152656, "runtime": 3.1398008699761704}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3161, "makespan": 128, "avg_agents_density": 0.19548695585692244, "runtime": 4.741757823954686}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2631, "makespan": 72, "avg_agents_density": 0.20839619064583767, "runtime": 2.818273947079433}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2953, "makespan": 87, "avg_agents_density": 0.21198603597277577, "runtime": 3.174268525923253}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 6274, "makespan": 128, "avg_agents_density": 0.21076649256597133, "runtime": 4.593940295846551}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4351, "makespan": 128, "avg_agents_density": 0.19231599007879854, "runtime": 4.099670312018134}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.703125, "CSR": 0.0, "ep_length": 128, "SoC": 6474, "makespan": 128, "avg_agents_density": 0.20369792101388945, "runtime": 4.0954897090559825}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 3301, "makespan": 88, "avg_agents_density": 0.1981426592625093, "runtime": 2.8192913660459453}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2881, "makespan": 128, "avg_agents_density": 0.21214693711380772, "runtime": 4.08903091387765}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3132, "makespan": 101, "avg_agents_density": 0.1755276572517161, "runtime": 3.23667909494543}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 128, "SoC": 6941, "makespan": 128, "avg_agents_density": 0.36479701482398863, "runtime": 4.092572000998189}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3148, "makespan": 128, "avg_agents_density": 0.19840413727831216, "runtime": 4.078558038090705}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2556, "makespan": 86, "avg_agents_density": 0.19562053330163953, "runtime": 2.7630249350477243}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3138, "makespan": 128, "avg_agents_density": 0.2132927103618593, "runtime": 4.678514396946412}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 4014, "makespan": 114, "avg_agents_density": 0.20606633930403523, "runtime": 3.740165644005174}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.609375, "CSR": 0.0, "ep_length": 128, "SoC": 5639, "makespan": 128, "avg_agents_density": 0.26051460845412766, "runtime": 4.146420860022772}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2303, "makespan": 71, "avg_agents_density": 0.15825511722268293, "runtime": 2.2486537200020393}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 5581, "makespan": 128, "avg_agents_density": 0.19716932355511202, "runtime": 3.901823328982573}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 128, "SoC": 6814, "makespan": 128, "avg_agents_density": 0.25311336465302703, "runtime": 4.0146716489689425}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4366, "makespan": 128, "avg_agents_density": 0.1979113858286429, "runtime": 4.178643400009605}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 3710, "makespan": 86, "avg_agents_density": 0.21497010338724257, "runtime": 2.763558933045715}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2528, "makespan": 79, "avg_agents_density": 0.1962398823368158, "runtime": 2.6932430750021012}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 3240, "makespan": 87, "avg_agents_density": 0.20376642209471632, "runtime": 2.790335585086723}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3797, "makespan": 128, "avg_agents_density": 0.19799820600415405, "runtime": 4.2147075629764}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1005, "makespan": 40, "avg_agents_density": 0.17965074540248196, "runtime": 1.290413762020762}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 2021, "makespan": 49, "avg_agents_density": 0.17999856466503655, "runtime": 1.5715767319488805}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4020, "makespan": 128, "avg_agents_density": 0.16774547386024544, "runtime": 4.143394796992652}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 6257, "makespan": 128, "avg_agents_density": 0.23499722749382462, "runtime": 4.079096223998931}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 3061, "makespan": 85, "avg_agents_density": 0.1916162788828614, "runtime": 2.7239810320024844}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 4059, "makespan": 114, "avg_agents_density": 0.23397164030953518, "runtime": 3.644994540067273}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1731, "makespan": 72, "avg_agents_density": 0.18648803478837797, "runtime": 2.801877828038414}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-24000"}]