[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 755, "makespan": 40, "avg_agents_density": 0.0978735796473635, "runtime": 1.08670204396185}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 812, "makespan": 52, "avg_agents_density": 0.11515905881979213, "runtime": 1.7236792899202555}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 830, "makespan": 55, "avg_agents_density": 0.08860000492151358, "runtime": 1.6332240320043638}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 638, "makespan": 40, "avg_agents_density": 0.10948897208541358, "runtime": 1.589087561951601}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 825, "makespan": 46, "avg_agents_density": 0.10714435452723768, "runtime": 1.4191800149710616}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1020, "makespan": 48, "avg_agents_density": 0.11691297949490882, "runtime": 1.6161502600007225}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 721, "makespan": 50, "avg_agents_density": 0.1010868194491457, "runtime": 0.9584779349243036}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1400, "makespan": 66, "avg_agents_density": 0.11403863230364149, "runtime": 2.1885244799777865}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 948, "makespan": 44, "avg_agents_density": 0.11931721245097916, "runtime": 1.1962344800267601}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 666, "makespan": 41, "avg_agents_density": 0.1290225425557448, "runtime": 1.0646539180452237}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 837, "makespan": 50, "avg_agents_density": 0.08556995877348923, "runtime": 1.5749334919819376}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1068, "makespan": 60, "avg_agents_density": 0.1402274341112775, "runtime": 1.8742890819703462}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 687, "makespan": 38, "avg_agents_density": 0.11366032363479288, "runtime": 1.716405720959301}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 613, "makespan": 35, "avg_agents_density": 0.10664974596818474, "runtime": 1.168917082977714}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 932, "makespan": 55, "avg_agents_density": 0.1203814742305206, "runtime": 1.6174380900047254}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 888, "makespan": 47, "avg_agents_density": 0.10769453562008503, "runtime": 1.209161126971594}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 720, "makespan": 47, "avg_agents_density": 0.10624296084002709, "runtime": 0.7100633489899337}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 726, "makespan": 52, "avg_agents_density": 0.09208461032605311, "runtime": 1.7539031519991113}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 994, "makespan": 46, "avg_agents_density": 0.10931281381080114, "runtime": 1.4595955179975135}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1088, "makespan": 65, "avg_agents_density": 0.11146385974960628, "runtime": 1.3972748700034572}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 936, "makespan": 81, "avg_agents_density": 0.09195456582139996, "runtime": 2.1725662070239196}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 873, "makespan": 49, "avg_agents_density": 0.11078313326728678, "runtime": 0.9467747029702878}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 627, "makespan": 46, "avg_agents_density": 0.0917773170009262, "runtime": 0.8882458829903044}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 876, "makespan": 53, "avg_agents_density": 0.11253838496688257, "runtime": 1.713698122970527}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 798, "makespan": 55, "avg_agents_density": 0.09860823695328783, "runtime": 1.4969818159588613}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 437, "makespan": 29, "avg_agents_density": 0.09531128104272629, "runtime": 0.26641104099689983}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 721, "makespan": 50, "avg_agents_density": 0.09736393230308782, "runtime": 1.3686700590478722}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 901, "makespan": 49, "avg_agents_density": 0.0907524976976493, "runtime": 1.588070547048119}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1105, "makespan": 67, "avg_agents_density": 0.09490165603228022, "runtime": 1.165965648033307}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 958, "makespan": 46, "avg_agents_density": 0.10463354866465485, "runtime": 0.8675360149791231}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 689, "makespan": 43, "avg_agents_density": 0.11353755542768552, "runtime": 0.6008891319943359}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 530, "makespan": 28, "avg_agents_density": 0.11566927317641947, "runtime": 0.5247414079494774}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1477, "makespan": 53, "avg_agents_density": 0.14167293580893148, "runtime": 2.3469980049703736}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1674, "makespan": 56, "avg_agents_density": 0.15871128136676835, "runtime": 2.5293745060043875}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 1528, "makespan": 110, "avg_agents_density": 0.13346593732109066, "runtime": 4.252064261978376}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1294, "makespan": 46, "avg_agents_density": 0.1590219649397405, "runtime": 1.9210536679893266}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1567, "makespan": 53, "avg_agents_density": 0.1547655928898637, "runtime": 2.202960689057363}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2363, "makespan": 87, "avg_agents_density": 0.16024538201487082, "runtime": 3.350670149040525}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1334, "makespan": 53, "avg_agents_density": 0.14337427080761728, "runtime": 1.7321063770068577}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2836, "makespan": 128, "avg_agents_density": 0.15258265886256261, "runtime": 5.229829017072916}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1617, "makespan": 85, "avg_agents_density": 0.16292116494125822, "runtime": 3.4571603300137212}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1485, "makespan": 54, "avg_agents_density": 0.17500615613906842, "runtime": 2.0690055289742304}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1265, "makespan": 42, "avg_agents_density": 0.1319600636496639, "runtime": 1.9784498660155805}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 3239, "makespan": 105, "avg_agents_density": 0.20366312288632765, "runtime": 4.102190898018307}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1508, "makespan": 55, "avg_agents_density": 0.15973208832562866, "runtime": 2.6472863199887797}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1405, "makespan": 50, "avg_agents_density": 0.15324829703190257, "runtime": 2.1657402320124675}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1309, "makespan": 46, "avg_agents_density": 0.1754034195628252, "runtime": 1.842377535023843}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1476, "makespan": 43, "avg_agents_density": 0.16161665413374462, "runtime": 1.6767588799702935}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1714, "makespan": 59, "avg_agents_density": 0.17421537886217864, "runtime": 1.9377688450185815}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1286, "makespan": 66, "avg_agents_density": 0.1216947278549167, "runtime": 2.5682611030206317}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 3217, "makespan": 109, "avg_agents_density": 0.18707462237298855, "runtime": 4.59534320406965}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2669, "makespan": 81, "avg_agents_density": 0.16955753284392686, "runtime": 2.6076221489493037}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1612, "makespan": 61, "avg_agents_density": 0.1437437196548162, "runtime": 2.3457387899252353}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1955, "makespan": 68, "avg_agents_density": 0.1658126981411493, "runtime": 2.228580376962782}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1042, "makespan": 36, "avg_agents_density": 0.14490581446851505, "runtime": 1.5617671200016048}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1642, "makespan": 57, "avg_agents_density": 0.1656592392569078, "runtime": 1.8158276400790783}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1886, "makespan": 64, "avg_agents_density": 0.1495746069374714, "runtime": 2.6787125260889297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 666, "makespan": 34, "avg_agents_density": 0.13298346450668364, "runtime": 1.5881239600566914}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1151, "makespan": 37, "avg_agents_density": 0.133530592662828, "runtime": 1.4405206960072974}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 2615, "makespan": 110, "avg_agents_density": 0.1382900125123968, "runtime": 4.279847675934434}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2219, "makespan": 85, "avg_agents_density": 0.14019184078718613, "runtime": 3.002841826993972}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1975, "makespan": 72, "avg_agents_density": 0.16021373816894535, "runtime": 3.1123219259170583}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1250, "makespan": 56, "avg_agents_density": 0.18319210887368978, "runtime": 2.2827662989584496}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 866, "makespan": 37, "avg_agents_density": 0.14373046311107712, "runtime": 1.1013110369676724}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2328, "makespan": 62, "avg_agents_density": 0.18226718479103896, "runtime": 3.78311739997298}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 3224, "makespan": 87, "avg_agents_density": 0.21517881042787126, "runtime": 4.462925702056964}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2488, "makespan": 70, "avg_agents_density": 0.20344510894518095, "runtime": 3.786685353872599}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2006, "makespan": 57, "avg_agents_density": 0.19617595995166465, "runtime": 3.2531412280077348}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 3002, "makespan": 96, "avg_agents_density": 0.2081981170654907, "runtime": 5.278183883972815}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5286, "makespan": 128, "avg_agents_density": 0.21660809678980414, "runtime": 6.7335849149676505}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 3176, "makespan": 95, "avg_agents_density": 0.19699631508264961, "runtime": 3.9729017150530126}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 6098, "makespan": 128, "avg_agents_density": 0.23333285186798083, "runtime": 5.787322816104279}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2925, "makespan": 128, "avg_agents_density": 0.1924647199973852, "runtime": 6.064005326959887}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2141, "makespan": 55, "avg_agents_density": 0.20977924436620846, "runtime": 2.4423506611201447}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2293, "makespan": 61, "avg_agents_density": 0.17023972249084252, "runtime": 2.7787131240329472}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.296875, "CSR": 0.0, "ep_length": 128, "SoC": 7315, "makespan": 128, "avg_agents_density": 0.3838479596329629, "runtime": 5.587026765977498}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 3099, "makespan": 70, "avg_agents_density": 0.21310996418605405, "runtime": 2.8682850090262946}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2719, "makespan": 83, "avg_agents_density": 0.2007705788452297, "runtime": 3.4760649599920725}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 3064, "makespan": 76, "avg_agents_density": 0.21931780226494646, "runtime": 3.9520102390815737}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2703, "makespan": 67, "avg_agents_density": 0.2037157763049004, "runtime": 3.005837774995598}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 6168, "makespan": 128, "avg_agents_density": 0.2293517962503549, "runtime": 5.558857980926405}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1892, "makespan": 64, "avg_agents_density": 0.15406313914473724, "runtime": 3.2942766279302305}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4764, "makespan": 128, "avg_agents_density": 0.18961392441371513, "runtime": 6.176338259989279}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5738, "makespan": 128, "avg_agents_density": 0.2087793681159707, "runtime": 5.583375379894278}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3571, "makespan": 92, "avg_agents_density": 0.18754111696033826, "runtime": 4.499357341977884}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3213, "makespan": 92, "avg_agents_density": 0.20944293584042467, "runtime": 4.4965394970349735}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1676, "makespan": 47, "avg_agents_density": 0.17809910683495075, "runtime": 2.3474938569997903}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2978, "makespan": 88, "avg_agents_density": 0.20120840648940008, "runtime": 3.70606869700714}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 3828, "makespan": 128, "avg_agents_density": 0.19418877993124264, "runtime": 5.089281586100697}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 922, "makespan": 33, "avg_agents_density": 0.1830362562896277, "runtime": 1.41803737700684}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2273, "makespan": 65, "avg_agents_density": 0.17425108839994183, "runtime": 3.1839398060110398}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2514, "makespan": 64, "avg_agents_density": 0.1697154569312149, "runtime": 2.637602613962372}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 4309, "makespan": 104, "avg_agents_density": 0.21197340571115125, "runtime": 4.8367049329244765}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 3090, "makespan": 90, "avg_agents_density": 0.20823436631578612, "runtime": 3.769459898961941}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 3038, "makespan": 85, "avg_agents_density": 0.24418122261411818, "runtime": 3.8680459370370954}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 3013, "makespan": 95, "avg_agents_density": 0.1916006199423801, "runtime": 5.341566943010548}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-312000"}]