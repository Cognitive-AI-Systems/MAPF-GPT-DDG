[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 708, "makespan": 40, "avg_agents_density": 0.09275101139185808, "runtime": 0.6528546709887451}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 907, "makespan": 47, "avg_agents_density": 0.12567333204665257, "runtime": 1.1946113130252343}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 824, "makespan": 56, "avg_agents_density": 0.0883486142189692, "runtime": 0.6508495549933286}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 656, "makespan": 42, "avg_agents_density": 0.10679547123484152, "runtime": 1.0121784440270858}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 915, "makespan": 48, "avg_agents_density": 0.105260565106926, "runtime": 1.30487412691582}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1100, "makespan": 52, "avg_agents_density": 0.11678625338023536, "runtime": 1.3415434210182866}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 829, "makespan": 52, "avg_agents_density": 0.10359436514459695, "runtime": 0.9001493510877481}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1031, "makespan": 54, "avg_agents_density": 0.10935830268614391, "runtime": 1.421557470006519}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1021, "makespan": 54, "avg_agents_density": 0.11237266421146032, "runtime": 1.0892184390104376}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 648, "makespan": 40, "avg_agents_density": 0.1247366916924459, "runtime": 0.2970026120747207}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 832, "makespan": 44, "avg_agents_density": 0.09120865709292504, "runtime": 1.0971340330288513}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1113, "makespan": 50, "avg_agents_density": 0.1593132096074646, "runtime": 0.9318714349792572}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 708, "makespan": 35, "avg_agents_density": 0.10894106869621864, "runtime": 0.929270258086035}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 617, "makespan": 36, "avg_agents_density": 0.11125699454347386, "runtime": 0.8660023039847147}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 695, "makespan": 45, "avg_agents_density": 0.12095281669984877, "runtime": 0.8584234110021498}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 983, "makespan": 55, "avg_agents_density": 0.1189288514737378, "runtime": 0.3858159940573387}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 733, "makespan": 41, "avg_agents_density": 0.1111826856014498, "runtime": 0.3660177650890546}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 783, "makespan": 52, "avg_agents_density": 0.09317106170467469, "runtime": 1.0119286609697156}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1301, "makespan": 72, "avg_agents_density": 0.11612618559323079, "runtime": 1.9564568929636152}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 946, "makespan": 47, "avg_agents_density": 0.11699541912434874, "runtime": 0.3333401600102661}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 815, "makespan": 49, "avg_agents_density": 0.09121093669626483, "runtime": 1.214560598062235}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 854, "makespan": 48, "avg_agents_density": 0.10849293497881361, "runtime": 0.1844890570064308}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 626, "makespan": 40, "avg_agents_density": 0.09735096194979412, "runtime": 0.701942050960497}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 762, "makespan": 45, "avg_agents_density": 0.10998803583214689, "runtime": 1.1874788029963383}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 979, "makespan": 58, "avg_agents_density": 0.10085063708920695, "runtime": 1.1145437660161406}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 433, "makespan": 29, "avg_agents_density": 0.09364221777672073, "runtime": 0.21762971696443856}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 785, "makespan": 45, "avg_agents_density": 0.09796558606582752, "runtime": 0.7778170879901154}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 879, "makespan": 47, "avg_agents_density": 0.08714483366551691, "runtime": 0.9959687890805071}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1132, "makespan": 58, "avg_agents_density": 0.09244612482196907, "runtime": 0.38101723200816195}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 994, "makespan": 57, "avg_agents_density": 0.10658840835913495, "runtime": 1.0538749630213715}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 660, "makespan": 38, "avg_agents_density": 0.11035238046508757, "runtime": 0.11087606902583502}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 512, "makespan": 29, "avg_agents_density": 0.11402228423765051, "runtime": 0.32202674708969425}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1337, "makespan": 61, "avg_agents_density": 0.14116169255440542, "runtime": 2.0790506179473596}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1811, "makespan": 60, "avg_agents_density": 0.15526610091704637, "runtime": 1.529911222998635}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1393, "makespan": 56, "avg_agents_density": 0.14487274308251621, "runtime": 1.729552555058035}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1363, "makespan": 51, "avg_agents_density": 0.15471269812353164, "runtime": 1.3005429390614154}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1430, "makespan": 50, "avg_agents_density": 0.1425832228736458, "runtime": 1.5374976749590132}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2078, "makespan": 68, "avg_agents_density": 0.15801896319287875, "runtime": 2.0398063820030075}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1254, "makespan": 48, "avg_agents_density": 0.1481512773816756, "runtime": 1.2459825760452077}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2614, "makespan": 128, "avg_agents_density": 0.1510724350132794, "runtime": 3.6744397190923337}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1687, "makespan": 67, "avg_agents_density": 0.16041114782043028, "runtime": 2.0354277089063544}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1356, "makespan": 52, "avg_agents_density": 0.17226945024870133, "runtime": 1.3457927260606084}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1505, "makespan": 60, "avg_agents_density": 0.12908789634969622, "runtime": 2.0313896130392095}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 128, "SoC": 3902, "makespan": 128, "avg_agents_density": 0.3095517290983641, "runtime": 3.5144050668895943}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1199, "makespan": 38, "avg_agents_density": 0.16350717885782443, "runtime": 1.3008116540004266}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1479, "makespan": 57, "avg_agents_density": 0.14912898566099192, "runtime": 1.8249717109720223}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1477, "makespan": 61, "avg_agents_density": 0.17309595957909246, "runtime": 1.6504645949898986}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1681, "makespan": 58, "avg_agents_density": 0.17121924114612302, "runtime": 1.7548310940183}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2094, "makespan": 84, "avg_agents_density": 0.16757513836433482, "runtime": 2.1117971941130236}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1149, "makespan": 53, "avg_agents_density": 0.12304101115826355, "runtime": 1.570954333030386}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 2544, "makespan": 105, "avg_agents_density": 0.15399208779088977, "runtime": 2.7000106330233393}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 128, "SoC": 4339, "makespan": 128, "avg_agents_density": 0.21084597921141268, "runtime": 2.1328845570096746}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1584, "makespan": 64, "avg_agents_density": 0.14062140848483273, "runtime": 1.7576693760056514}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1650, "makespan": 57, "avg_agents_density": 0.1599284379934132, "runtime": 1.3453216240304755}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1194, "makespan": 45, "avg_agents_density": 0.1472319185213942, "runtime": 1.1956321159668732}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1363, "makespan": 43, "avg_agents_density": 0.16545754328923765, "runtime": 1.090584920035326}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 1820, "makespan": 100, "avg_agents_density": 0.15284087706570315, "runtime": 2.588267027938855}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 651, "makespan": 32, "avg_agents_density": 0.13452349837673772, "runtime": 0.8201673559960909}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1152, "makespan": 49, "avg_agents_density": 0.13064396849800686, "runtime": 1.4221689399855677}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1988, "makespan": 80, "avg_agents_density": 0.13194919199216615, "runtime": 1.9714007181028137}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2007, "makespan": 85, "avg_agents_density": 0.1390886441053432, "runtime": 2.2173153650946915}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1927, "makespan": 70, "avg_agents_density": 0.16049107607890978, "runtime": 1.9983137590752449}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1537, "makespan": 51, "avg_agents_density": 0.17862157033829307, "runtime": 1.2897946759476326}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 851, "makespan": 32, "avg_agents_density": 0.14573691847037415, "runtime": 0.875174504952156}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2800, "makespan": 73, "avg_agents_density": 0.18709054112656043, "runtime": 2.9098893989867065}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2809, "makespan": 72, "avg_agents_density": 0.20278501467295698, "runtime": 2.8958278300706297}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2473, "makespan": 77, "avg_agents_density": 0.19670466898098077, "runtime": 3.1187847860419424}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2453, "makespan": 70, "avg_agents_density": 0.1942754825631121, "runtime": 2.679914953027037}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2424, "makespan": 70, "avg_agents_density": 0.18962564971317436, "runtime": 2.8246736280125333}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4916, "makespan": 128, "avg_agents_density": 0.20422166496483218, "runtime": 4.631617242965149}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2366, "makespan": 70, "avg_agents_density": 0.18532765089350087, "runtime": 2.4709212039160775}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 128, "SoC": 6650, "makespan": 128, "avg_agents_density": 0.3211301775284548, "runtime": 4.475149936013622}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 3422, "makespan": 91, "avg_agents_density": 0.2114537808539466, "runtime": 3.0927784109226195}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2931, "makespan": 81, "avg_agents_density": 0.21657863687803514, "runtime": 2.7966724549623905}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1956, "makespan": 48, "avg_agents_density": 0.1680232678674127, "runtime": 1.729130320934928}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 128, "SoC": 7031, "makespan": 128, "avg_agents_density": 0.3644852096239767, "runtime": 4.475208212912548}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 3060, "makespan": 79, "avg_agents_density": 0.20559909023636855, "runtime": 2.724934935962665}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2348, "makespan": 60, "avg_agents_density": 0.19538605754613006, "runtime": 2.014343658956932}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 2057, "makespan": 47, "avg_agents_density": 0.215879408120075, "runtime": 1.8826625420042546}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2764, "makespan": 75, "avg_agents_density": 0.20822628654643074, "runtime": 2.7190296789922286}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4303, "makespan": 128, "avg_agents_density": 0.20657963391630343, "runtime": 4.383741261000978}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2034, "makespan": 64, "avg_agents_density": 0.15414607677647976, "runtime": 2.3213134040270234}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5172, "makespan": 128, "avg_agents_density": 0.19566287388431508, "runtime": 4.420761049055727}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5790, "makespan": 128, "avg_agents_density": 0.20373111865601584, "runtime": 3.861115458101267}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 3357, "makespan": 89, "avg_agents_density": 0.19728125994218032, "runtime": 3.0977005990134785}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 3399, "makespan": 98, "avg_agents_density": 0.21760955584202446, "runtime": 3.1840830000583082}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1662, "makespan": 51, "avg_agents_density": 0.1836277510697493, "runtime": 1.679442253021989}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2798, "makespan": 78, "avg_agents_density": 0.20040615464831907, "runtime": 2.8061916018777993}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 3622, "makespan": 128, "avg_agents_density": 0.19647639666759695, "runtime": 4.571049672056688}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 991, "makespan": 30, "avg_agents_density": 0.18263455471554427, "runtime": 0.9875383459875593}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1951, "makespan": 51, "avg_agents_density": 0.1798980129891124, "runtime": 1.766267111976049}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2423, "makespan": 69, "avg_agents_density": 0.17679777039716532, "runtime": 2.328358380967984}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 5135, "makespan": 128, "avg_agents_density": 0.19461282337093277, "runtime": 4.495679532061331}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 3028, "makespan": 78, "avg_agents_density": 0.21436979446124382, "runtime": 2.6158718199294526}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 3028, "makespan": 89, "avg_agents_density": 0.22532943844736317, "runtime": 3.0713813260081224}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1714, "makespan": 57, "avg_agents_density": 0.19537394457560256, "runtime": 2.140370643013739}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-256000"}]