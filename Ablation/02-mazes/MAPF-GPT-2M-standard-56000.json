[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 769, "makespan": 74, "avg_agents_density": 0.0960392272332137, "runtime": 1.2121549411676824}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 917, "makespan": 45, "avg_agents_density": 0.13112204499264482, "runtime": 0.7181544929626398}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1061, "makespan": 128, "avg_agents_density": 0.08318203071941266, "runtime": 1.4105495900439564}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 681, "makespan": 69, "avg_agents_density": 0.10533043702471445, "runtime": 1.4503273217997048}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 879, "makespan": 50, "avg_agents_density": 0.11237537604512803, "runtime": 1.0666266770567745}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1815, "makespan": 128, "avg_agents_density": 0.10198152618699201, "runtime": 2.122846463927999}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 760, "makespan": 49, "avg_agents_density": 0.09765609109620386, "runtime": 1.002479461953044}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1124, "makespan": 55, "avg_agents_density": 0.11278130403973849, "runtime": 1.1492300658428576}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 1194, "makespan": 122, "avg_agents_density": 0.10506066943103086, "runtime": 2.625038951955503}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 833, "makespan": 51, "avg_agents_density": 0.12177608634051361, "runtime": 0.8501172959804535}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 828, "makespan": 45, "avg_agents_density": 0.09183029924824, "runtime": 0.8292802760843188}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 1874, "makespan": 128, "avg_agents_density": 0.13328345347597167, "runtime": 2.3212518068321515}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 751, "makespan": 66, "avg_agents_density": 0.10134529113993514, "runtime": 1.3865101769333705}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 584, "makespan": 33, "avg_agents_density": 0.10996434584435368, "runtime": 0.6983790640661027}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 690, "makespan": 49, "avg_agents_density": 0.12135494115853623, "runtime": 0.5337827409093734}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1123, "makespan": 63, "avg_agents_density": 0.12048637292456704, "runtime": 0.8942504429433029}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 1717, "makespan": 128, "avg_agents_density": 0.10511976484982377, "runtime": 2.156131248892052}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 744, "makespan": 46, "avg_agents_density": 0.09096797833456281, "runtime": 0.9348695908847731}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 1618, "makespan": 106, "avg_agents_density": 0.12617364633541583, "runtime": 1.9836087139556184}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 2578, "makespan": 128, "avg_agents_density": 0.11737396948269507, "runtime": 0.6828373902244493}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 959, "makespan": 69, "avg_agents_density": 0.09381132253082312, "runtime": 0.8775385220069438}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1086, "makespan": 61, "avg_agents_density": 0.113165581792871, "runtime": 0.5785265509912279}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 707, "makespan": 44, "avg_agents_density": 0.09783383603534752, "runtime": 0.40440871892496943}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1064, "makespan": 64, "avg_agents_density": 0.11945642660303947, "runtime": 1.3377505089738406}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 942, "makespan": 65, "avg_agents_density": 0.10253363244521714, "runtime": 1.2676075570343528}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 477, "makespan": 30, "avg_agents_density": 0.09658856284616643, "runtime": 0.39474742294987664}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 802, "makespan": 48, "avg_agents_density": 0.0966848661973599, "runtime": 0.8917974100040738}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 942, "makespan": 69, "avg_agents_density": 0.08244286740863183, "runtime": 1.008574390958529}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1228, "makespan": 91, "avg_agents_density": 0.09142468173629005, "runtime": 0.26465480073238723}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 953, "makespan": 49, "avg_agents_density": 0.11018507962142804, "runtime": 0.4645347749174107}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 870, "makespan": 117, "avg_agents_density": 0.10370009532053924, "runtime": 0.7415632529300638}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 540, "makespan": 32, "avg_agents_density": 0.11072643682753448, "runtime": 0.23868104798020795}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1579, "makespan": 68, "avg_agents_density": 0.146492295567705, "runtime": 1.9823775340046268}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 2332, "makespan": 120, "avg_agents_density": 0.1518876926234024, "runtime": 3.051440834184177}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2202, "makespan": 128, "avg_agents_density": 0.13305744140471007, "runtime": 3.249442892993102}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1444, "makespan": 57, "avg_agents_density": 0.1699497721224366, "runtime": 1.4444103279674891}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1976, "makespan": 128, "avg_agents_density": 0.14454402791273258, "runtime": 3.267387912783306}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.7916666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3793, "makespan": 128, "avg_agents_density": 0.15239100317618948, "runtime": 3.2537916150176898}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 1881, "makespan": 103, "avg_agents_density": 0.14123193755220215, "runtime": 2.6162391842517536}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4456, "makespan": 128, "avg_agents_density": 0.1612487012415615, "runtime": 3.546881358954124}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 2301, "makespan": 99, "avg_agents_density": 0.16314266158025528, "runtime": 2.5124521458346862}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 1881, "makespan": 88, "avg_agents_density": 0.17149068363098227, "runtime": 2.235149518994149}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1277, "makespan": 52, "avg_agents_density": 0.12520283138275928, "runtime": 1.3078128680645023}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 128, "SoC": 4862, "makespan": 128, "avg_agents_density": 0.2970214243919848, "runtime": 3.2768549119355157}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1814, "makespan": 80, "avg_agents_density": 0.1665570387902952, "runtime": 2.2811418790952303}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1751, "makespan": 74, "avg_agents_density": 0.161069461527702, "runtime": 1.9322499661066104}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1857, "makespan": 128, "avg_agents_density": 0.1646217844039846, "runtime": 3.252913308009738}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 2425, "makespan": 118, "avg_agents_density": 0.16079093180182571, "runtime": 3.126914559135912}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2187, "makespan": 73, "avg_agents_density": 0.17184920346690133, "runtime": 1.8523940640152432}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1396, "makespan": 72, "avg_agents_density": 0.12156160108722128, "runtime": 1.8257630881271325}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4424, "makespan": 128, "avg_agents_density": 0.15829567627364038, "runtime": 3.2104765650292393}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4155, "makespan": 128, "avg_agents_density": 0.16685260416243763, "runtime": 2.6124975390848704}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2404, "makespan": 128, "avg_agents_density": 0.14118128563082843, "runtime": 2.6914647639205214}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2796, "makespan": 128, "avg_agents_density": 0.1711291378405364, "runtime": 2.741618770000059}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1446, "makespan": 73, "avg_agents_density": 0.14982511555805342, "runtime": 1.845302871952299}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1947, "makespan": 74, "avg_agents_density": 0.16944722877501195, "runtime": 1.5325564838421997}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2661, "makespan": 97, "avg_agents_density": 0.1519286731098741, "runtime": 2.35150157881435}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 696, "makespan": 30, "avg_agents_density": 0.13880493015434503, "runtime": 0.7560352110594977}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 1314, "makespan": 84, "avg_agents_density": 0.12667828617479532, "runtime": 2.1337863360822666}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3216, "makespan": 128, "avg_agents_density": 0.128245586615164, "runtime": 2.912583162105875}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3075, "makespan": 128, "avg_agents_density": 0.1567292801207288, "runtime": 3.0095806909375824}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3681, "makespan": 128, "avg_agents_density": 0.1728458532544156, "runtime": 3.1135283509793226}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2049, "makespan": 101, "avg_agents_density": 0.1810863536497124, "runtime": 2.550803997932235}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1154, "makespan": 48, "avg_agents_density": 0.1548110783033762, "runtime": 1.2151655789639335}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 5074, "makespan": 128, "avg_agents_density": 0.21709557185995407, "runtime": 4.238294225011487}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5859, "makespan": 128, "avg_agents_density": 0.23334387343655513, "runtime": 4.492618476244388}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 5223, "makespan": 128, "avg_agents_density": 0.22923720615926269, "runtime": 4.554074341722298}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 2942, "makespan": 128, "avg_agents_density": 0.19436388444605662, "runtime": 4.5426272359036375}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.609375, "CSR": 0.0, "ep_length": 128, "SoC": 5079, "makespan": 128, "avg_agents_density": 0.28593471343795823, "runtime": 4.487166320061078}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 6392, "makespan": 128, "avg_agents_density": 0.23028580363423146, "runtime": 4.444747918023495}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4293, "makespan": 128, "avg_agents_density": 0.19498500777705427, "runtime": 4.0746882111998275}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 128, "SoC": 6917, "makespan": 128, "avg_agents_density": 0.22631508344697132, "runtime": 4.100008011155296}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 6008, "makespan": 128, "avg_agents_density": 0.2397993257154165, "runtime": 4.086409477109555}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 3895, "makespan": 112, "avg_agents_density": 0.23870148106794725, "runtime": 3.5878569111810066}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 3752, "makespan": 128, "avg_agents_density": 0.19307575607676022, "runtime": 4.091036935016746}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 128, "SoC": 7492, "makespan": 128, "avg_agents_density": 0.41600077615039316, "runtime": 4.095665506931255}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3929, "makespan": 128, "avg_agents_density": 0.21014103406682436, "runtime": 4.09085205104202}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3298, "makespan": 128, "avg_agents_density": 0.19589757719522063, "runtime": 4.092219062993536}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5124, "makespan": 128, "avg_agents_density": 0.23406428629257642, "runtime": 4.0119245668756776}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5285, "makespan": 128, "avg_agents_density": 0.21939452857572858, "runtime": 4.036244341026759}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.453125, "CSR": 0.0, "ep_length": 128, "SoC": 6398, "makespan": 128, "avg_agents_density": 0.2971766367471392, "runtime": 4.029481862031389}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 2389, "makespan": 113, "avg_agents_density": 0.1532141686677954, "runtime": 3.539109567005653}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 6462, "makespan": 128, "avg_agents_density": 0.2185348219458008, "runtime": 3.66997512706439}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 128, "SoC": 7600, "makespan": 128, "avg_agents_density": 0.22458075026689595, "runtime": 3.6835554758727085}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 5410, "makespan": 128, "avg_agents_density": 0.18647499029594658, "runtime": 3.680304719193373}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5106, "makespan": 128, "avg_agents_density": 0.20716751148835552, "runtime": 3.752436451934045}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2143, "makespan": 59, "avg_agents_density": 0.20256467782172766, "runtime": 1.8009847721259575}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3891, "makespan": 128, "avg_agents_density": 0.19179722275547298, "runtime": 4.0360153250803705}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.703125, "CSR": 0.0, "ep_length": 128, "SoC": 5430, "makespan": 128, "avg_agents_density": 0.18909623772352216, "runtime": 3.9806369161524344}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 987, "makespan": 32, "avg_agents_density": 0.18358799504878937, "runtime": 1.012386652029818}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 2498, "makespan": 128, "avg_agents_density": 0.16893855577418523, "runtime": 3.7924729420046788}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 4884, "makespan": 128, "avg_agents_density": 0.18981553349013805, "runtime": 4.023917540063849}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.515625, "CSR": 0.0, "ep_length": 128, "SoC": 6826, "makespan": 128, "avg_agents_density": 0.27606051562794265, "runtime": 4.023997276992304}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 5849, "makespan": 128, "avg_agents_density": 0.28889727892327904, "runtime": 4.015892682102276}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 4999, "makespan": 128, "avg_agents_density": 0.2238308033057285, "runtime": 4.08723061386263}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1657, "makespan": 51, "avg_agents_density": 0.19083299614891644, "runtime": 1.814453792932909}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-56000"}]