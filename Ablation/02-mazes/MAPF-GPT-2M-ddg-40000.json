[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 753, "makespan": 45, "avg_agents_density": 0.09916448535614304, "runtime": 1.0317697179852985}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1125, "makespan": 58, "avg_agents_density": 0.1285031968776217, "runtime": 0.7914455817081034}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 1143, "makespan": 128, "avg_agents_density": 0.08403189154858046, "runtime": 1.7126808409811929}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 748, "makespan": 46, "avg_agents_density": 0.11396219654159874, "runtime": 1.2028998308232985}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1138, "makespan": 59, "avg_agents_density": 0.11851387488472372, "runtime": 1.248959025950171}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 1650, "makespan": 106, "avg_agents_density": 0.10584888587638654, "runtime": 1.6103488823282532}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 934, "makespan": 63, "avg_agents_density": 0.0997431147775382, "runtime": 1.0801725431228988}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 1484, "makespan": 109, "avg_agents_density": 0.10449564398742724, "runtime": 3.1846827206318267}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 911, "makespan": 47, "avg_agents_density": 0.11762283446532884, "runtime": 1.0510854289750569}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 721, "makespan": 40, "avg_agents_density": 0.12390210362820352, "runtime": 0.719731614983175}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 824, "makespan": 47, "avg_agents_density": 0.09179599643885102, "runtime": 0.7638996817986481}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 1684, "makespan": 113, "avg_agents_density": 0.1350811725692612, "runtime": 2.1868712278665043}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 743, "makespan": 39, "avg_agents_density": 0.10982311394529272, "runtime": 1.1353354689781554}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 653, "makespan": 35, "avg_agents_density": 0.11025555345183456, "runtime": 0.9242872810573317}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 805, "makespan": 46, "avg_agents_density": 0.12292101597084784, "runtime": 0.45991598308319226}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 922, "makespan": 40, "avg_agents_density": 0.11081971733766009, "runtime": 0.7402337389066815}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1095, "makespan": 128, "avg_agents_density": 0.10429023630501884, "runtime": 1.779373896191828}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 692, "makespan": 39, "avg_agents_density": 0.09183526250265807, "runtime": 0.6757717818836682}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1021, "makespan": 55, "avg_agents_density": 0.12059225368562816, "runtime": 1.5842801159014925}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1292, "makespan": 128, "avg_agents_density": 0.1129484311576407, "runtime": 0.904567168909125}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 835, "makespan": 46, "avg_agents_density": 0.09334007250029885, "runtime": 0.4234553485875949}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 920, "makespan": 44, "avg_agents_density": 0.11130609340867631, "runtime": 0.7515499200671911}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 785, "makespan": 43, "avg_agents_density": 0.09404116065727415, "runtime": 0.352498539024964}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 781, "makespan": 41, "avg_agents_density": 0.11224261162231156, "runtime": 1.266148425231222}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 885, "makespan": 58, "avg_agents_density": 0.10204736915865258, "runtime": 1.6103531408007257}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 444, "makespan": 29, "avg_agents_density": 0.09518797398306554, "runtime": 0.27795865084044635}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 940, "makespan": 59, "avg_agents_density": 0.09844093064353607, "runtime": 0.9704928150167689}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1032, "makespan": 63, "avg_agents_density": 0.0878440529793321, "runtime": 1.7710007899440825}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 1229, "makespan": 81, "avg_agents_density": 0.09104809670155017, "runtime": 0.2919248371035792}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 1291, "makespan": 81, "avg_agents_density": 0.10688015572280747, "runtime": 0.6122624779236503}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 823, "makespan": 48, "avg_agents_density": 0.11588868161747302, "runtime": 0.6412362340488471}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 543, "makespan": 30, "avg_agents_density": 0.11489507103146125, "runtime": 0.25810720230219886}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1436, "makespan": 47, "avg_agents_density": 0.1482598187231786, "runtime": 1.425170740869362}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1832, "makespan": 64, "avg_agents_density": 0.16583888573043826, "runtime": 2.070828947413247}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 1724, "makespan": 115, "avg_agents_density": 0.13331949204606544, "runtime": 3.4792605686816387}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1252, "makespan": 42, "avg_agents_density": 0.16880015229341186, "runtime": 1.2511692190309986}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1779, "makespan": 67, "avg_agents_density": 0.14640999752837278, "runtime": 2.087693254055921}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2752, "makespan": 102, "avg_agents_density": 0.15457029862502905, "runtime": 3.3398219075170346}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1353, "makespan": 57, "avg_agents_density": 0.14229065032351465, "runtime": 1.6245963692199439}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3612, "makespan": 128, "avg_agents_density": 0.1545934058735609, "runtime": 4.091784507152624}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1877, "makespan": 66, "avg_agents_density": 0.16874757193179155, "runtime": 2.0762935878592543}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1732, "makespan": 65, "avg_agents_density": 0.18524765367167148, "runtime": 2.130036526999902}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1550, "makespan": 75, "avg_agents_density": 0.12677663816882312, "runtime": 2.478999503189698}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4322, "makespan": 128, "avg_agents_density": 0.20958222050614755, "runtime": 4.030089284002315}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1692, "makespan": 55, "avg_agents_density": 0.17407946027093665, "runtime": 1.7918625779566355}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1307, "makespan": 43, "avg_agents_density": 0.14855076991398855, "runtime": 1.312421632988844}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1742, "makespan": 128, "avg_agents_density": 0.16461334558276294, "runtime": 3.930612489930354}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 1848, "makespan": 93, "avg_agents_density": 0.15706522218237923, "runtime": 3.063584371760953}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3421, "makespan": 128, "avg_agents_density": 0.19354187699053463, "runtime": 3.861033043882344}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1261, "makespan": 51, "avg_agents_density": 0.11912223059169559, "runtime": 1.5455723361228593}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3208, "makespan": 128, "avg_agents_density": 0.17419299495775883, "runtime": 4.020384011906572}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 128, "SoC": 4693, "makespan": 128, "avg_agents_density": 0.29945147289634405, "runtime": 3.8097791602485813}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 2199, "makespan": 90, "avg_agents_density": 0.1515805104337874, "runtime": 1.7242828100570478}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1727, "makespan": 61, "avg_agents_density": 0.162708118036592, "runtime": 1.706369431805797}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1203, "makespan": 54, "avg_agents_density": 0.1449216753441922, "runtime": 1.6620414520730264}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 2839, "makespan": 105, "avg_agents_density": 0.18886355162700996, "runtime": 2.308683432289399}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2225, "makespan": 128, "avg_agents_density": 0.15539555920117443, "runtime": 3.918076924921479}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 711, "makespan": 31, "avg_agents_density": 0.13509517603055576, "runtime": 0.9663833911181428}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1176, "makespan": 48, "avg_agents_density": 0.13600200126514972, "runtime": 1.4471606969018467}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2132, "makespan": 82, "avg_agents_density": 0.1337898388526593, "runtime": 2.4962894828640856}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 3122, "makespan": 121, "avg_agents_density": 0.14743604445466577, "runtime": 3.784770586178638}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 2349, "makespan": 112, "avg_agents_density": 0.15288636136358297, "runtime": 3.485108512395527}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1772, "makespan": 73, "avg_agents_density": 0.17936790749461373, "runtime": 2.0635811201645993}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1108, "makespan": 46, "avg_agents_density": 0.1487595609884984, "runtime": 1.209246345446445}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2677, "makespan": 70, "avg_agents_density": 0.19506221632193071, "runtime": 2.6634616209194064}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 6129, "makespan": 128, "avg_agents_density": 0.2797069893276608, "runtime": 4.621060701319948}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5862, "makespan": 128, "avg_agents_density": 0.24548284563842, "runtime": 4.656600482179783}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2403, "makespan": 77, "avg_agents_density": 0.19617062661344, "runtime": 2.871160004346166}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 5196, "makespan": 128, "avg_agents_density": 0.23789564814525813, "runtime": 4.722269660094753}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 5782, "makespan": 128, "avg_agents_density": 0.22731738075844393, "runtime": 4.747489662957378}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 3775, "makespan": 128, "avg_agents_density": 0.1958116099055006, "runtime": 4.0514409963507205}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.421875, "CSR": 0.0, "ep_length": 128, "SoC": 7103, "makespan": 128, "avg_agents_density": 0.28823532688273296, "runtime": 4.041375071334187}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 4140, "makespan": 128, "avg_agents_density": 0.21282715208399175, "runtime": 3.992332841968164}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3068, "makespan": 128, "avg_agents_density": 0.2206182602395452, "runtime": 4.093416288436856}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4579, "makespan": 128, "avg_agents_density": 0.17837987788983448, "runtime": 4.041574354225304}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.296875, "CSR": 0.0, "ep_length": 128, "SoC": 6708, "makespan": 128, "avg_agents_density": 0.3968125210310868, "runtime": 4.019101261976175}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4544, "makespan": 128, "avg_agents_density": 0.22994803807146588, "runtime": 4.039656606968492}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2278, "makespan": 66, "avg_agents_density": 0.19242743877270568, "runtime": 2.1184776929439977}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4698, "makespan": 128, "avg_agents_density": 0.25069148224234294, "runtime": 4.564212728815619}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4671, "makespan": 128, "avg_agents_density": 0.2238001348772578, "runtime": 4.0031451432732865}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 6018, "makespan": 128, "avg_agents_density": 0.26026811407664535, "runtime": 3.9910731741110794}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1985, "makespan": 59, "avg_agents_density": 0.15819590090044275, "runtime": 1.8724032911122777}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 5254, "makespan": 128, "avg_agents_density": 0.1876848050322016, "runtime": 3.9776287016575225}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.390625, "CSR": 0.0, "ep_length": 128, "SoC": 6944, "makespan": 128, "avg_agents_density": 0.30568931679808364, "runtime": 3.9885797551251017}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 4035, "makespan": 128, "avg_agents_density": 0.19759151342799203, "runtime": 4.272739554930013}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3918, "makespan": 128, "avg_agents_density": 0.20225341715311992, "runtime": 4.051331128459424}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1839, "makespan": 64, "avg_agents_density": 0.18476671740155276, "runtime": 1.9953416997450404}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 3354, "makespan": 120, "avg_agents_density": 0.20088848225472372, "runtime": 3.763445366465021}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4338, "makespan": 128, "avg_agents_density": 0.20026870998166033, "runtime": 4.012487503874581}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 996, "makespan": 34, "avg_agents_density": 0.18304064984088733, "runtime": 1.0768083770526573}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2889, "makespan": 83, "avg_agents_density": 0.18655304475756665, "runtime": 2.658129912801087}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3582, "makespan": 128, "avg_agents_density": 0.17662649994163282, "runtime": 4.008401285216678}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 6021, "makespan": 128, "avg_agents_density": 0.2692866531508687, "runtime": 3.9954405021853745}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 5715, "makespan": 128, "avg_agents_density": 0.25236822194545794, "runtime": 3.9803847759612836}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 3614, "makespan": 128, "avg_agents_density": 0.22793334237467022, "runtime": 4.108763886848465}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2308, "makespan": 74, "avg_agents_density": 0.2027918732498533, "runtime": 2.8807734714937396}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-40000"}]