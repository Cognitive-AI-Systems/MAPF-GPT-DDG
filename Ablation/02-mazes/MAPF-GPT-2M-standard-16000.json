[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1035, "makespan": 60, "avg_agents_density": 0.10176478756179044, "runtime": 0.9172461339330766}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 942, "makespan": 52, "avg_agents_density": 0.12563997326631413, "runtime": 0.8195292558229994}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1382, "makespan": 128, "avg_agents_density": 0.08348122429678047, "runtime": 2.051583871128969}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 678, "makespan": 45, "avg_agents_density": 0.10947576379687325, "runtime": 0.8361195979232434}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 872, "makespan": 52, "avg_agents_density": 0.10892145054135276, "runtime": 1.0903490689815953}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 2089, "makespan": 128, "avg_agents_density": 0.10303798110798613, "runtime": 2.4287646790326107}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 818, "makespan": 47, "avg_agents_density": 0.09547713758798748, "runtime": 0.8423106808622833}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 1859, "makespan": 123, "avg_agents_density": 0.1060452023178107, "runtime": 2.6428597671038006}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 1314, "makespan": 96, "avg_agents_density": 0.10233212245722549, "runtime": 1.8831274668627884}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 926, "makespan": 73, "avg_agents_density": 0.12292794344737877, "runtime": 1.372977287886897}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 806, "makespan": 50, "avg_agents_density": 0.08721172463828557, "runtime": 0.8660940499394201}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1152, "makespan": 128, "avg_agents_density": 0.1360637875884826, "runtime": 2.3964703259116504}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 860, "makespan": 64, "avg_agents_density": 0.10044318377050997, "runtime": 1.2565420659957454}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 640, "makespan": 34, "avg_agents_density": 0.10879546275803122, "runtime": 0.7598880178993568}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 770, "makespan": 42, "avg_agents_density": 0.12624802208575545, "runtime": 0.6710492698766757}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 124, "SoC": 1792, "makespan": 124, "avg_agents_density": 0.11148183372166079, "runtime": 1.997886939177988}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 1143, "makespan": 118, "avg_agents_density": 0.10732933979184332, "runtime": 1.8622872389678378}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 759, "makespan": 46, "avg_agents_density": 0.08558494698361759, "runtime": 0.875521471927641}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 1565, "makespan": 89, "avg_agents_density": 0.10903553536629919, "runtime": 1.4418874689145014}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 2314, "makespan": 128, "avg_agents_density": 0.12958869430695402, "runtime": 1.1333300609258004}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1121, "makespan": 128, "avg_agents_density": 0.09375626600583958, "runtime": 1.7158762679900974}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1324, "makespan": 71, "avg_agents_density": 0.12630687997811535, "runtime": 0.9817342608293984}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 901, "makespan": 90, "avg_agents_density": 0.08886144338687674, "runtime": 1.426833050994901}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 833, "makespan": 59, "avg_agents_density": 0.10571539622263999, "runtime": 1.1165965190448333}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1297, "makespan": 128, "avg_agents_density": 0.10034006363397664, "runtime": 2.0936265520576853}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 528, "makespan": 44, "avg_agents_density": 0.08982306637553325, "runtime": 0.626764601940522}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 872, "makespan": 49, "avg_agents_density": 0.09527382539583919, "runtime": 0.8992980530601926}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1218, "makespan": 72, "avg_agents_density": 0.08440758504402496, "runtime": 1.1402620560547803}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1356, "makespan": 83, "avg_agents_density": 0.09578544334279979, "runtime": 0.2847704980522394}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1123, "makespan": 87, "avg_agents_density": 0.10370506855695213, "runtime": 0.5763850382936653}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 927, "makespan": 70, "avg_agents_density": 0.10779352151566911, "runtime": 0.5260439457488246}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 632, "makespan": 42, "avg_agents_density": 0.11156987465249993, "runtime": 0.5170180501008872}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1558, "makespan": 70, "avg_agents_density": 0.14426815896942416, "runtime": 2.076502758980496}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1889, "makespan": 75, "avg_agents_density": 0.15652182368926718, "runtime": 1.9130499399325345}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1725, "makespan": 128, "avg_agents_density": 0.13432785274923095, "runtime": 3.2676365319348406}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1518, "makespan": 53, "avg_agents_density": 0.17996768391214576, "runtime": 1.3499212359602097}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2728, "makespan": 128, "avg_agents_density": 0.1607505811338222, "runtime": 3.2672823198663536}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3803, "makespan": 128, "avg_agents_density": 0.15349449720713676, "runtime": 3.296345174952876}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 1747, "makespan": 114, "avg_agents_density": 0.13919591562096517, "runtime": 2.908701918000588}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.7916666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3972, "makespan": 128, "avg_agents_density": 0.16361479823396716, "runtime": 3.4907247920054942}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3149, "makespan": 128, "avg_agents_density": 0.1850168816919119, "runtime": 3.2724038849701174}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1982, "makespan": 73, "avg_agents_density": 0.1735490290676108, "runtime": 1.9095912480843253}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1513, "makespan": 70, "avg_agents_density": 0.13131246031794974, "runtime": 1.7864458390686195}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.4791666666666667, "CSR": 0.0, "ep_length": 128, "SoC": 4860, "makespan": 128, "avg_agents_density": 0.2922388771827361, "runtime": 3.353168335859664}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 1765, "makespan": 99, "avg_agents_density": 0.1568833043213592, "runtime": 2.5254068000649568}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1338, "makespan": 56, "avg_agents_density": 0.1534675365601188, "runtime": 1.5797043529746588}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1669, "makespan": 71, "avg_agents_density": 0.17138563626495662, "runtime": 1.8070091039407998}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3804, "makespan": 128, "avg_agents_density": 0.1801775784964221, "runtime": 3.4165181730350014}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2320, "makespan": 128, "avg_agents_density": 0.15486238948703446, "runtime": 3.222326707938919}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1280, "makespan": 51, "avg_agents_density": 0.12200797382344347, "runtime": 1.2648491929576267}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 4566, "makespan": 128, "avg_agents_density": 0.20043902794848747, "runtime": 3.259557392098941}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 128, "SoC": 5010, "makespan": 128, "avg_agents_density": 0.243379922652261, "runtime": 2.8389982800290454}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2720, "makespan": 128, "avg_agents_density": 0.15464978273252977, "runtime": 2.5636516219528858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 2834, "makespan": 113, "avg_agents_density": 0.18000840304279703, "runtime": 2.6679759533144534}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1340, "makespan": 66, "avg_agents_density": 0.14418356861375406, "runtime": 1.505082670133561}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2258, "makespan": 82, "avg_agents_density": 0.17789369161126983, "runtime": 1.8884757691703271}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3092, "makespan": 128, "avg_agents_density": 0.15021200650110006, "runtime": 3.2048084759444464}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 790, "makespan": 48, "avg_agents_density": 0.1306884501405945, "runtime": 1.2168656720314175}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1491, "makespan": 63, "avg_agents_density": 0.13410523790536732, "runtime": 1.6043157418316696}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1772, "makespan": 63, "avg_agents_density": 0.130873436305878, "runtime": 1.6031009338621516}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4035, "makespan": 128, "avg_agents_density": 0.16034055376188855, "runtime": 3.2659736676723696}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 3043, "makespan": 110, "avg_agents_density": 0.17337168709804726, "runtime": 2.7034530358214397}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 2819, "makespan": 94, "avg_agents_density": 0.17946952608090988, "runtime": 2.3957700808823574}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1028, "makespan": 46, "avg_agents_density": 0.14321907542402249, "runtime": 1.0542620498454198}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 3108, "makespan": 111, "avg_agents_density": 0.19016232759521426, "runtime": 3.846784538065549}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 5305, "makespan": 128, "avg_agents_density": 0.22444322954339085, "runtime": 4.519770326995058}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4665, "makespan": 128, "avg_agents_density": 0.20900048399236434, "runtime": 4.507402807095787}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3757, "makespan": 94, "avg_agents_density": 0.2231916583009059, "runtime": 3.240442629205063}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 6228, "makespan": 128, "avg_agents_density": 0.2630382847686302, "runtime": 4.219561844103737}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.484375, "CSR": 0.0, "ep_length": 128, "SoC": 7128, "makespan": 128, "avg_agents_density": 0.2720130765409084, "runtime": 4.425303149939282}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 4183, "makespan": 128, "avg_agents_density": 0.2071015575722487, "runtime": 4.056311183026992}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 7210, "makespan": 128, "avg_agents_density": 0.23820786752508338, "runtime": 4.003453314770013}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 4445, "makespan": 110, "avg_agents_density": 0.24367083683638718, "runtime": 3.4234007339400705}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 3655, "makespan": 97, "avg_agents_density": 0.23137898432323595, "runtime": 3.0360429888824}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 3775, "makespan": 128, "avg_agents_density": 0.17223766813236366, "runtime": 4.007672232633922}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 128, "SoC": 7612, "makespan": 128, "avg_agents_density": 0.41323503983347204, "runtime": 4.014576304325601}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 5418, "makespan": 128, "avg_agents_density": 0.23779000399410496, "runtime": 4.013988429971505}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 2731, "makespan": 116, "avg_agents_density": 0.19515813939431728, "runtime": 3.636556207027752}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4176, "makespan": 128, "avg_agents_density": 0.2178102491728004, "runtime": 4.4719166397699155}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 128, "SoC": 5960, "makespan": 128, "avg_agents_density": 0.275040978614901, "runtime": 4.0208155061118305}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 5935, "makespan": 128, "avg_agents_density": 0.23804791653994617, "runtime": 4.016205799125601}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2214, "makespan": 86, "avg_agents_density": 0.15509709939022523, "runtime": 2.696706373943016}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 128, "SoC": 6152, "makespan": 128, "avg_agents_density": 0.20572204271259883, "runtime": 3.664130848075729}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 128, "SoC": 6683, "makespan": 128, "avg_agents_density": 0.23672523257759773, "runtime": 3.7693613148585428}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4694, "makespan": 128, "avg_agents_density": 0.18927672162683984, "runtime": 3.6598515751829837}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 4069, "makespan": 118, "avg_agents_density": 0.20434988671136808, "runtime": 3.5144225341500714}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 3712, "makespan": 128, "avg_agents_density": 0.20962128917645367, "runtime": 3.6566805540642235}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 128, "SoC": 6209, "makespan": 128, "avg_agents_density": 0.2664839180775416, "runtime": 4.0123443129705265}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5302, "makespan": 128, "avg_agents_density": 0.1905902120111227, "runtime": 3.9217971221660264}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1042, "makespan": 36, "avg_agents_density": 0.17895409771858165, "runtime": 1.1259631380380597}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2146, "makespan": 59, "avg_agents_density": 0.17997745892976452, "runtime": 1.7484658590401523}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4246, "makespan": 128, "avg_agents_density": 0.16774567014235, "runtime": 4.013826319860527}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 5736, "makespan": 128, "avg_agents_density": 0.23380458113083594, "runtime": 4.000333742325893}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5215, "makespan": 128, "avg_agents_density": 0.2271341082609446, "runtime": 4.011604817031184}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3759, "makespan": 128, "avg_agents_density": 0.23130882817656348, "runtime": 4.001018507027766}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-16000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1490, "makespan": 48, "avg_agents_density": 0.18720026327781755, "runtime": 1.8352741948910989}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-16000"}]