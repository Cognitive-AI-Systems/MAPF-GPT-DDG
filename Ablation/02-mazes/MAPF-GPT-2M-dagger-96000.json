[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 734, "makespan": 52, "avg_agents_density": 0.09623280549705207, "runtime": 1.2982592929183738}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 890, "makespan": 41, "avg_agents_density": 0.12424552469376622, "runtime": 0.7720554720435757}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 1113, "makespan": 109, "avg_agents_density": 0.0842295668291888, "runtime": 2.2251107710326323}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 642, "makespan": 32, "avg_agents_density": 0.10701030998161605, "runtime": 0.9375552190322196}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 934, "makespan": 52, "avg_agents_density": 0.09693530700236118, "runtime": 1.84164219199738}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 981, "makespan": 42, "avg_agents_density": 0.11792006961158626, "runtime": 0.7594104060408426}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 747, "makespan": 52, "avg_agents_density": 0.09785124301174981, "runtime": 1.8607014538429212}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1244, "makespan": 79, "avg_agents_density": 0.1071144566911065, "runtime": 3.3047108079772443}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 945, "makespan": 47, "avg_agents_density": 0.11568187240759194, "runtime": 1.9073819019831717}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 736, "makespan": 41, "avg_agents_density": 0.1296782878005931, "runtime": 0.8450994219892891}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 771, "makespan": 46, "avg_agents_density": 0.08463930885026845, "runtime": 1.0025782380398596}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1557, "makespan": 128, "avg_agents_density": 0.13801025466725483, "runtime": 3.604123085984611}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 808, "makespan": 49, "avg_agents_density": 0.10582512259735667, "runtime": 1.836883058960666}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 697, "makespan": 36, "avg_agents_density": 0.11321136737621586, "runtime": 1.454492131000734}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 745, "makespan": 43, "avg_agents_density": 0.11673176101423403, "runtime": 0.7624757589946967}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 963, "makespan": 46, "avg_agents_density": 0.11423219012551505, "runtime": 0.7991585200361442}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 926, "makespan": 53, "avg_agents_density": 0.10607500691436465, "runtime": 1.611197633043048}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 679, "makespan": 42, "avg_agents_density": 0.09032085615737173, "runtime": 1.2529186580795795}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1208, "makespan": 66, "avg_agents_density": 0.12424642868516747, "runtime": 1.9593308989860816}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 1293, "makespan": 84, "avg_agents_density": 0.10638695983909223, "runtime": 1.0677823839796474}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 847, "makespan": 48, "avg_agents_density": 0.09191454943897963, "runtime": 0.9545699449954554}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 922, "makespan": 51, "avg_agents_density": 0.12159046179702328, "runtime": 1.1212763680086937}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 664, "makespan": 41, "avg_agents_density": 0.09840789791584821, "runtime": 0.9665611579839606}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 743, "makespan": 39, "avg_agents_density": 0.12026713709114598, "runtime": 1.217847982989042}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 840, "makespan": 62, "avg_agents_density": 0.1003917769039509, "runtime": 1.847759146039607}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 430, "makespan": 37, "avg_agents_density": 0.08988047214734411, "runtime": 1.0565167690074304}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 669, "makespan": 40, "avg_agents_density": 0.0936605799220354, "runtime": 1.120814388996223}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 902, "makespan": 43, "avg_agents_density": 0.09131247758846306, "runtime": 0.8178986600105418}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1107, "makespan": 59, "avg_agents_density": 0.09049765199249381, "runtime": 0.38104090800334234}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1109, "makespan": 60, "avg_agents_density": 0.10662903229265439, "runtime": 1.0554563270125072}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 714, "makespan": 34, "avg_agents_density": 0.11414276579435713, "runtime": 0.5935214039927814}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 540, "makespan": 31, "avg_agents_density": 0.1119954683715833, "runtime": 0.5607419549342012}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1586, "makespan": 69, "avg_agents_density": 0.13906494788698834, "runtime": 2.8606362560240086}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1776, "makespan": 66, "avg_agents_density": 0.15522206080822018, "runtime": 2.9439504940237384}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 1717, "makespan": 108, "avg_agents_density": 0.1325632796922403, "runtime": 4.619386791047873}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1395, "makespan": 52, "avg_agents_density": 0.16966046032972926, "runtime": 2.160456138983136}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1606, "makespan": 59, "avg_agents_density": 0.15506342250504698, "runtime": 2.4336662229907233}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2483, "makespan": 89, "avg_agents_density": 0.15357310497798812, "runtime": 3.627579421925475}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1236, "makespan": 42, "avg_agents_density": 0.1513528993220855, "runtime": 1.7341221560636768}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2918, "makespan": 88, "avg_agents_density": 0.16066359442179806, "runtime": 3.4933223039406585}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1723, "makespan": 56, "avg_agents_density": 0.16627801512859786, "runtime": 2.4454549760266673}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1650, "makespan": 50, "avg_agents_density": 0.19094246947943244, "runtime": 1.9395310370309744}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1534, "makespan": 80, "avg_agents_density": 0.12663876689914547, "runtime": 3.2617765580362175}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 128, "SoC": 4050, "makespan": 128, "avg_agents_density": 0.3035914514183168, "runtime": 5.244287542998791}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1632, "makespan": 66, "avg_agents_density": 0.1636065718479264, "runtime": 2.586318028974347}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1404, "makespan": 61, "avg_agents_density": 0.15217557103055587, "runtime": 2.4536119700060226}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1627, "makespan": 80, "avg_agents_density": 0.1637827355224665, "runtime": 3.496630731096957}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1769, "makespan": 60, "avg_agents_density": 0.164844293865241, "runtime": 2.4411040280974703}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1406, "makespan": 46, "avg_agents_density": 0.17278385774424943, "runtime": 1.9878465029469226}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1356, "makespan": 60, "avg_agents_density": 0.1243208354139927, "runtime": 2.591802452909178}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 2431, "makespan": 98, "avg_agents_density": 0.154354589024693, "runtime": 4.155567163004889}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4548, "makespan": 128, "avg_agents_density": 0.1902435178553078, "runtime": 4.141016234876588}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1702, "makespan": 69, "avg_agents_density": 0.1459956818237693, "runtime": 2.1193495209445246}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2029, "makespan": 86, "avg_agents_density": 0.1634005481853305, "runtime": 3.4695966959989164}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1075, "makespan": 43, "avg_agents_density": 0.15088817724766737, "runtime": 1.790639907005243}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1875, "makespan": 82, "avg_agents_density": 0.16336325065021567, "runtime": 2.4754409449960804}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2245, "makespan": 81, "avg_agents_density": 0.15144128672948176, "runtime": 3.6168360529263737}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 714, "makespan": 36, "avg_agents_density": 0.13177372896712508, "runtime": 1.4500663319631713}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1124, "makespan": 43, "avg_agents_density": 0.13118735062356066, "runtime": 1.7492148419405567}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2012, "makespan": 74, "avg_agents_density": 0.13801191286338552, "runtime": 2.6624630699807312}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2207, "makespan": 89, "avg_agents_density": 0.14233611930641393, "runtime": 3.642200596994371}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2200, "makespan": 82, "avg_agents_density": 0.16016002044999517, "runtime": 2.8364272870094283}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1739, "makespan": 67, "avg_agents_density": 0.17859645814109396, "runtime": 2.763280573009979}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 805, "makespan": 30, "avg_agents_density": 0.14523457031451176, "runtime": 1.2743474370217882}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 2954, "makespan": 100, "avg_agents_density": 0.17928234087964068, "runtime": 5.220082312953309}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 3231, "makespan": 70, "avg_agents_density": 0.21592907757420118, "runtime": 3.7898641379579203}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3328, "makespan": 102, "avg_agents_density": 0.19485922117412455, "runtime": 4.937240748055046}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2318, "makespan": 60, "avg_agents_density": 0.1966357065049986, "runtime": 3.2842935520602623}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 4131, "makespan": 118, "avg_agents_density": 0.23179083215991306, "runtime": 6.097061110966024}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 4434, "makespan": 122, "avg_agents_density": 0.2007339474300021, "runtime": 6.310462133973488}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 127, "SoC": 4060, "makespan": 127, "avg_agents_density": 0.19386055315653067, "runtime": 5.810632917040493}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 6263, "makespan": 128, "avg_agents_density": 0.21306073640255285, "runtime": 6.089970143875689}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 3106, "makespan": 82, "avg_agents_density": 0.2078095820267791, "runtime": 3.7766231749701547}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2445, "makespan": 61, "avg_agents_density": 0.2170802169553785, "runtime": 2.9313630209799157}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 4075, "makespan": 115, "avg_agents_density": 0.18140277763389462, "runtime": 5.409530325981905}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.296875, "CSR": 0.0, "ep_length": 128, "SoC": 7132, "makespan": 128, "avg_agents_density": 0.36527711201861657, "runtime": 5.961536953880568}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4004, "makespan": 128, "avg_agents_density": 0.20583721742891364, "runtime": 5.953936835983768}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2329, "makespan": 68, "avg_agents_density": 0.19506238390869352, "runtime": 3.1848915839073015}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2461, "makespan": 80, "avg_agents_density": 0.20365151160662281, "runtime": 4.425413878969266}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2900, "makespan": 85, "avg_agents_density": 0.20470402808035335, "runtime": 3.5070919110585237}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4814, "makespan": 128, "avg_agents_density": 0.20750238586817096, "runtime": 5.712984670972219}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2136, "makespan": 68, "avg_agents_density": 0.15315251373136257, "runtime": 2.404829008024535}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 5885, "makespan": 128, "avg_agents_density": 0.1848748841703981, "runtime": 5.150805268087424}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 6812, "makespan": 128, "avg_agents_density": 0.2322871014040061, "runtime": 5.260376433987403}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3843, "makespan": 128, "avg_agents_density": 0.19552514441972682, "runtime": 5.19308089299011}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 3193, "makespan": 81, "avg_agents_density": 0.19660166956834696, "runtime": 3.0434424520208267}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1819, "makespan": 52, "avg_agents_density": 0.1910814845419757, "runtime": 2.1129269740195014}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2889, "makespan": 128, "avg_agents_density": 0.18507887580848012, "runtime": 4.975346418024856}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4004, "makespan": 128, "avg_agents_density": 0.19332696409373848, "runtime": 5.006546707023517}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1041, "makespan": 41, "avg_agents_density": 0.17375980723085155, "runtime": 1.9095938870013924}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2150, "makespan": 57, "avg_agents_density": 0.16933156464036503, "runtime": 2.30290350598807}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 3389, "makespan": 104, "avg_agents_density": 0.17670238679503492, "runtime": 3.927234060916817}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4332, "makespan": 128, "avg_agents_density": 0.1946715235152408, "runtime": 5.270274824069929}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3578, "makespan": 92, "avg_agents_density": 0.21777140567541786, "runtime": 3.6370944509544643}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3744, "makespan": 128, "avg_agents_density": 0.22164373716038355, "runtime": 6.161169780025375}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1642, "makespan": 54, "avg_agents_density": 0.18861522001483014, "runtime": 3.2731857229955494}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-96000"}]