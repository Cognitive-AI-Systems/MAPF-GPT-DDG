[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 715, "makespan": 34, "avg_agents_density": 0.09677298710880458, "runtime": 0.8311794029432349}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 885, "makespan": 49, "avg_agents_density": 0.12222039923318503, "runtime": 0.44323994702426717}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 1147, "makespan": 116, "avg_agents_density": 0.08191982239213147, "runtime": 1.052818682976067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 703, "makespan": 35, "avg_agents_density": 0.10843770364860623, "runtime": 0.8288635548087768}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 907, "makespan": 51, "avg_agents_density": 0.10619111957279861, "runtime": 1.168405976262875}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1038, "makespan": 48, "avg_agents_density": 0.10890839016467957, "runtime": 1.0743094108183868}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 774, "makespan": 62, "avg_agents_density": 0.09767022365827739, "runtime": 1.3185780150815845}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1301, "makespan": 60, "avg_agents_density": 0.10613731999942179, "runtime": 1.5352846399182454}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 975, "makespan": 53, "avg_agents_density": 0.11525042450460667, "runtime": 1.2399999531917274}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 674, "makespan": 42, "avg_agents_density": 0.12877594649325572, "runtime": 0.6237553577520885}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 869, "makespan": 53, "avg_agents_density": 0.09080587591515019, "runtime": 0.4557690928922966}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1697, "makespan": 128, "avg_agents_density": 0.13741134544990602, "runtime": 1.6662447130656801}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 828, "makespan": 44, "avg_agents_density": 0.10562574126532609, "runtime": 1.0783568092156202}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 639, "makespan": 34, "avg_agents_density": 0.10626470203609102, "runtime": 0.8321419929852709}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 836, "makespan": 42, "avg_agents_density": 0.12495701993024237, "runtime": 0.8691404589335434}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1031, "makespan": 60, "avg_agents_density": 0.11199852859564646, "runtime": 0.5961975409300067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1004, "makespan": 50, "avg_agents_density": 0.10229688106158816, "runtime": 0.8728040590067394}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 692, "makespan": 43, "avg_agents_density": 0.0868124015896991, "runtime": 0.9001658190391026}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1064, "makespan": 53, "avg_agents_density": 0.11679540173720789, "runtime": 1.1021265037707053}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1298, "makespan": 54, "avg_agents_density": 0.12765337470276492, "runtime": 0.25375748792430386}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1006, "makespan": 56, "avg_agents_density": 0.08932374410187968, "runtime": 0.5416355341440067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1109, "makespan": 58, "avg_agents_density": 0.11329413856005674, "runtime": 0.5932864369242452}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 663, "makespan": 38, "avg_agents_density": 0.09692398433014093, "runtime": 0.7085934049100615}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1004, "makespan": 66, "avg_agents_density": 0.11512129977481425, "runtime": 1.7824182150652632}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 919, "makespan": 49, "avg_agents_density": 0.10295228664602864, "runtime": 1.2113171159871854}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 443, "makespan": 30, "avg_agents_density": 0.09349158449713298, "runtime": 0.42208009579917416}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 778, "makespan": 40, "avg_agents_density": 0.09496730220304764, "runtime": 0.8919251363840885}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1036, "makespan": 58, "avg_agents_density": 0.08477418693569462, "runtime": 0.9987057030084543}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1149, "makespan": 62, "avg_agents_density": 0.0907860182152449, "runtime": 0.20024630491388962}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 909, "makespan": 42, "avg_agents_density": 0.1097882156395693, "runtime": 0.290926895046141}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1006, "makespan": 49, "avg_agents_density": 0.11722328902864014, "runtime": 0.4251313589629717}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 534, "makespan": 28, "avg_agents_density": 0.11785266242799049, "runtime": 0.45930505223805085}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2034, "makespan": 75, "avg_agents_density": 0.151992139306693, "runtime": 2.3736581532284617}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1800, "makespan": 75, "avg_agents_density": 0.15595075660697155, "runtime": 2.0308200019644573}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1696, "makespan": 128, "avg_agents_density": 0.13198053216408673, "runtime": 3.314616271003615}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1350, "makespan": 56, "avg_agents_density": 0.16291372551055372, "runtime": 1.5604571160511114}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1757, "makespan": 72, "avg_agents_density": 0.14734513914801128, "runtime": 1.964222463837359}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2768, "makespan": 87, "avg_agents_density": 0.16138326698138492, "runtime": 2.2779310739133507}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1699, "makespan": 60, "avg_agents_density": 0.14936698028233947, "runtime": 1.678400099161081}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3790, "makespan": 128, "avg_agents_density": 0.16255291739491767, "runtime": 3.56284174422035}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1653, "makespan": 50, "avg_agents_density": 0.16902086360453103, "runtime": 1.3162157390033826}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1959, "makespan": 72, "avg_agents_density": 0.17597808847162572, "runtime": 1.9044442236190662}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 2451, "makespan": 116, "avg_agents_density": 0.14495429034784038, "runtime": 3.16741340624867}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 4133, "makespan": 128, "avg_agents_density": 0.22123764511562716, "runtime": 3.5470079185906798}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1820, "makespan": 59, "avg_agents_density": 0.16698498638381684, "runtime": 1.5240610948530957}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1399, "makespan": 54, "avg_agents_density": 0.15154094376338992, "runtime": 1.4854676728718914}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1501, "makespan": 56, "avg_agents_density": 0.17858740066344939, "runtime": 1.5077840499579906}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2044, "makespan": 61, "avg_agents_density": 0.16680437184533367, "runtime": 1.8673227020772174}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2201, "makespan": 82, "avg_agents_density": 0.16797961518827703, "runtime": 2.352040164580103}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1276, "makespan": 49, "avg_agents_density": 0.12342962419531328, "runtime": 1.3027915628626943}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2314, "makespan": 87, "avg_agents_density": 0.1536358347296851, "runtime": 2.3110113221337087}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 124, "SoC": 3619, "makespan": 124, "avg_agents_density": 0.17647594349932177, "runtime": 2.62039889045991}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1882, "makespan": 73, "avg_agents_density": 0.1453438392325496, "runtime": 1.308587958861608}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2046, "makespan": 70, "avg_agents_density": 0.1663996349479282, "runtime": 1.5754105829400942}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1104, "makespan": 41, "avg_agents_density": 0.14704215081870314, "runtime": 1.0936766376253217}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1553, "makespan": 58, "avg_agents_density": 0.16439045718620196, "runtime": 1.6358845548820682}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1656, "makespan": 64, "avg_agents_density": 0.1511454400756436, "runtime": 1.7410658771987073}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 653, "makespan": 30, "avg_agents_density": 0.13703074389150766, "runtime": 0.8114700507721864}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1085, "makespan": 46, "avg_agents_density": 0.13069702417709095, "runtime": 1.3177007759804837}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2222, "makespan": 78, "avg_agents_density": 0.13713271560810064, "runtime": 2.1640482112998143}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3428, "makespan": 128, "avg_agents_density": 0.14877126354243708, "runtime": 3.425624367140699}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1996, "makespan": 60, "avg_agents_density": 0.15998592049575774, "runtime": 1.3400037350365892}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1780, "makespan": 69, "avg_agents_density": 0.1780536738101743, "runtime": 1.8302067820332013}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 960, "makespan": 37, "avg_agents_density": 0.15029967224838914, "runtime": 0.9394045270164497}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4250, "makespan": 128, "avg_agents_density": 0.1865198040450979, "runtime": 4.624875985144172}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3478, "makespan": 92, "avg_agents_density": 0.20212430681448088, "runtime": 3.3936047038878314}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3293, "makespan": 128, "avg_agents_density": 0.1902829671566292, "runtime": 4.476695627090521}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2242, "makespan": 63, "avg_agents_density": 0.20271378099027354, "runtime": 2.3618287830031477}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 3531, "makespan": 96, "avg_agents_density": 0.21350917219702714, "runtime": 3.478008573700208}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.515625, "CSR": 0.0, "ep_length": 128, "SoC": 6950, "makespan": 128, "avg_agents_density": 0.2273237535048484, "runtime": 4.653734687482938}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 4055, "makespan": 128, "avg_agents_density": 0.20309933091663684, "runtime": 4.2745220126817}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 6815, "makespan": 128, "avg_agents_density": 0.20859852782543042, "runtime": 4.19974162633298}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3659, "makespan": 92, "avg_agents_density": 0.22407375007559865, "runtime": 2.9810396752436645}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3315, "makespan": 128, "avg_agents_density": 0.21613690301478566, "runtime": 4.343764716584701}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 5710, "makespan": 128, "avg_agents_density": 0.19409112448409727, "runtime": 4.165220091759693}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.234375, "CSR": 0.0, "ep_length": 128, "SoC": 7450, "makespan": 128, "avg_agents_density": 0.41505406617045026, "runtime": 4.19537434715312}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3196, "makespan": 128, "avg_agents_density": 0.19757736709967866, "runtime": 4.282459714799188}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 2296, "makespan": 51, "avg_agents_density": 0.1921140917215533, "runtime": 1.6729187488672324}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 3423, "makespan": 111, "avg_agents_density": 0.20983223004923063, "runtime": 3.9816913231043145}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5016, "makespan": 128, "avg_agents_density": 0.22314744497212283, "runtime": 4.092166542948689}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.515625, "CSR": 0.0, "ep_length": 128, "SoC": 6839, "makespan": 128, "avg_agents_density": 0.2784976210522126, "runtime": 4.008510712941643}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 2108, "makespan": 51, "avg_agents_density": 0.15904954108600095, "runtime": 1.6068690213141963}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5263, "makespan": 128, "avg_agents_density": 0.19033724933891588, "runtime": 3.8864298377302475}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.703125, "CSR": 0.0, "ep_length": 128, "SoC": 7054, "makespan": 128, "avg_agents_density": 0.21536787931156243, "runtime": 3.8880350828403607}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4595, "makespan": 128, "avg_agents_density": 0.1869117064142485, "runtime": 3.6619806379894726}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 127, "SoC": 5499, "makespan": 127, "avg_agents_density": 0.2277853381326873, "runtime": 3.6992312613292597}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2838, "makespan": 81, "avg_agents_density": 0.21333872824113645, "runtime": 2.3496184454998}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4114, "makespan": 128, "avg_agents_density": 0.19854073615182571, "runtime": 4.0816993490443565}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3950, "makespan": 128, "avg_agents_density": 0.19435652197745054, "runtime": 4.021581356879324}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1190, "makespan": 46, "avg_agents_density": 0.178193632227179, "runtime": 1.484154884063173}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2308, "makespan": 70, "avg_agents_density": 0.17145182829059996, "runtime": 2.1822387499851175}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4042, "makespan": 128, "avg_agents_density": 0.17035341123999367, "runtime": 4.056400582776405}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 128, "SoC": 6441, "makespan": 128, "avg_agents_density": 0.28073966499325076, "runtime": 3.988023354904726}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 5523, "makespan": 128, "avg_agents_density": 0.2339721921346393, "runtime": 4.0741859918343835}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4073, "makespan": 128, "avg_agents_density": 0.22782802709003502, "runtime": 4.077958155656233}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1792, "makespan": 50, "avg_agents_density": 0.19441628495290422, "runtime": 2.077502201369498}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-32000"}]