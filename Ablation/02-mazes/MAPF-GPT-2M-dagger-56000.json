[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 659, "makespan": 33, "avg_agents_density": 0.09745330323210125, "runtime": 0.8778174079780001}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 749, "makespan": 43, "avg_agents_density": 0.12156491131527301, "runtime": 0.7912712299876148}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 994, "makespan": 117, "avg_agents_density": 0.08237684551882206, "runtime": 1.7695762669172836}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 689, "makespan": 38, "avg_agents_density": 0.11263276909919892, "runtime": 1.8085215889732353}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 825, "makespan": 47, "avg_agents_density": 0.10824723974571271, "runtime": 1.4961209549510386}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 974, "makespan": 56, "avg_agents_density": 0.10877546373838294, "runtime": 1.822394719987642}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 784, "makespan": 53, "avg_agents_density": 0.09716066400554439, "runtime": 1.848944814017159}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1396, "makespan": 67, "avg_agents_density": 0.11702603078627681, "runtime": 3.1541299399978016}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 949, "makespan": 45, "avg_agents_density": 0.11551892665270211, "runtime": 1.9031827059516218}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 676, "makespan": 35, "avg_agents_density": 0.12893637705507457, "runtime": 0.3817971510143252}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 840, "makespan": 52, "avg_agents_density": 0.08916311904870879, "runtime": 1.1481166720332112}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1127, "makespan": 62, "avg_agents_density": 0.15216602171029983, "runtime": 1.6642821279674536}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 754, "makespan": 41, "avg_agents_density": 0.10773417116219729, "runtime": 1.5699177809874527}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 687, "makespan": 42, "avg_agents_density": 0.10785275887969119, "runtime": 1.381897059007315}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 683, "makespan": 39, "avg_agents_density": 0.11776040964938386, "runtime": 0.9182775039953412}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 761, "makespan": 38, "avg_agents_density": 0.10847162664385329, "runtime": 0.4000639030127786}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 857, "makespan": 50, "avg_agents_density": 0.10921379184390194, "runtime": 1.280291390939965}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 667, "makespan": 44, "avg_agents_density": 0.09008375248317964, "runtime": 1.065620703942841}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1126, "makespan": 50, "avg_agents_density": 0.12303034468623406, "runtime": 2.1257622240518685}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 1343, "makespan": 113, "avg_agents_density": 0.10745174235452279, "runtime": 0.8445300469029462}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 863, "makespan": 44, "avg_agents_density": 0.09280240992430791, "runtime": 0.49158135399920866}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 966, "makespan": 48, "avg_agents_density": 0.12559432632539158, "runtime": 0.4407939199882094}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 682, "makespan": 38, "avg_agents_density": 0.09921299052840722, "runtime": 0.8032111259672092}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 730, "makespan": 41, "avg_agents_density": 0.1110522589483564, "runtime": 1.51114997798868}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 912, "makespan": 44, "avg_agents_density": 0.1028551063551559, "runtime": 1.5506686469889246}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 427, "makespan": 31, "avg_agents_density": 0.09153521312815305, "runtime": 0.6557826420030324}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 841, "makespan": 46, "avg_agents_density": 0.09660692181979308, "runtime": 0.866320626999368}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1050, "makespan": 58, "avg_agents_density": 0.08853817883836396, "runtime": 1.9804568200052017}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1261, "makespan": 75, "avg_agents_density": 0.09222536126583726, "runtime": 0.4093380401027389}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1136, "makespan": 63, "avg_agents_density": 0.10487102572257118, "runtime": 0.5622685340640601}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 621, "makespan": 28, "avg_agents_density": 0.11610137672824482, "runtime": 0.2788076160213677}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 574, "makespan": 29, "avg_agents_density": 0.11560014370811796, "runtime": 0.38275574195722584}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1675, "makespan": 83, "avg_agents_density": 0.14146917240065676, "runtime": 3.4059666059329174}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1852, "makespan": 66, "avg_agents_density": 0.14986417235071184, "runtime": 3.0548411639902042}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1221, "makespan": 46, "avg_agents_density": 0.14424018326279955, "runtime": 1.657536024969886}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1395, "makespan": 46, "avg_agents_density": 0.16518902860894558, "runtime": 2.0259528670139844}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1432, "makespan": 57, "avg_agents_density": 0.15207858478744687, "runtime": 1.9424193510203622}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2487, "makespan": 128, "avg_agents_density": 0.14959764696083613, "runtime": 4.528424895004719}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1415, "makespan": 57, "avg_agents_density": 0.1455655032110241, "runtime": 1.9693980089505203}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 2767, "makespan": 100, "avg_agents_density": 0.17217594116139442, "runtime": 3.4028352630120935}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2003, "makespan": 75, "avg_agents_density": 0.1724825613733599, "runtime": 2.5371173590247054}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1264, "makespan": 45, "avg_agents_density": 0.17463088671372998, "runtime": 1.7812047870393144}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1761, "makespan": 76, "avg_agents_density": 0.13445840418823288, "runtime": 2.6408969999174587}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 3950, "makespan": 128, "avg_agents_density": 0.22249924265199628, "runtime": 4.563363032109919}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1805, "makespan": 71, "avg_agents_density": 0.1647944063513493, "runtime": 2.9177597729867557}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1413, "makespan": 50, "avg_agents_density": 0.15337679304478913, "runtime": 1.7564657400216674}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1320, "makespan": 47, "avg_agents_density": 0.17249526296077092, "runtime": 1.745201653946424}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1498, "makespan": 51, "avg_agents_density": 0.1575976462957424, "runtime": 1.7206531629926758}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1771, "makespan": 51, "avg_agents_density": 0.1734629848059124, "runtime": 2.0578106620087055}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1095, "makespan": 51, "avg_agents_density": 0.12229418726469093, "runtime": 1.675213985989103}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3232, "makespan": 102, "avg_agents_density": 0.1802837163707568, "runtime": 3.93029876309447}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4097, "makespan": 128, "avg_agents_density": 0.1926560477884581, "runtime": 3.234715202037478}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2169, "makespan": 128, "avg_agents_density": 0.1441809904370202, "runtime": 5.009907175102853}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1762, "makespan": 53, "avg_agents_density": 0.16414047541705695, "runtime": 1.89096547702502}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1526, "makespan": 66, "avg_agents_density": 0.15876665148557673, "runtime": 2.4567964790621772}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1889, "makespan": 69, "avg_agents_density": 0.16241374125059535, "runtime": 2.7104551719967276}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1868, "makespan": 82, "avg_agents_density": 0.15486883365388757, "runtime": 3.7980732710129814}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 738, "makespan": 29, "avg_agents_density": 0.1395728289405606, "runtime": 1.1684831860329723}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1474, "makespan": 52, "avg_agents_density": 0.13442985412904015, "runtime": 1.7554801830265205}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2214, "makespan": 102, "avg_agents_density": 0.13418857465356, "runtime": 4.346494828962022}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2238, "makespan": 86, "avg_agents_density": 0.14724542901237758, "runtime": 3.3944567948783515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1989, "makespan": 64, "avg_agents_density": 0.17016748708842552, "runtime": 2.6811095989251044}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1575, "makespan": 50, "avg_agents_density": 0.1804807614869165, "runtime": 2.224553509047837}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 820, "makespan": 33, "avg_agents_density": 0.14276896125400965, "runtime": 1.6126683609909378}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2384, "makespan": 56, "avg_agents_density": 0.19254365562733286, "runtime": 2.3828747500519967}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 3038, "makespan": 74, "avg_agents_density": 0.21922924159598126, "runtime": 3.053545681977994}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5299, "makespan": 128, "avg_agents_density": 0.22119517695110305, "runtime": 4.6156061479850905}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2640, "makespan": 89, "avg_agents_density": 0.19746457115439597, "runtime": 3.8183041750162374}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 3272, "makespan": 96, "avg_agents_density": 0.2129192776296305, "runtime": 2.5847550989419688}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5358, "makespan": 128, "avg_agents_density": 0.198897748633136, "runtime": 4.875770956030465}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2389, "makespan": 76, "avg_agents_density": 0.1839686670927708, "runtime": 2.7595734429341974}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 128, "SoC": 6903, "makespan": 128, "avg_agents_density": 0.27913973744000153, "runtime": 5.248669702006737}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 4773, "makespan": 128, "avg_agents_density": 0.2279044907078212, "runtime": 5.301702389057027}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2927, "makespan": 128, "avg_agents_density": 0.21507680807011254, "runtime": 5.2662322360120015}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4585, "makespan": 128, "avg_agents_density": 0.1886138675107043, "runtime": 5.397720151042449}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 128, "SoC": 7145, "makespan": 128, "avg_agents_density": 0.39310174203736187, "runtime": 5.3439884340332355}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 3142, "makespan": 88, "avg_agents_density": 0.20293450506224223, "runtime": 3.2314569380541798}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2488, "makespan": 67, "avg_agents_density": 0.19735787209193956, "runtime": 2.9543046379403677}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2715, "makespan": 65, "avg_agents_density": 0.22720990208764702, "runtime": 2.7368935619597323}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2947, "makespan": 75, "avg_agents_density": 0.20137644715374772, "runtime": 2.9670620369142853}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 6240, "makespan": 128, "avg_agents_density": 0.2382582319420063, "runtime": 5.382437451960868}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1999, "makespan": 52, "avg_agents_density": 0.15789900637125076, "runtime": 2.1223449450335465}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 5037, "makespan": 128, "avg_agents_density": 0.18817687842732292, "runtime": 5.088328561047092}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 128, "SoC": 7037, "makespan": 128, "avg_agents_density": 0.21080862002965003, "runtime": 4.610436799019226}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3032, "makespan": 84, "avg_agents_density": 0.18412627119918368, "runtime": 2.871933299145894}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 3510, "makespan": 98, "avg_agents_density": 0.19812951985099328, "runtime": 3.2944061270100065}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 2206, "makespan": 51, "avg_agents_density": 0.1954134171499292, "runtime": 2.220656016957946}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2841, "makespan": 85, "avg_agents_density": 0.20421830706058672, "runtime": 3.482306298086769}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3574, "makespan": 128, "avg_agents_density": 0.2020452462545015, "runtime": 5.214890494054998}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 1041, "makespan": 32, "avg_agents_density": 0.18325285635081756, "runtime": 1.2437561930855736}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2650, "makespan": 83, "avg_agents_density": 0.18181151006808113, "runtime": 3.3739148209861014}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 3326, "makespan": 126, "avg_agents_density": 0.16962143116484435, "runtime": 5.219847039959859}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 0.671875, "CSR": 0.0, "ep_length": 128, "SoC": 6350, "makespan": 128, "avg_agents_density": 0.2330413210640723, "runtime": 5.202535008094856}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 3287, "makespan": 83, "avg_agents_density": 0.2153955688397828, "runtime": 3.651613784066285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 3438, "makespan": 90, "avg_agents_density": 0.2277579567162153, "runtime": 3.4941271130082896}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1645, "makespan": 50, "avg_agents_density": 0.19809897276123825, "runtime": 2.0214251550205518}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-56000"}]