[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 789, "makespan": 54, "avg_agents_density": 0.09609561766918055, "runtime": 1.4313765290280571}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 770, "makespan": 46, "avg_agents_density": 0.1192620545813792, "runtime": 1.2668594109418336}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 906, "makespan": 60, "avg_agents_density": 0.08462929881915876, "runtime": 1.7372956381150289}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 787, "makespan": 45, "avg_agents_density": 0.10806155087555923, "runtime": 1.559290689008776}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 817, "makespan": 46, "avg_agents_density": 0.10627697743505603, "runtime": 1.7236632669810206}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1040, "makespan": 50, "avg_agents_density": 0.10999428498543795, "runtime": 1.6712742139061447}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 889, "makespan": 75, "avg_agents_density": 0.09273880574340164, "runtime": 2.446661166002741}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1320, "makespan": 68, "avg_agents_density": 0.11390883626993731, "runtime": 2.3709867040306563}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 952, "makespan": 47, "avg_agents_density": 0.10796913636434674, "runtime": 1.8777448749460746}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 651, "makespan": 41, "avg_agents_density": 0.12330700897871358, "runtime": 0.4591306660004193}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 791, "makespan": 44, "avg_agents_density": 0.08799657361271031, "runtime": 1.3761110350169474}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 1447, "makespan": 118, "avg_agents_density": 0.12656096414117982, "runtime": 4.3154879291396355}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 778, "makespan": 41, "avg_agents_density": 0.11141387452527479, "runtime": 1.408413765966543}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 664, "makespan": 43, "avg_agents_density": 0.10890610290068738, "runtime": 1.6063967769878218}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 665, "makespan": 35, "avg_agents_density": 0.12484069394026924, "runtime": 1.077482352993684}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 911, "makespan": 41, "avg_agents_density": 0.12058515754161807, "runtime": 0.5069771599810338}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1044, "makespan": 62, "avg_agents_density": 0.11086884032274323, "runtime": 1.5924844689870952}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 748, "makespan": 45, "avg_agents_density": 0.08513315337209823, "runtime": 1.4021035880286945}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1175, "makespan": 82, "avg_agents_density": 0.11729178649952057, "runtime": 2.887789512096788}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1238, "makespan": 68, "avg_agents_density": 0.12309282409942578, "runtime": 1.1886000210652128}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 1039, "makespan": 113, "avg_agents_density": 0.09238567473880978, "runtime": 1.8027281058894005}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 996, "makespan": 75, "avg_agents_density": 0.10978768614203542, "runtime": 0.9339141900418326}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 616, "makespan": 34, "avg_agents_density": 0.09402022767715203, "runtime": 0.8479294179996941}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 801, "makespan": 51, "avg_agents_density": 0.11059757996647705, "runtime": 1.8828495780326193}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 895, "makespan": 72, "avg_agents_density": 0.1010459885765529, "runtime": 2.3446673158323392}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 426, "makespan": 31, "avg_agents_density": 0.09272321178728356, "runtime": 0.61273996901582}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 735, "makespan": 36, "avg_agents_density": 0.10038719786943615, "runtime": 0.897020412972779}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 970, "makespan": 60, "avg_agents_density": 0.0905001035878762, "runtime": 1.802310722952825}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1288, "makespan": 92, "avg_agents_density": 0.09147618750168707, "runtime": 1.2324876929924358}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 917, "makespan": 53, "avg_agents_density": 0.10471876452374634, "runtime": 0.803144036050071}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 743, "makespan": 41, "avg_agents_density": 0.1129447805732244, "runtime": 0.30388589203357697}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 544, "makespan": 30, "avg_agents_density": 0.1112631575150018, "runtime": 0.599062870038324}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1577, "makespan": 50, "avg_agents_density": 0.14729553302332019, "runtime": 1.8550153830001364}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2035, "makespan": 69, "avg_agents_density": 0.15775773587332478, "runtime": 2.5271885929541895}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1388, "makespan": 77, "avg_agents_density": 0.13972955302100618, "runtime": 2.789841694975621}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1270, "makespan": 46, "avg_agents_density": 0.15950224986982015, "runtime": 1.6632907050516224}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1568, "makespan": 55, "avg_agents_density": 0.15324700452890577, "runtime": 1.748882643005345}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2093, "makespan": 70, "avg_agents_density": 0.15925959660694006, "runtime": 2.5939445979893208}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1252, "makespan": 46, "avg_agents_density": 0.14281958509447287, "runtime": 1.6753592930181185}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2948, "makespan": 128, "avg_agents_density": 0.15942814075256379, "runtime": 4.431206356923212}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1622, "makespan": 57, "avg_agents_density": 0.17437142554893506, "runtime": 2.05383147696557}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1556, "makespan": 69, "avg_agents_density": 0.17028219592355676, "runtime": 2.527932580007473}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1823, "makespan": 83, "avg_agents_density": 0.14040249738447436, "runtime": 2.753594456065912}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2865, "makespan": 97, "avg_agents_density": 0.21894131425372135, "runtime": 3.315297478926368}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1347, "makespan": 45, "avg_agents_density": 0.16336372915717123, "runtime": 1.6574911980278557}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1385, "makespan": 57, "avg_agents_density": 0.14982877928603439, "runtime": 1.8149143559858203}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1438, "makespan": 51, "avg_agents_density": 0.17906215034730627, "runtime": 1.7713575410307385}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1818, "makespan": 63, "avg_agents_density": 0.16519325491574477, "runtime": 2.314906030005659}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1529, "makespan": 51, "avg_agents_density": 0.16024813988288342, "runtime": 1.7794842520233942}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1134, "makespan": 53, "avg_agents_density": 0.12197629679553365, "runtime": 1.9126237310119905}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 2576, "makespan": 103, "avg_agents_density": 0.16010776112887412, "runtime": 3.686286703014048}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3232, "makespan": 128, "avg_agents_density": 0.16214099633578016, "runtime": 3.084946917981142}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1841, "makespan": 79, "avg_agents_density": 0.14859850437633496, "runtime": 2.9939890360983554}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2018, "makespan": 65, "avg_agents_density": 0.16311966027226546, "runtime": 2.2788052470132243}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1085, "makespan": 40, "avg_agents_density": 0.14670250111836508, "runtime": 1.3391048529883847}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1580, "makespan": 58, "avg_agents_density": 0.16029885102944638, "runtime": 2.274559203069657}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1845, "makespan": 69, "avg_agents_density": 0.1607214437113462, "runtime": 2.4472848429868463}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 658, "makespan": 30, "avg_agents_density": 0.1328239447622662, "runtime": 1.0542880470165983}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1342, "makespan": 64, "avg_agents_density": 0.13113440506706783, "runtime": 2.057357648955076}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1746, "makespan": 61, "avg_agents_density": 0.13182143330593704, "runtime": 2.203319865031517}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 2683, "makespan": 106, "avg_agents_density": 0.1443271322650661, "runtime": 3.998683773970697}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1612, "makespan": 55, "avg_agents_density": 0.165109612601172, "runtime": 1.9203821520786732}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1383, "makespan": 43, "avg_agents_density": 0.17930730378236415, "runtime": 1.5177626649965532}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 896, "makespan": 32, "avg_agents_density": 0.15083770663898305, "runtime": 1.1602231350261718}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2387, "makespan": 59, "avg_agents_density": 0.18101511805075277, "runtime": 2.19861924496945}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 3250, "makespan": 80, "avg_agents_density": 0.21311206512275566, "runtime": 4.087204525014386}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2812, "makespan": 77, "avg_agents_density": 0.21393391530492797, "runtime": 4.507392028011964}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2284, "makespan": 73, "avg_agents_density": 0.1914135420856974, "runtime": 3.9783079889893997}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2891, "makespan": 86, "avg_agents_density": 0.20516712746793883, "runtime": 5.0433846439409535}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 4798, "makespan": 108, "avg_agents_density": 0.21736784938048043, "runtime": 5.949123838858213}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2979, "makespan": 83, "avg_agents_density": 0.19178437470137752, "runtime": 3.804002205011784}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5367, "makespan": 128, "avg_agents_density": 0.21102662461228958, "runtime": 5.357450033930945}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 3089, "makespan": 77, "avg_agents_density": 0.21002743110185434, "runtime": 3.4542931830510497}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2536, "makespan": 83, "avg_agents_density": 0.21571487347331342, "runtime": 3.6382195059850346}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 2707, "makespan": 90, "avg_agents_density": 0.17558885150428696, "runtime": 4.359253716043895}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.265625, "CSR": 0.0, "ep_length": 128, "SoC": 7068, "makespan": 128, "avg_agents_density": 0.37590532773419494, "runtime": 5.988898876006715}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2678, "makespan": 79, "avg_agents_density": 0.20245001407007995, "runtime": 3.8167554510437185}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2301, "makespan": 64, "avg_agents_density": 0.1944330233792028, "runtime": 3.2343088850029744}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3127, "makespan": 128, "avg_agents_density": 0.20682172201540672, "runtime": 6.883143088009092}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2796, "makespan": 73, "avg_agents_density": 0.20215126908923514, "runtime": 2.5648843870148994}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3914, "makespan": 128, "avg_agents_density": 0.20108253810469884, "runtime": 5.10273033696285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1900, "makespan": 56, "avg_agents_density": 0.15458525250050875, "runtime": 1.9795442469767295}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 5242, "makespan": 128, "avg_agents_density": 0.19466783036586566, "runtime": 4.492046495040995}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 128, "SoC": 6433, "makespan": 128, "avg_agents_density": 0.20792401930926274, "runtime": 4.331536669065827}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3792, "makespan": 128, "avg_agents_density": 0.18982361872493275, "runtime": 4.516004652032279}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 3014, "makespan": 68, "avg_agents_density": 0.2055884406351616, "runtime": 2.4398406640830217}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1629, "makespan": 56, "avg_agents_density": 0.1791213596105329, "runtime": 1.9616841960523743}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3445, "makespan": 128, "avg_agents_density": 0.19364418295032657, "runtime": 5.184922838117927}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4138, "makespan": 128, "avg_agents_density": 0.20376994249283628, "runtime": 4.525197603041306}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 1003, "makespan": 33, "avg_agents_density": 0.18469879426340655, "runtime": 1.3097881150461035}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1772, "makespan": 49, "avg_agents_density": 0.17584356047107375, "runtime": 1.7519186630815966}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3872, "makespan": 128, "avg_agents_density": 0.16831368853266354, "runtime": 4.654652744909981}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4747, "makespan": 128, "avg_agents_density": 0.20327054754256316, "runtime": 4.709497654883307}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2893, "makespan": 81, "avg_agents_density": 0.19485205373091227, "runtime": 3.0275754389731446}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 2866, "makespan": 128, "avg_agents_density": 0.22131174812596607, "runtime": 5.9682125170656946}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1563, "makespan": 52, "avg_agents_density": 0.19072285134416406, "runtime": 3.404801775002852}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-168000"}]