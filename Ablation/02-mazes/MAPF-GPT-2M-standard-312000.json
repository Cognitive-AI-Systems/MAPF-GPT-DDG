[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 601, "makespan": 32, "avg_agents_density": 0.09584339623839204, "runtime": 0.6126161360298283}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 686, "makespan": 33, "avg_agents_density": 0.12207819625212932, "runtime": 0.5293916629452724}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 717, "makespan": 53, "avg_agents_density": 0.08821018090964904, "runtime": 0.494852337957127}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 673, "makespan": 72, "avg_agents_density": 0.1059140414157446, "runtime": 1.3498666939558461}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 829, "makespan": 44, "avg_agents_density": 0.11157942817306979, "runtime": 0.9162752309348434}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 1359, "makespan": 100, "avg_agents_density": 0.10375008239012158, "runtime": 2.0058898047718685}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 733, "makespan": 50, "avg_agents_density": 0.09557884580949062, "runtime": 0.9731555189355277}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 1324, "makespan": 86, "avg_agents_density": 0.11289485702556547, "runtime": 1.8919148930290248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 877, "makespan": 50, "avg_agents_density": 0.11689917165542207, "runtime": 1.0235652599367313}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 667, "makespan": 40, "avg_agents_density": 0.13089239437402678, "runtime": 0.7429057941189967}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 859, "makespan": 55, "avg_agents_density": 0.08786482831867184, "runtime": 1.0770496030745562}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1091, "makespan": 69, "avg_agents_density": 0.14988332492126194, "runtime": 0.8940293920750264}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 739, "makespan": 61, "avg_agents_density": 0.1040312659034722, "runtime": 1.2714466360630468}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 600, "makespan": 39, "avg_agents_density": 0.11339240761892118, "runtime": 0.8580557169916574}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 859, "makespan": 51, "avg_agents_density": 0.12234106022990877, "runtime": 0.7580148089909926}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 901, "makespan": 51, "avg_agents_density": 0.1074152066264833, "runtime": 0.7266383130627219}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 851, "makespan": 61, "avg_agents_density": 0.10256828574197592, "runtime": 0.89653802086832}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 738, "makespan": 44, "avg_agents_density": 0.09494636235436973, "runtime": 0.8853868989390321}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1105, "makespan": 61, "avg_agents_density": 0.12435166095565271, "runtime": 0.8495005709992256}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 1723, "makespan": 106, "avg_agents_density": 0.11545404620537628, "runtime": 0.5206403041665908}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 940, "makespan": 62, "avg_agents_density": 0.09274615292681294, "runtime": 0.8405434588203207}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 862, "makespan": 42, "avg_agents_density": 0.1108082532990279, "runtime": 0.5212969760177657}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 602, "makespan": 38, "avg_agents_density": 0.09415053449337603, "runtime": 0.5061815139197279}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 732, "makespan": 49, "avg_agents_density": 0.11038078153847657, "runtime": 1.045975048065884}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 787, "makespan": 52, "avg_agents_density": 0.10295415329521337, "runtime": 1.0525777660368476}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 434, "makespan": 30, "avg_agents_density": 0.09655676679984167, "runtime": 0.40142722605378367}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 646, "makespan": 39, "avg_agents_density": 0.09610488991432685, "runtime": 0.6930619189806748}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 884, "makespan": 70, "avg_agents_density": 0.08710726093474794, "runtime": 0.7416683320188895}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1149, "makespan": 62, "avg_agents_density": 0.08923873983407513, "runtime": 0.18182767493999563}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 942, "makespan": 99, "avg_agents_density": 0.10464533607735493, "runtime": 0.8889409279508982}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 702, "makespan": 117, "avg_agents_density": 0.10376900222658948, "runtime": 0.8924645957886241}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 529, "makespan": 27, "avg_agents_density": 0.11206707204704094, "runtime": 0.2938506719947327}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1228, "makespan": 51, "avg_agents_density": 0.14774185202246126, "runtime": 1.5671216809714679}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1608, "makespan": 54, "avg_agents_density": 0.16188310042115303, "runtime": 1.392506749049062}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1198, "makespan": 41, "avg_agents_density": 0.1436163369349639, "runtime": 1.0218598300707527}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1244, "makespan": 45, "avg_agents_density": 0.16786100187368166, "runtime": 1.037060405156808}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1432, "makespan": 56, "avg_agents_density": 0.1577094412304782, "runtime": 1.4558558511198498}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2029, "makespan": 75, "avg_agents_density": 0.15604703795332825, "runtime": 1.9766250291431788}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1247, "makespan": 45, "avg_agents_density": 0.14238822748004176, "runtime": 1.1585128570441157}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2676, "makespan": 128, "avg_agents_density": 0.15412750805144157, "runtime": 3.5576843170274515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1549, "makespan": 59, "avg_agents_density": 0.17036062222163825, "runtime": 1.5609332848689519}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1170, "makespan": 41, "avg_agents_density": 0.17271425209172583, "runtime": 1.0885465230385307}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1250, "makespan": 92, "avg_agents_density": 0.125772110751751, "runtime": 2.3990494930476416}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4010, "makespan": 128, "avg_agents_density": 0.2875654813842635, "runtime": 3.2181916257250123}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1489, "makespan": 54, "avg_agents_density": 0.16292522494966832, "runtime": 1.4929017928952817}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1175, "makespan": 53, "avg_agents_density": 0.1514703790809875, "runtime": 1.533633687038673}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1215, "makespan": 39, "avg_agents_density": 0.18067989264298312, "runtime": 1.0040916700963862}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1926, "makespan": 68, "avg_agents_density": 0.16118756999467737, "runtime": 2.0493315349449404}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1678, "makespan": 79, "avg_agents_density": 0.1494299015077524, "runtime": 1.9217292077664752}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 1780, "makespan": 84, "avg_agents_density": 0.12488226568441238, "runtime": 2.092286072904244}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 2696, "makespan": 103, "avg_agents_density": 0.16359620565944624, "runtime": 2.684171055239858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3078, "makespan": 99, "avg_agents_density": 0.16408243760274638, "runtime": 2.0868474482558668}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1430, "makespan": 53, "avg_agents_density": 0.1442014951566801, "runtime": 1.134599176060874}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1953, "makespan": 78, "avg_agents_density": 0.17808429148393737, "runtime": 1.3447860300075263}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1008, "makespan": 44, "avg_agents_density": 0.14444614760993577, "runtime": 1.0355366829608101}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1353, "makespan": 53, "avg_agents_density": 0.1629116769367272, "runtime": 1.2146516680368222}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1802, "makespan": 76, "avg_agents_density": 0.14887572913652614, "runtime": 1.862146544008283}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 658, "makespan": 30, "avg_agents_density": 0.13510980269217623, "runtime": 0.7723910870263353}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1062, "makespan": 40, "avg_agents_density": 0.1336107897603294, "runtime": 1.116870091180317}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2062, "makespan": 78, "avg_agents_density": 0.14274441048756717, "runtime": 1.925899979978567}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2389, "makespan": 102, "avg_agents_density": 0.14812083040723414, "runtime": 2.4834300941729452}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1830, "makespan": 70, "avg_agents_density": 0.1648874809002276, "runtime": 1.6587538628664333}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1588, "makespan": 67, "avg_agents_density": 0.17826617593686464, "runtime": 1.361719672975596}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 878, "makespan": 38, "avg_agents_density": 0.14274522436643225, "runtime": 0.8643048989470117}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 2839, "makespan": 128, "avg_agents_density": 0.17912421402982592, "runtime": 4.486676989879925}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 3802, "makespan": 120, "avg_agents_density": 0.21067290445411968, "runtime": 4.138226237060735}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 127, "SoC": 4599, "makespan": 127, "avg_agents_density": 0.2143457578383381, "runtime": 4.375767273799283}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1835, "makespan": 50, "avg_agents_density": 0.20014017953360352, "runtime": 1.9262549490085803}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.484375, "CSR": 0.0, "ep_length": 128, "SoC": 4956, "makespan": 128, "avg_agents_density": 0.30689598049151856, "runtime": 4.363636871916242}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4472, "makespan": 128, "avg_agents_density": 0.19779023239111893, "runtime": 4.341099095938262}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3868, "makespan": 128, "avg_agents_density": 0.19603622584941524, "runtime": 4.101200796110788}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 5560, "makespan": 128, "avg_agents_density": 0.20287983383818708, "runtime": 4.090905963006662}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2173, "makespan": 56, "avg_agents_density": 0.19919162942196092, "runtime": 1.7852376499213278}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2557, "makespan": 85, "avg_agents_density": 0.2238564924311641, "runtime": 2.7194841800956056}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2203, "makespan": 91, "avg_agents_density": 0.1638749920723765, "runtime": 2.908496135874884}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 128, "SoC": 7309, "makespan": 128, "avg_agents_density": 0.36913287888389884, "runtime": 4.088505204039393}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2601, "makespan": 69, "avg_agents_density": 0.21942464823632263, "runtime": 2.197205530013889}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1952, "makespan": 55, "avg_agents_density": 0.19893705519474617, "runtime": 1.7579750200675335}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2367, "makespan": 83, "avg_agents_density": 0.21008315680437226, "runtime": 2.968301491899183}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3198, "makespan": 94, "avg_agents_density": 0.21109572844113508, "runtime": 2.974466502084397}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5267, "makespan": 128, "avg_agents_density": 0.23317520980592185, "runtime": 4.003668680146802}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1775, "makespan": 49, "avg_agents_density": 0.15838726015643897, "runtime": 1.5626600179239176}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 6162, "makespan": 128, "avg_agents_density": 0.18835837450642728, "runtime": 3.8003126498661004}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 6178, "makespan": 128, "avg_agents_density": 0.21309565146267245, "runtime": 3.7989755190792494}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 3199, "makespan": 122, "avg_agents_density": 0.1841194732166767, "runtime": 3.5877647478773724}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 5451, "makespan": 128, "avg_agents_density": 0.2367465820242815, "runtime": 3.6110226569580846}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2071, "makespan": 74, "avg_agents_density": 0.1905993715300048, "runtime": 2.200983048067428}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 3323, "makespan": 111, "avg_agents_density": 0.193098307574102, "runtime": 3.4861743629153352}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 124, "SoC": 4105, "makespan": 124, "avg_agents_density": 0.19867315776017627, "runtime": 3.8490207128343172}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 966, "makespan": 39, "avg_agents_density": 0.17668502559530228, "runtime": 1.2406695811077952}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1968, "makespan": 69, "avg_agents_density": 0.1711415476369653, "runtime": 2.0871701739670243}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2466, "makespan": 89, "avg_agents_density": 0.17572256447947404, "runtime": 2.824232611019397}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5413, "makespan": 128, "avg_agents_density": 0.22406943338772775, "runtime": 4.06790415107389}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 3389, "makespan": 83, "avg_agents_density": 0.23137131065982972, "runtime": 2.596964968222892}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2848, "makespan": 95, "avg_agents_density": 0.22755488463895213, "runtime": 3.042157846997725}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-312000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1409, "makespan": 42, "avg_agents_density": 0.18971467760638572, "runtime": 1.6421620169421658}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-312000"}]