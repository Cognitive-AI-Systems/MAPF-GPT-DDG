[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 663, "makespan": 44, "avg_agents_density": 0.09480129333430322, "runtime": 0.4405900009442121}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 669, "makespan": 40, "avg_agents_density": 0.12069486137360655, "runtime": 0.8145389031269588}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 795, "makespan": 66, "avg_agents_density": 0.08729918904768569, "runtime": 0.48503776197321713}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 772, "makespan": 47, "avg_agents_density": 0.11110239121088616, "runtime": 0.9697762358991895}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 960, "makespan": 55, "avg_agents_density": 0.1182622864912427, "runtime": 1.1332612200640142}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 949, "makespan": 55, "avg_agents_density": 0.10348316671599174, "runtime": 1.128719307074789}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 684, "makespan": 35, "avg_agents_density": 0.09875673112981936, "runtime": 0.6072430890344549}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1202, "makespan": 71, "avg_agents_density": 0.10597929228538135, "runtime": 1.6385040641471278}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 881, "makespan": 53, "avg_agents_density": 0.11562827240663721, "runtime": 1.0571667509502731}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 571, "makespan": 36, "avg_agents_density": 0.12712006221164657, "runtime": 0.6364648148883134}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 759, "makespan": 41, "avg_agents_density": 0.08925987566887306, "runtime": 0.8338533731293865}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1378, "makespan": 77, "avg_agents_density": 0.15748220786992714, "runtime": 1.1474967809626833}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 680, "makespan": 39, "avg_agents_density": 0.11082415472531468, "runtime": 0.8425497419084422}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 587, "makespan": 33, "avg_agents_density": 0.11299957293681662, "runtime": 0.6883662499603815}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 672, "makespan": 38, "avg_agents_density": 0.12033607406567534, "runtime": 0.7722287961223628}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 827, "makespan": 46, "avg_agents_density": 0.11318980798468468, "runtime": 0.48753859897260554}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 774, "makespan": 44, "avg_agents_density": 0.10720071148236279, "runtime": 0.4648124680388719}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 657, "makespan": 40, "avg_agents_density": 0.09430965648836774, "runtime": 0.785263163066702}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1099, "makespan": 51, "avg_agents_density": 0.1157477023366987, "runtime": 1.0352355418144725}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1043, "makespan": 48, "avg_agents_density": 0.12243782607088159, "runtime": 0.2617720198468305}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1010, "makespan": 68, "avg_agents_density": 0.0946654727583392, "runtime": 1.3043146331328899}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 767, "makespan": 38, "avg_agents_density": 0.11806243379036886, "runtime": 0.28926651197252795}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 684, "makespan": 38, "avg_agents_density": 0.09766050571038945, "runtime": 0.7422340228513349}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 923, "makespan": 128, "avg_agents_density": 0.09896027026789658, "runtime": 2.6438670268980786}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 848, "makespan": 77, "avg_agents_density": 0.09937396435445055, "runtime": 1.312438020016998}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 406, "makespan": 29, "avg_agents_density": 0.0949172342569666, "runtime": 0.2438293949526269}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 651, "makespan": 39, "avg_agents_density": 0.10037563678780907, "runtime": 0.6798849229817279}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 861, "makespan": 51, "avg_agents_density": 0.09355120020769989, "runtime": 0.9405559240258299}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1060, "makespan": 72, "avg_agents_density": 0.09326966685228548, "runtime": 0.3648630450188648}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 770, "makespan": 38, "avg_agents_density": 0.11435067326831795, "runtime": 0.49167084408691153}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 746, "makespan": 128, "avg_agents_density": 0.10462335562711318, "runtime": 0.6831832984753419}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 523, "makespan": 28, "avg_agents_density": 0.11377867017410641, "runtime": 0.5070939480501693}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1268, "makespan": 52, "avg_agents_density": 0.14410581671400097, "runtime": 1.6050426540896297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1372, "makespan": 50, "avg_agents_density": 0.1652736023068227, "runtime": 1.2715668670425657}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1349, "makespan": 66, "avg_agents_density": 0.14067243680934793, "runtime": 1.7584438499470707}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1182, "makespan": 45, "avg_agents_density": 0.1619929254483184, "runtime": 1.086444075073814}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1545, "makespan": 70, "avg_agents_density": 0.14341344125851407, "runtime": 1.8630354779888876}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2573, "makespan": 101, "avg_agents_density": 0.14971474195568252, "runtime": 2.643025954690529}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1218, "makespan": 43, "avg_agents_density": 0.13965295615731418, "runtime": 1.0252345749468077}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2872, "makespan": 128, "avg_agents_density": 0.15368456587482016, "runtime": 3.24936574473395}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1189, "makespan": 45, "avg_agents_density": 0.1772778735206, "runtime": 1.2003656081215013}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1219, "makespan": 42, "avg_agents_density": 0.1717058841783634, "runtime": 1.068411222047871}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1344, "makespan": 52, "avg_agents_density": 0.12484257712256919, "runtime": 1.4930371001828462}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 3935, "makespan": 115, "avg_agents_density": 0.21203925604822893, "runtime": 3.022439953900175}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1376, "makespan": 50, "avg_agents_density": 0.1651582789317888, "runtime": 1.4308414650440682}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1357, "makespan": 52, "avg_agents_density": 0.15665434955232999, "runtime": 1.4786210309830494}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1152, "makespan": 47, "avg_agents_density": 0.17351286994111167, "runtime": 1.2148244839336257}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1349, "makespan": 44, "avg_agents_density": 0.1629885645647628, "runtime": 1.348206400172785}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1692, "makespan": 59, "avg_agents_density": 0.17062524388668976, "runtime": 1.2508177030831575}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1114, "makespan": 52, "avg_agents_density": 0.12095935135354369, "runtime": 1.3300556179019623}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2319, "makespan": 85, "avg_agents_density": 0.15700724963745782, "runtime": 2.199910258728778}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 4278, "makespan": 126, "avg_agents_density": 0.20734638846645423, "runtime": 2.549219252920011}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 1561, "makespan": 96, "avg_agents_density": 0.14108804643318976, "runtime": 2.2826305362104904}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2061, "makespan": 84, "avg_agents_density": 0.16945190638392968, "runtime": 1.6878270956513006}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1137, "makespan": 62, "avg_agents_density": 0.14785282969519695, "runtime": 1.476936383987777}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1390, "makespan": 49, "avg_agents_density": 0.16665124082811336, "runtime": 1.158697251958074}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1823, "makespan": 69, "avg_agents_density": 0.157841855470791, "runtime": 1.6417118628160097}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 626, "makespan": 30, "avg_agents_density": 0.13421331460963418, "runtime": 0.734726619994035}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 1138, "makespan": 84, "avg_agents_density": 0.12769564235664865, "runtime": 2.360418513097102}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1728, "makespan": 64, "avg_agents_density": 0.1299181007356962, "runtime": 1.5710107411141507}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2241, "makespan": 80, "avg_agents_density": 0.1367417002455294, "runtime": 1.897092209168477}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1521, "makespan": 53, "avg_agents_density": 0.1681674410083562, "runtime": 1.3721131241472904}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 1636, "makespan": 88, "avg_agents_density": 0.17157549728561922, "runtime": 1.9805191300110891}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 863, "makespan": 29, "avg_agents_density": 0.1539324843486939, "runtime": 0.5867991159320809}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 3060, "makespan": 80, "avg_agents_density": 0.18885671987212327, "runtime": 2.860374112118734}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 3412, "makespan": 103, "avg_agents_density": 0.21152366512379592, "runtime": 3.576263872993877}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 3034, "makespan": 86, "avg_agents_density": 0.19985555399951005, "runtime": 3.0009189730044454}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2010, "makespan": 58, "avg_agents_density": 0.2004679439842959, "runtime": 2.036600759049179}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2231, "makespan": 62, "avg_agents_density": 0.20599140459284102, "runtime": 2.243465839914279}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 4614, "makespan": 110, "avg_agents_density": 0.21344861859915998, "runtime": 3.8479028059227858}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 3151, "makespan": 107, "avg_agents_density": 0.19017423887438273, "runtime": 3.3990849711408373}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 5787, "makespan": 128, "avg_agents_density": 0.2083695532181529, "runtime": 4.056983012909768}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2356, "makespan": 69, "avg_agents_density": 0.2009487314384845, "runtime": 2.1487982697726693}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2545, "makespan": 74, "avg_agents_density": 0.23197041544796212, "runtime": 2.3559675999276806}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2058, "makespan": 60, "avg_agents_density": 0.1711309391255049, "runtime": 1.9107255740091205}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.390625, "CSR": 0.0, "ep_length": 128, "SoC": 7054, "makespan": 128, "avg_agents_density": 0.36185012383580245, "runtime": 4.143405545182759}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 3631, "makespan": 83, "avg_agents_density": 0.2276243370761465, "runtime": 2.646843668888323}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1847, "makespan": 49, "avg_agents_density": 0.20079854426423777, "runtime": 1.5517315160832368}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2113, "makespan": 56, "avg_agents_density": 0.22879387228718764, "runtime": 2.1227317938464694}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 3278, "makespan": 90, "avg_agents_density": 0.2174299766678848, "runtime": 2.8301473630708642}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 128, "SoC": 5508, "makespan": 128, "avg_agents_density": 0.3075861869761665, "runtime": 4.001509818655904}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1751, "makespan": 53, "avg_agents_density": 0.15308880720423623, "runtime": 1.6839329209469724}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4541, "makespan": 128, "avg_agents_density": 0.18530170479395147, "runtime": 3.788823900074931}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.484375, "CSR": 0.0, "ep_length": 128, "SoC": 6870, "makespan": 128, "avg_agents_density": 0.26055841243004446, "runtime": 3.653226855181856}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 2724, "makespan": 96, "avg_agents_density": 0.18397701041859296, "runtime": 2.94847622801899}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2767, "makespan": 79, "avg_agents_density": 0.2032726056693063, "runtime": 2.2959897551045287}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1445, "makespan": 40, "avg_agents_density": 0.18907939475120356, "runtime": 1.2101879740075674}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2866, "makespan": 88, "avg_agents_density": 0.2003738668507909, "runtime": 2.7419878309883643}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 2892, "makespan": 128, "avg_agents_density": 0.19583306765519204, "runtime": 3.7136960229836404}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 886, "makespan": 27, "avg_agents_density": 0.18273002052823614, "runtime": 0.8530759729037527}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1948, "makespan": 66, "avg_agents_density": 0.17847003914445866, "runtime": 1.9986377300519962}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 3511, "makespan": 128, "avg_agents_density": 0.1699024771775444, "runtime": 4.046585027012043}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 4858, "makespan": 123, "avg_agents_density": 0.1982245256979702, "runtime": 3.8545680011156946}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 4108, "makespan": 106, "avg_agents_density": 0.21979571028952785, "runtime": 3.3713849090854637}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 4813, "makespan": 128, "avg_agents_density": 0.28535921051497193, "runtime": 4.077753682184266}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-376000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 3627, "makespan": 128, "avg_agents_density": 0.2175373493869426, "runtime": 4.253661608992843}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-376000"}]