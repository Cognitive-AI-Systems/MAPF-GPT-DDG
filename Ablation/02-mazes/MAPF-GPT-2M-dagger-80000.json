[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 939, "makespan": 52, "avg_agents_density": 0.1015823938540358, "runtime": 1.1627534749859478}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 838, "makespan": 48, "avg_agents_density": 0.12315051919356648, "runtime": 1.404554831009591}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1114, "makespan": 128, "avg_agents_density": 0.08172015027548572, "runtime": 1.6533144019776955}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 792, "makespan": 45, "avg_agents_density": 0.11269256022340976, "runtime": 1.5513312469120137}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 830, "makespan": 57, "avg_agents_density": 0.0971067045323003, "runtime": 1.7579030339984456}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1058, "makespan": 48, "avg_agents_density": 0.10633682713601793, "runtime": 1.3887182370235678}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 676, "makespan": 36, "avg_agents_density": 0.0965934758787777, "runtime": 1.2665104199841153}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1270, "makespan": 71, "avg_agents_density": 0.10898075761465116, "runtime": 1.9689837389305467}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1006, "makespan": 54, "avg_agents_density": 0.1128246759103985, "runtime": 1.4422013870062074}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 789, "makespan": 44, "avg_agents_density": 0.12958027261216704, "runtime": 1.0127865709800972}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 796, "makespan": 45, "avg_agents_density": 0.09070459984087659, "runtime": 1.4735004860267509}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1031, "makespan": 57, "avg_agents_density": 0.152155263763883, "runtime": 1.3344281470199348}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 734, "makespan": 39, "avg_agents_density": 0.1114605913840466, "runtime": 1.0332827049860498}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 717, "makespan": 37, "avg_agents_density": 0.1047458845567955, "runtime": 0.9510038230218925}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 859, "makespan": 55, "avg_agents_density": 0.12147040712429973, "runtime": 1.2450487120077014}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 899, "makespan": 43, "avg_agents_density": 0.11094630253826425, "runtime": 0.6327272299386095}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 905, "makespan": 68, "avg_agents_density": 0.11014391011147831, "runtime": 1.9992458350316156}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 697, "makespan": 51, "avg_agents_density": 0.08868315285963943, "runtime": 1.499101974972291}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1249, "makespan": 75, "avg_agents_density": 0.1236909106742244, "runtime": 2.185511156989378}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1332, "makespan": 72, "avg_agents_density": 0.11847129210793457, "runtime": 0.47590603001299314}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 913, "makespan": 62, "avg_agents_density": 0.09432271277096335, "runtime": 1.232589583931258}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 997, "makespan": 55, "avg_agents_density": 0.12020769953142259, "runtime": 0.7397172610071721}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 632, "makespan": 44, "avg_agents_density": 0.09366596537967033, "runtime": 0.6518714930280112}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 823, "makespan": 42, "avg_agents_density": 0.11807744891659952, "runtime": 1.4426572350348579}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 936, "makespan": 47, "avg_agents_density": 0.09570708136818078, "runtime": 1.355231024994282}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 418, "makespan": 29, "avg_agents_density": 0.0933382372215694, "runtime": 0.7080841560091358}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 751, "makespan": 49, "avg_agents_density": 0.09569542050087092, "runtime": 1.5066989140032092}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1013, "makespan": 63, "avg_agents_density": 0.08755618550807892, "runtime": 1.2826664009480737}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1309, "makespan": 70, "avg_agents_density": 0.09700340110037473, "runtime": 0.3098811340605607}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1087, "makespan": 67, "avg_agents_density": 0.1021604001237829, "runtime": 0.9167834769905312}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 709, "makespan": 56, "avg_agents_density": 0.10998040523133377, "runtime": 0.534232431979035}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 564, "makespan": 36, "avg_agents_density": 0.11277222318596841, "runtime": 0.47082657093415037}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1641, "makespan": 78, "avg_agents_density": 0.13450604471687014, "runtime": 3.0433418449538294}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1650, "makespan": 54, "avg_agents_density": 0.16424258337093467, "runtime": 1.7447845340502681}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1745, "makespan": 128, "avg_agents_density": 0.13211903570501704, "runtime": 4.134490926007857}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1419, "makespan": 48, "avg_agents_density": 0.16961415858747178, "runtime": 1.7062438239518087}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1719, "makespan": 61, "avg_agents_density": 0.14722364246181754, "runtime": 1.9379543459508568}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 2271, "makespan": 93, "avg_agents_density": 0.15968253107079283, "runtime": 3.1739061499683885}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1231, "makespan": 44, "avg_agents_density": 0.14327810946858793, "runtime": 1.4018015510082478}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3376, "makespan": 128, "avg_agents_density": 0.1663717333112229, "runtime": 4.540953742980491}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1741, "makespan": 56, "avg_agents_density": 0.17699850048976495, "runtime": 1.7771327640220989}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1402, "makespan": 59, "avg_agents_density": 0.17304860209340273, "runtime": 1.7526133380597457}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1466, "makespan": 59, "avg_agents_density": 0.12410146115166952, "runtime": 2.1949919740727637}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3044, "makespan": 128, "avg_agents_density": 0.20163582829262477, "runtime": 4.061621286004083}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1499, "makespan": 66, "avg_agents_density": 0.16619474898726946, "runtime": 2.283189691064763}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1567, "makespan": 51, "avg_agents_density": 0.14930837399971583, "runtime": 1.9885528370068641}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1299, "makespan": 45, "avg_agents_density": 0.18352505886067333, "runtime": 1.4652840959461173}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1821, "makespan": 60, "avg_agents_density": 0.17038207880632963, "runtime": 2.0445897280296776}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1936, "makespan": 68, "avg_agents_density": 0.16522643539442014, "runtime": 2.2420392409112537}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1153, "makespan": 48, "avg_agents_density": 0.1228934720645224, "runtime": 1.5973186650080606}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3786, "makespan": 128, "avg_agents_density": 0.18339421287210475, "runtime": 4.1476032500650035}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3342, "makespan": 128, "avg_agents_density": 0.17945292118687822, "runtime": 3.9234202451480087}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2163, "makespan": 75, "avg_agents_density": 0.14451064576475003, "runtime": 2.0693933849979658}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1920, "makespan": 63, "avg_agents_density": 0.16356065794722935, "runtime": 2.025634369972977}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1095, "makespan": 44, "avg_agents_density": 0.14209160000663465, "runtime": 1.3613946459518047}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1664, "makespan": 79, "avg_agents_density": 0.1695093970390122, "runtime": 2.602973644970916}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 2418, "makespan": 94, "avg_agents_density": 0.1651029221889187, "runtime": 3.1824914770113537}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 701, "makespan": 30, "avg_agents_density": 0.13436955174832854, "runtime": 0.914730163058266}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1316, "makespan": 58, "avg_agents_density": 0.13192276403124126, "runtime": 1.867759258064325}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2329, "makespan": 87, "avg_agents_density": 0.1373575749575189, "runtime": 2.610340747924056}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2764, "makespan": 101, "avg_agents_density": 0.16371109272413706, "runtime": 3.053378824988613}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1875, "makespan": 66, "avg_agents_density": 0.16484707870043627, "runtime": 2.222188398023718}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1709, "makespan": 91, "avg_agents_density": 0.1724834778370926, "runtime": 2.6874479749967577}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 915, "makespan": 37, "avg_agents_density": 0.14497476542101642, "runtime": 1.1236945659911726}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2683, "makespan": 87, "avg_agents_density": 0.18201402489299207, "runtime": 3.8724053349724272}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 4416, "makespan": 108, "avg_agents_density": 0.2180139821609789, "runtime": 4.2586200931546045}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 3406, "makespan": 88, "avg_agents_density": 0.2061342769309574, "runtime": 4.218232124054339}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2354, "makespan": 57, "avg_agents_density": 0.20153058667306925, "runtime": 2.7678899320599157}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 3169, "makespan": 81, "avg_agents_density": 0.22015439416029306, "runtime": 3.6287529959663516}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 5461, "makespan": 128, "avg_agents_density": 0.22427731555336727, "runtime": 5.441027445936925}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2767, "makespan": 75, "avg_agents_density": 0.1967342701927679, "runtime": 2.915585859082057}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 128, "SoC": 6281, "makespan": 128, "avg_agents_density": 0.2297422306932282, "runtime": 5.239817921057693}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3249, "makespan": 92, "avg_agents_density": 0.206487986765733, "runtime": 4.098087748119724}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2883, "makespan": 78, "avg_agents_density": 0.22133979808613097, "runtime": 3.2318930330657167}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3000, "makespan": 101, "avg_agents_density": 0.17487949984915496, "runtime": 4.137428413014277}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.296875, "CSR": 0.0, "ep_length": 128, "SoC": 7317, "makespan": 128, "avg_agents_density": 0.38771613396448473, "runtime": 5.320090057095513}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 3378, "makespan": 121, "avg_agents_density": 0.20012551136909568, "runtime": 5.133712574111996}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2357, "makespan": 81, "avg_agents_density": 0.19561996965700812, "runtime": 3.497463331092149}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2285, "makespan": 55, "avg_agents_density": 0.21322062836211111, "runtime": 2.65456941408047}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3592, "makespan": 99, "avg_agents_density": 0.21069034774637818, "runtime": 4.697365693034953}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 6328, "makespan": 128, "avg_agents_density": 0.24735293609307737, "runtime": 5.821547944025951}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2000, "makespan": 65, "avg_agents_density": 0.15602932406749717, "runtime": 2.978099298066809}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 5250, "makespan": 128, "avg_agents_density": 0.21161880387746212, "runtime": 4.678819254986593}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 128, "SoC": 6319, "makespan": 128, "avg_agents_density": 0.2629859746390561, "runtime": 4.8566388419567375}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 3249, "makespan": 89, "avg_agents_density": 0.19851766475973046, "runtime": 3.5224308489850955}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4042, "makespan": 128, "avg_agents_density": 0.21407289982562142, "runtime": 4.916842579899821}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2010, "makespan": 57, "avg_agents_density": 0.18583248092303095, "runtime": 2.142533126010676}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3588, "makespan": 128, "avg_agents_density": 0.2163600474093349, "runtime": 5.571364749033819}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4906, "makespan": 128, "avg_agents_density": 0.2109671652499989, "runtime": 5.668498633967829}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 955, "makespan": 29, "avg_agents_density": 0.18374208221098046, "runtime": 1.3849636659870157}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2057, "makespan": 60, "avg_agents_density": 0.1687224952155283, "runtime": 2.361595388967544}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4320, "makespan": 128, "avg_agents_density": 0.1914708435130926, "runtime": 5.68818494095467}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 6146, "makespan": 128, "avg_agents_density": 0.2240231585316294, "runtime": 5.7596599809330655}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 4056, "makespan": 111, "avg_agents_density": 0.21207389396535786, "runtime": 5.294978936028201}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4137, "makespan": 128, "avg_agents_density": 0.2200706456516734, "runtime": 5.686883474918432}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1737, "makespan": 51, "avg_agents_density": 0.1994747965528796, "runtime": 2.4655476460029604}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-80000"}]