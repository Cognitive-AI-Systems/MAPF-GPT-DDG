[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 676, "makespan": 41, "avg_agents_density": 0.09766786917976174, "runtime": 1.1226938540639821}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 937, "makespan": 48, "avg_agents_density": 0.1199096743273559, "runtime": 1.1441782330075512}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 796, "makespan": 55, "avg_agents_density": 0.09040117043119407, "runtime": 1.4827685380150797}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 670, "makespan": 41, "avg_agents_density": 0.11061952955421231, "runtime": 1.3000600909872446}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 878, "makespan": 46, "avg_agents_density": 0.10978095624599189, "runtime": 1.387383353037876}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1085, "makespan": 60, "avg_agents_density": 0.10849533004826, "runtime": 2.1660161038889783}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 858, "makespan": 65, "avg_agents_density": 0.09548359356235031, "runtime": 1.8336101550376043}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1132, "makespan": 56, "avg_agents_density": 0.11134554631260941, "runtime": 2.187182596011553}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 882, "makespan": 44, "avg_agents_density": 0.11228184408484392, "runtime": 1.4693843679269776}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 646, "makespan": 34, "avg_agents_density": 0.13194549172913903, "runtime": 0.4100798359577311}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 789, "makespan": 45, "avg_agents_density": 0.08651412220209301, "runtime": 1.2734874639863847}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 918, "makespan": 42, "avg_agents_density": 0.1488858296842334, "runtime": 1.288332970929332}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 768, "makespan": 48, "avg_agents_density": 0.10491889640640431, "runtime": 1.5437066500453511}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 601, "makespan": 36, "avg_agents_density": 0.10881711090092325, "runtime": 1.1770348510035546}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 654, "makespan": 33, "avg_agents_density": 0.12415857449247951, "runtime": 0.9834688429691596}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 924, "makespan": 51, "avg_agents_density": 0.1128256436372303, "runtime": 0.4623056669370271}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 807, "makespan": 46, "avg_agents_density": 0.11152255907113633, "runtime": 1.1367947959515732}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 751, "makespan": 48, "avg_agents_density": 0.0883939943426173, "runtime": 1.3031653159996495}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 923, "makespan": 42, "avg_agents_density": 0.11795199932128925, "runtime": 1.7151342790020863}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1287, "makespan": 58, "avg_agents_density": 0.10763743235548383, "runtime": 1.304087053053081}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 922, "makespan": 52, "avg_agents_density": 0.08878083738493182, "runtime": 0.9207122379448265}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 824, "makespan": 41, "avg_agents_density": 0.11568920636716266, "runtime": 0.20325197900820058}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 613, "makespan": 34, "avg_agents_density": 0.097383970940389, "runtime": 0.9732033500185935}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 707, "makespan": 40, "avg_agents_density": 0.1176173222416408, "runtime": 1.5780440429662121}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 963, "makespan": 66, "avg_agents_density": 0.10040188470657443, "runtime": 2.002910996074206}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 426, "makespan": 29, "avg_agents_density": 0.09457316626577056, "runtime": 0.6318914429866709}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 771, "makespan": 40, "avg_agents_density": 0.09781599761813989, "runtime": 0.8328503310185624}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1053, "makespan": 59, "avg_agents_density": 0.08843857886763949, "runtime": 1.9764352680649608}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1030, "makespan": 58, "avg_agents_density": 0.09421968859917833, "runtime": 0.6699960369878681}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 780, "makespan": 42, "avg_agents_density": 0.10822533302316897, "runtime": 0.4634758010361111}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 713, "makespan": 47, "avg_agents_density": 0.10659933100362745, "runtime": 0.58294639797532}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 554, "makespan": 33, "avg_agents_density": 0.113434958228795, "runtime": 0.8990806500078179}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1375, "makespan": 41, "avg_agents_density": 0.15096146256813833, "runtime": 2.0821382949652616}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1680, "makespan": 55, "avg_agents_density": 0.16021208447976712, "runtime": 1.7993477289564908}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1424, "makespan": 65, "avg_agents_density": 0.14094918189437933, "runtime": 2.1469878369680373}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1471, "makespan": 58, "avg_agents_density": 0.16691758833566644, "runtime": 1.863120501046069}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1506, "makespan": 60, "avg_agents_density": 0.15194556953023275, "runtime": 2.753205977001926}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2148, "makespan": 79, "avg_agents_density": 0.16202334775550717, "runtime": 2.501382085029036}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1279, "makespan": 76, "avg_agents_density": 0.1411830553290177, "runtime": 2.424799383021309}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 2984, "makespan": 93, "avg_agents_density": 0.1526963678370682, "runtime": 3.7760267869598465}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1614, "makespan": 56, "avg_agents_density": 0.17729537258719483, "runtime": 2.3484917930036318}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1310, "makespan": 53, "avg_agents_density": 0.17006734698751064, "runtime": 1.6863109799742233}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1298, "makespan": 53, "avg_agents_density": 0.12542126055360361, "runtime": 1.7093260359106353}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.5208333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4342, "makespan": 128, "avg_agents_density": 0.31841821897397793, "runtime": 5.143640405018232}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1502, "makespan": 68, "avg_agents_density": 0.16006997537182258, "runtime": 3.259874556111754}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1397, "makespan": 50, "avg_agents_density": 0.15077123740837195, "runtime": 1.9959683049964951}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1403, "makespan": 73, "avg_agents_density": 0.1668972336628877, "runtime": 2.542620228952728}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1334, "makespan": 41, "avg_agents_density": 0.15846766126854836, "runtime": 1.8260535670269746}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1862, "makespan": 71, "avg_agents_density": 0.1610539314563023, "runtime": 2.55383591199643}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1216, "makespan": 50, "avg_agents_density": 0.1203336276722732, "runtime": 1.7865290449844906}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 2953, "makespan": 105, "avg_agents_density": 0.1799690625091568, "runtime": 3.4220499300427036}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 128, "SoC": 4581, "makespan": 128, "avg_agents_density": 0.2472976956062438, "runtime": 3.549203222923097}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1593, "makespan": 56, "avg_agents_density": 0.1407494666005386, "runtime": 1.8362155909708235}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1684, "makespan": 60, "avg_agents_density": 0.16311833429858416, "runtime": 2.4680785108794225}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1153, "makespan": 43, "avg_agents_density": 0.14541058814121494, "runtime": 1.3801154080865672}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1533, "makespan": 47, "avg_agents_density": 0.17037611980625758, "runtime": 1.7558892870147247}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2083, "makespan": 80, "avg_agents_density": 0.15024054573511575, "runtime": 3.0538516759843333}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 653, "makespan": 28, "avg_agents_density": 0.1363910457485846, "runtime": 0.9869991740415571}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1232, "makespan": 41, "avg_agents_density": 0.13568678272336976, "runtime": 1.479327188921161}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1749, "makespan": 57, "avg_agents_density": 0.13891128303590375, "runtime": 1.8600311401241925}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 2561, "makespan": 108, "avg_agents_density": 0.14509789448528868, "runtime": 3.9891150670300703}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1980, "makespan": 63, "avg_agents_density": 0.1650281568840487, "runtime": 2.4403750989440596}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1292, "makespan": 68, "avg_agents_density": 0.1770271828856584, "runtime": 2.3085770639881957}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 835, "makespan": 31, "avg_agents_density": 0.1477902145630876, "runtime": 1.2360810669633793}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2288, "makespan": 63, "avg_agents_density": 0.18669682137667684, "runtime": 3.014900302005117}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2904, "makespan": 77, "avg_agents_density": 0.20385567769091603, "runtime": 4.097699944046326}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 3064, "makespan": 95, "avg_agents_density": 0.196016424232494, "runtime": 4.8329181479348335}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2141, "makespan": 55, "avg_agents_density": 0.20251765970965088, "runtime": 2.610401656056638}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2393, "makespan": 65, "avg_agents_density": 0.2063334745214113, "runtime": 3.3156977410108084}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3802, "makespan": 128, "avg_agents_density": 0.19557743281848503, "runtime": 6.5704600660537835}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2333, "makespan": 70, "avg_agents_density": 0.1834978663552748, "runtime": 3.588260043063201}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 6232, "makespan": 128, "avg_agents_density": 0.2279349258133352, "runtime": 6.162064821983222}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2675, "makespan": 73, "avg_agents_density": 0.2044732183149987, "runtime": 3.550368561060168}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 2206, "makespan": 53, "avg_agents_density": 0.2173790148438225, "runtime": 2.5492215690319426}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2537, "makespan": 74, "avg_agents_density": 0.17262169548539258, "runtime": 3.746782141068252}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.328125, "CSR": 0.0, "ep_length": 128, "SoC": 6840, "makespan": 128, "avg_agents_density": 0.3766033362557863, "runtime": 6.214948359134723}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2877, "makespan": 70, "avg_agents_density": 0.20500995399696165, "runtime": 3.442751577022136}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2090, "makespan": 64, "avg_agents_density": 0.1930221751560998, "runtime": 3.1141610280028544}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2556, "makespan": 128, "avg_agents_density": 0.20168035239719753, "runtime": 6.423024236049969}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 2317, "makespan": 53, "avg_agents_density": 0.2028976678728776, "runtime": 2.733550440010731}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 3383, "makespan": 97, "avg_agents_density": 0.19228598391646654, "runtime": 4.912344059936004}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1792, "makespan": 52, "avg_agents_density": 0.15371216881157085, "runtime": 2.4461419290455524}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 4349, "makespan": 117, "avg_agents_density": 0.19185773639619427, "runtime": 5.68927984405309}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 128, "SoC": 6362, "makespan": 128, "avg_agents_density": 0.2661335721515404, "runtime": 5.610487343001296}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 3594, "makespan": 128, "avg_agents_density": 0.18856237773598433, "runtime": 5.8673022760340245}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3445, "makespan": 92, "avg_agents_density": 0.2056048772035913, "runtime": 4.525952359079383}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1738, "makespan": 49, "avg_agents_density": 0.19186436592702336, "runtime": 2.3756593110301765}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2622, "makespan": 85, "avg_agents_density": 0.20123649156096393, "runtime": 4.213588307015016}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4046, "makespan": 128, "avg_agents_density": 0.18738266921649385, "runtime": 6.101587536250008}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 973, "makespan": 34, "avg_agents_density": 0.1838255469980223, "runtime": 1.6102151040249737}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1861, "makespan": 45, "avg_agents_density": 0.1750781405660658, "runtime": 2.01480254199123}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 3349, "makespan": 96, "avg_agents_density": 0.1834058834054126, "runtime": 4.613539920101175}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 4622, "makespan": 115, "avg_agents_density": 0.19050467055746365, "runtime": 5.525783566990867}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3765, "makespan": 102, "avg_agents_density": 0.20569075362645622, "runtime": 4.894835173967294}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2417, "makespan": 58, "avg_agents_density": 0.23734902468472244, "runtime": 2.725062210985925}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1573, "makespan": 48, "avg_agents_density": 0.19560886598947816, "runtime": 2.489321510976879}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-320000"}]