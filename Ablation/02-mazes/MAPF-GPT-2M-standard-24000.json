[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 772, "makespan": 44, "avg_agents_density": 0.10252626886264458, "runtime": 0.8120258760172874}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1201, "makespan": 67, "avg_agents_density": 0.12390569703826149, "runtime": 0.6253996150335297}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1426, "makespan": 128, "avg_agents_density": 0.08534419407456735, "runtime": 1.5297475879779086}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 972, "makespan": 128, "avg_agents_density": 0.10244546312048915, "runtime": 2.658170719019836}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1081, "makespan": 61, "avg_agents_density": 0.12275379926518915, "runtime": 1.2588431590120308}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 2322, "makespan": 128, "avg_agents_density": 0.10253756240056691, "runtime": 2.519353990937816}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 829, "makespan": 83, "avg_agents_density": 0.09317997058159559, "runtime": 1.679410613985965}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2234, "makespan": 128, "avg_agents_density": 0.11394607808669859, "runtime": 2.7872724117478356}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 942, "makespan": 50, "avg_agents_density": 0.11286046621283226, "runtime": 1.0572820097149815}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 805, "makespan": 50, "avg_agents_density": 0.13271787482838418, "runtime": 0.9317711829207838}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 943, "makespan": 128, "avg_agents_density": 0.08114321355498358, "runtime": 1.8898883829824626}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 2510, "makespan": 128, "avg_agents_density": 0.1503072855853837, "runtime": 2.3936668501410168}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 878, "makespan": 45, "avg_agents_density": 0.10651871012531697, "runtime": 1.0116958409489598}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 729, "makespan": 38, "avg_agents_density": 0.10839523121920627, "runtime": 0.8049199439701624}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 903, "makespan": 88, "avg_agents_density": 0.1123617232381469, "runtime": 1.3404253752378281}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1037, "makespan": 58, "avg_agents_density": 0.11098539033140435, "runtime": 0.8508073910779785}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1483, "makespan": 128, "avg_agents_density": 0.10415594056191711, "runtime": 2.216214099986246}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 761, "makespan": 51, "avg_agents_density": 0.09055862003772491, "runtime": 1.0082735238829628}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 1688, "makespan": 120, "avg_agents_density": 0.12272369504070636, "runtime": 2.1551519679487683}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 1556, "makespan": 81, "avg_agents_density": 0.12652377669598117, "runtime": 0.5883948591363151}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1443, "makespan": 128, "avg_agents_density": 0.10082449113981903, "runtime": 0.7900903069239575}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 1417, "makespan": 107, "avg_agents_density": 0.10628558909678677, "runtime": 1.1433775407786015}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 724, "makespan": 47, "avg_agents_density": 0.09449662989560943, "runtime": 0.5570463320764247}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 883, "makespan": 70, "avg_agents_density": 0.10593672885126644, "runtime": 1.4472347430128139}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1148, "makespan": 58, "avg_agents_density": 0.10521197099133346, "runtime": 1.1364931110583711}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 441, "makespan": 30, "avg_agents_density": 0.09493066104787849, "runtime": 0.4052085488801822}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 871, "makespan": 76, "avg_agents_density": 0.08984690322498809, "runtime": 1.3455839489470236}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1350, "makespan": 85, "avg_agents_density": 0.08409138213646515, "runtime": 1.0573688128497452}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 1414, "makespan": 97, "avg_agents_density": 0.09362149626602746, "runtime": 0.5238024458521977}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1483, "makespan": 78, "avg_agents_density": 0.1182012698442024, "runtime": 0.3033778040553443}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 919, "makespan": 53, "avg_agents_density": 0.11907615694543959, "runtime": 0.39819384503061883}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 540, "makespan": 33, "avg_agents_density": 0.1097668925345572, "runtime": 0.29836883896496147}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1663, "makespan": 75, "avg_agents_density": 0.14508830539156192, "runtime": 2.2612058431550395}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.7708333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3528, "makespan": 128, "avg_agents_density": 0.16443377326327388, "runtime": 3.2683537560224067}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1972, "makespan": 128, "avg_agents_density": 0.13170874596130702, "runtime": 3.2608712879009545}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2156, "makespan": 128, "avg_agents_density": 0.16449385759412455, "runtime": 3.269526126940036}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2193, "makespan": 128, "avg_agents_density": 0.14721838224693098, "runtime": 3.2709593549079727}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3541, "makespan": 128, "avg_agents_density": 0.16715631494109112, "runtime": 3.2708471798105165}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 1792, "makespan": 118, "avg_agents_density": 0.138869372299057, "runtime": 3.014546426158631}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4084, "makespan": 128, "avg_agents_density": 0.15022820290606806, "runtime": 3.526741434179712}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 3383, "makespan": 128, "avg_agents_density": 0.16466377782418454, "runtime": 3.2751156828308012}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3222, "makespan": 128, "avg_agents_density": 0.18327010159186963, "runtime": 3.290789275924908}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1690, "makespan": 128, "avg_agents_density": 0.12248511905745846, "runtime": 3.2644256082421634}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 128, "SoC": 4948, "makespan": 128, "avg_agents_density": 0.34439918364184086, "runtime": 3.3423519718053285}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1745, "makespan": 56, "avg_agents_density": 0.17775224340767037, "runtime": 1.450249939050991}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2005, "makespan": 76, "avg_agents_density": 0.15432691918580635, "runtime": 1.9556428770592902}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1733, "makespan": 70, "avg_agents_density": 0.17275300883215536, "runtime": 1.7854522839479614}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 2099, "makespan": 128, "avg_agents_density": 0.16453997550981952, "runtime": 3.457611462159548}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3441, "makespan": 128, "avg_agents_density": 0.1609211150355723, "runtime": 3.21413383790059}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1266, "makespan": 72, "avg_agents_density": 0.12164694396875872, "runtime": 1.8326422900427133}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3088, "makespan": 128, "avg_agents_density": 0.16302978292021114, "runtime": 3.266726955829654}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.3541666666666667, "CSR": 0.0, "ep_length": 128, "SoC": 5333, "makespan": 128, "avg_agents_density": 0.20886758954659487, "runtime": 2.5885055149556138}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 2942, "makespan": 128, "avg_agents_density": 0.14628920920407804, "runtime": 2.525416564953048}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 2725, "makespan": 120, "avg_agents_density": 0.1674379784744554, "runtime": 2.555619684921112}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1307, "makespan": 54, "avg_agents_density": 0.14927179260017592, "runtime": 1.3267672079091426}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2095, "makespan": 81, "avg_agents_density": 0.15680531836041817, "runtime": 1.7505831890157424}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.7708333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3339, "makespan": 128, "avg_agents_density": 0.15338696591091938, "runtime": 3.071733460848918}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 763, "makespan": 29, "avg_agents_density": 0.14232980616781793, "runtime": 0.7349307829863392}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1312, "makespan": 65, "avg_agents_density": 0.13024546396697004, "runtime": 1.656903570954455}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.8333333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3109, "makespan": 128, "avg_agents_density": 0.14634501350478324, "runtime": 3.1430854690261185}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4887, "makespan": 128, "avg_agents_density": 0.15487837162961474, "runtime": 2.9836841639480554}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2587, "makespan": 128, "avg_agents_density": 0.15105305019844426, "runtime": 2.89211286714999}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 2403, "makespan": 96, "avg_agents_density": 0.17941695952140302, "runtime": 2.3383050799311604}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1004, "makespan": 43, "avg_agents_density": 0.14037034276958418, "runtime": 0.9781324412324466}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 3715, "makespan": 128, "avg_agents_density": 0.19049825420949193, "runtime": 4.452896443690406}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5373, "makespan": 128, "avg_agents_density": 0.22825002274318903, "runtime": 4.161444440193009}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5100, "makespan": 128, "avg_agents_density": 0.22666990882795693, "runtime": 4.362296665058238}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 3106, "makespan": 108, "avg_agents_density": 0.19835126639500578, "runtime": 3.6649573059403338}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 4142, "makespan": 113, "avg_agents_density": 0.2055337031667686, "runtime": 3.9612089922302403}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 128, "SoC": 6963, "makespan": 128, "avg_agents_density": 0.2253918549001434, "runtime": 4.046671346150106}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4486, "makespan": 128, "avg_agents_density": 0.1903550107203719, "runtime": 4.080348624003818}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.421875, "CSR": 0.0, "ep_length": 128, "SoC": 7024, "makespan": 128, "avg_agents_density": 0.2188935833275196, "runtime": 4.077077555033611}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 6041, "makespan": 128, "avg_agents_density": 0.22628866052732743, "runtime": 4.043111725972267}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3227, "makespan": 99, "avg_agents_density": 0.2162282010079804, "runtime": 3.1518682817113586}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4343, "makespan": 128, "avg_agents_density": 0.1756743456864172, "runtime": 4.055376093107043}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.234375, "CSR": 0.0, "ep_length": 128, "SoC": 6789, "makespan": 128, "avg_agents_density": 0.3857291936626661, "runtime": 4.069667208183091}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 5641, "makespan": 128, "avg_agents_density": 0.20617535626942085, "runtime": 4.0671070191892795}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3469, "makespan": 128, "avg_agents_density": 0.1990348993572896, "runtime": 4.066531992080854}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4057, "makespan": 128, "avg_agents_density": 0.2101232711620331, "runtime": 4.0946458771359175}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 5104, "makespan": 128, "avg_agents_density": 0.21344137189800702, "runtime": 4.033839797222754}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 6516, "makespan": 128, "avg_agents_density": 0.23158173171633537, "runtime": 4.021387734101154}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2165, "makespan": 89, "avg_agents_density": 0.1535176644585086, "runtime": 2.7967467569978908}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 6707, "makespan": 128, "avg_agents_density": 0.20730493338110936, "runtime": 3.7493975779798348}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 128, "SoC": 7413, "makespan": 128, "avg_agents_density": 0.294813065483451, "runtime": 3.793022995814681}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 5796, "makespan": 128, "avg_agents_density": 0.2020746152096572, "runtime": 3.6942701170919463}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 128, "SoC": 5544, "makespan": 128, "avg_agents_density": 0.2220533995288395, "runtime": 3.8422621550853364}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2596, "makespan": 101, "avg_agents_density": 0.19068706267899901, "runtime": 2.9714473040075973}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5493, "makespan": 128, "avg_agents_density": 0.21359906162764816, "runtime": 4.015743031952297}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 5218, "makespan": 128, "avg_agents_density": 0.18459488580005043, "runtime": 3.9460274548910093}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1116, "makespan": 37, "avg_agents_density": 0.1764410374517679, "runtime": 1.1480524911021348}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 3303, "makespan": 126, "avg_agents_density": 0.17104599619027414, "runtime": 3.726322196132969}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4383, "makespan": 128, "avg_agents_density": 0.16683926014676778, "runtime": 4.025820192007814}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 128, "SoC": 6372, "makespan": 128, "avg_agents_density": 0.2786845214846735, "runtime": 4.021493658830877}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 5875, "makespan": 128, "avg_agents_density": 0.22151908555091443, "runtime": 4.008683433930855}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 4609, "makespan": 128, "avg_agents_density": 0.23201763501121644, "runtime": 4.059801456925925}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-24000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1457, "makespan": 44, "avg_agents_density": 0.190550973242945, "runtime": 1.6358833099075127}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-24000"}]