[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 693, "makespan": 35, "avg_agents_density": 0.09639140411558172, "runtime": 0.6069351269979961}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 943, "makespan": 57, "avg_agents_density": 0.12052479806927589, "runtime": 1.5444802139973035}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 847, "makespan": 72, "avg_agents_density": 0.0861391004780935, "runtime": 2.058270871086279}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 753, "makespan": 44, "avg_agents_density": 0.11037975922899093, "runtime": 1.6998993829620304}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 826, "makespan": 47, "avg_agents_density": 0.10020379065385132, "runtime": 1.5760631890007062}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1041, "makespan": 54, "avg_agents_density": 0.1080128666788658, "runtime": 1.7707310029800283}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 889, "makespan": 74, "avg_agents_density": 0.09600783044812802, "runtime": 2.2002859539934434}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 1631, "makespan": 118, "avg_agents_density": 0.11021371039440954, "runtime": 4.557971625967184}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 894, "makespan": 43, "avg_agents_density": 0.11259529184995563, "runtime": 1.6286546900082612}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 643, "makespan": 36, "avg_agents_density": 0.1207402805713126, "runtime": 0.6515259270236129}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 802, "makespan": 47, "avg_agents_density": 0.08315326942162976, "runtime": 1.2885998080164427}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1055, "makespan": 61, "avg_agents_density": 0.12925895702849732, "runtime": 2.180585195979802}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 646, "makespan": 35, "avg_agents_density": 0.11016484196084934, "runtime": 1.499868213039008}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 653, "makespan": 37, "avg_agents_density": 0.1106597791985122, "runtime": 1.6544293709594058}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 668, "makespan": 38, "avg_agents_density": 0.1160224113905961, "runtime": 1.0148891659337096}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 980, "makespan": 44, "avg_agents_density": 0.11980194662394017, "runtime": 0.4918724220187869}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1051, "makespan": 72, "avg_agents_density": 0.11064761241524104, "runtime": 1.1940511739667272}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 779, "makespan": 43, "avg_agents_density": 0.08904937982952815, "runtime": 1.2071933440311113}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1118, "makespan": 55, "avg_agents_density": 0.12158772740672864, "runtime": 1.525331847020425}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1086, "makespan": 49, "avg_agents_density": 0.10892632579684283, "runtime": 0.7924911939917365}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 936, "makespan": 66, "avg_agents_density": 0.0912784673279148, "runtime": 0.9661046629189514}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 965, "makespan": 49, "avg_agents_density": 0.1155559188865962, "runtime": 0.42432894301600754}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 656, "makespan": 41, "avg_agents_density": 0.09688724866385548, "runtime": 1.0808252651040675}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 710, "makespan": 40, "avg_agents_density": 0.11007462981038743, "runtime": 1.1348740329412976}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 862, "makespan": 51, "avg_agents_density": 0.09551993837946823, "runtime": 1.3932823729410302}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 417, "makespan": 29, "avg_agents_density": 0.09399216621250558, "runtime": 0.33247760696394835}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 678, "makespan": 42, "avg_agents_density": 0.09695095963854872, "runtime": 1.1886484310089145}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 898, "makespan": 47, "avg_agents_density": 0.0879429515173032, "runtime": 1.3362181470001815}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1034, "makespan": 53, "avg_agents_density": 0.0951622114366397, "runtime": 0.5419043510191841}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 911, "makespan": 54, "avg_agents_density": 0.10808098935718194, "runtime": 0.5689299699297408}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 770, "makespan": 43, "avg_agents_density": 0.11396218903909133, "runtime": 0.19870275691209827}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 537, "makespan": 28, "avg_agents_density": 0.11244289752192076, "runtime": 0.4684280839865096}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1202, "makespan": 40, "avg_agents_density": 0.14492156034676562, "runtime": 2.032512022939045}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1537, "makespan": 59, "avg_agents_density": 0.1595573466395298, "runtime": 2.705318931984948}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 1875, "makespan": 115, "avg_agents_density": 0.1345654237300258, "runtime": 4.672980380986701}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1246, "makespan": 41, "avg_agents_density": 0.16150371013128564, "runtime": 1.770865179001703}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1628, "makespan": 73, "avg_agents_density": 0.15295828107516815, "runtime": 2.861949939033366}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1870, "makespan": 65, "avg_agents_density": 0.16019163767568115, "runtime": 2.4553946379892295}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1190, "makespan": 44, "avg_agents_density": 0.14299439079207113, "runtime": 2.0185763709887397}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 3190, "makespan": 128, "avg_agents_density": 0.16061886930984923, "runtime": 4.866236487898277}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1410, "makespan": 46, "avg_agents_density": 0.17682536249420214, "runtime": 1.7926018569414737}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1403, "makespan": 43, "avg_agents_density": 0.1730731573321321, "runtime": 1.6723371829721145}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1570, "makespan": 66, "avg_agents_density": 0.1277370900677962, "runtime": 2.350235972000519}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.6458333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3917, "makespan": 128, "avg_agents_density": 0.2654473070362282, "runtime": 4.939099372015335}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1562, "makespan": 59, "avg_agents_density": 0.15557201267545065, "runtime": 2.125036410012399}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1253, "makespan": 45, "avg_agents_density": 0.14741598991592245, "runtime": 1.6859430320182582}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1369, "makespan": 55, "avg_agents_density": 0.1815860888272526, "runtime": 2.2896723640005803}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1642, "makespan": 55, "avg_agents_density": 0.1676707279587919, "runtime": 1.8746277679747436}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1735, "makespan": 71, "avg_agents_density": 0.15837551314392187, "runtime": 2.7778999509318965}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1324, "makespan": 52, "avg_agents_density": 0.11931265638615364, "runtime": 2.337439792929217}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3054, "makespan": 99, "avg_agents_density": 0.17713668371607022, "runtime": 4.286475032873568}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.6458333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4319, "makespan": 128, "avg_agents_density": 0.24471378062381782, "runtime": 4.23537372390274}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1537, "makespan": 58, "avg_agents_density": 0.14614023743792437, "runtime": 2.474378853003145}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1819, "makespan": 54, "avg_agents_density": 0.15732411813008843, "runtime": 2.1936273040628294}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1053, "makespan": 39, "avg_agents_density": 0.14568191333024644, "runtime": 1.3457227999751922}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1613, "makespan": 56, "avg_agents_density": 0.1709808563655259, "runtime": 2.4330880800262094}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1799, "makespan": 71, "avg_agents_density": 0.148342143203707, "runtime": 2.758405280968873}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 674, "makespan": 30, "avg_agents_density": 0.1343267496222902, "runtime": 1.396298262057826}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1234, "makespan": 38, "avg_agents_density": 0.13580382927110907, "runtime": 1.5429003800672945}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1782, "makespan": 66, "avg_agents_density": 0.1308672794525666, "runtime": 2.604354742943542}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2117, "makespan": 67, "avg_agents_density": 0.14777545220326596, "runtime": 2.566676577931503}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1887, "makespan": 59, "avg_agents_density": 0.16476139711688004, "runtime": 2.303874677949352}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1446, "makespan": 55, "avg_agents_density": 0.18019216312856992, "runtime": 2.284790599020198}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 847, "makespan": 31, "avg_agents_density": 0.1430267513846817, "runtime": 1.3056488539587008}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2483, "makespan": 67, "avg_agents_density": 0.18975850186130822, "runtime": 3.8335559160186676}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 3201, "makespan": 83, "avg_agents_density": 0.2023129640163687, "runtime": 4.642980101925787}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3340, "makespan": 84, "avg_agents_density": 0.2177438013153479, "runtime": 4.330975684861187}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 2000, "makespan": 52, "avg_agents_density": 0.2007423972595665, "runtime": 2.0847657450067345}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2923, "makespan": 75, "avg_agents_density": 0.20938754550572922, "runtime": 4.152509589999681}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4576, "makespan": 128, "avg_agents_density": 0.2052896328125722, "runtime": 6.720730847955565}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2396, "makespan": 78, "avg_agents_density": 0.18094028304372103, "runtime": 3.480376199047896}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5842, "makespan": 128, "avg_agents_density": 0.22696672136758056, "runtime": 5.727219710097415}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2993, "makespan": 70, "avg_agents_density": 0.20181644595634016, "runtime": 3.3393302969634533}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2301, "makespan": 65, "avg_agents_density": 0.21499112289207392, "runtime": 3.1903069920517737}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1980, "makespan": 51, "avg_agents_density": 0.17098232369984617, "runtime": 2.327952374034794}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 128, "SoC": 7549, "makespan": 128, "avg_agents_density": 0.382265198924005, "runtime": 6.290882387984311}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 3233, "makespan": 89, "avg_agents_density": 0.21351137310955157, "runtime": 4.2409938579803566}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2342, "makespan": 64, "avg_agents_density": 0.18864377659337683, "runtime": 3.0434030419564806}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 3058, "makespan": 86, "avg_agents_density": 0.22119100364694383, "runtime": 4.548270757950377}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2972, "makespan": 85, "avg_agents_density": 0.21468237976360754, "runtime": 3.5996447290381184}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 3361, "makespan": 85, "avg_agents_density": 0.20919021222435352, "runtime": 3.3462887931091245}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1961, "makespan": 61, "avg_agents_density": 0.1495766371928644, "runtime": 2.547878030978609}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4808, "makespan": 128, "avg_agents_density": 0.18505984320898095, "runtime": 5.536576763988705}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 128, "SoC": 5857, "makespan": 128, "avg_agents_density": 0.2744898311658509, "runtime": 5.399874444992747}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3181, "makespan": 99, "avg_agents_density": 0.19418619668285456, "runtime": 4.643725754096522}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2761, "makespan": 68, "avg_agents_density": 0.19513116086676494, "runtime": 3.2812752590543823}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1919, "makespan": 55, "avg_agents_density": 0.18101833637583592, "runtime": 2.878499443992041}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 124, "SoC": 3139, "makespan": 124, "avg_agents_density": 0.19284218714310652, "runtime": 4.959735042924876}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 4086, "makespan": 118, "avg_agents_density": 0.19102573538476103, "runtime": 5.159104559017578}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 939, "makespan": 31, "avg_agents_density": 0.18350644762109083, "runtime": 1.102287782021449}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1900, "makespan": 49, "avg_agents_density": 0.17470593527271894, "runtime": 2.3162705689901486}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2879, "makespan": 83, "avg_agents_density": 0.17020697605295826, "runtime": 3.1427340979862493}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4498, "makespan": 128, "avg_agents_density": 0.2030947465606514, "runtime": 5.0807646731846035}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 4280, "makespan": 93, "avg_agents_density": 0.2351942795248642, "runtime": 4.035956524050562}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2528, "makespan": 80, "avg_agents_density": 0.22101309582517595, "runtime": 3.7049694289889885}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1340, "makespan": 45, "avg_agents_density": 0.18800853986589083, "runtime": 2.9049717719171895}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-344000"}]