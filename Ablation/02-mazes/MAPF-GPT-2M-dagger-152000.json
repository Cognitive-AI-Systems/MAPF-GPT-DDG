[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 751, "makespan": 47, "avg_agents_density": 0.0957696203260446, "runtime": 1.409096789022442}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 864, "makespan": 40, "avg_agents_density": 0.11727368583218684, "runtime": 1.0389461730519542}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 775, "makespan": 51, "avg_agents_density": 0.08761418442981261, "runtime": 1.3250471419742098}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 770, "makespan": 43, "avg_agents_density": 0.11020427410405044, "runtime": 1.4472251819970552}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 869, "makespan": 55, "avg_agents_density": 0.10424409345312945, "runtime": 2.025231382009224}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1069, "makespan": 54, "avg_agents_density": 0.10413929284780475, "runtime": 1.6155678360228194}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 635, "makespan": 37, "avg_agents_density": 0.09971311709166056, "runtime": 0.8758408350113314}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1216, "makespan": 56, "avg_agents_density": 0.11500859158808123, "runtime": 2.1132776390149957}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1096, "makespan": 51, "avg_agents_density": 0.11770825802792959, "runtime": 1.4397862849727971}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 783, "makespan": 45, "avg_agents_density": 0.13122355071633687, "runtime": 1.478391308002756}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 823, "makespan": 56, "avg_agents_density": 0.0915624401118999, "runtime": 1.2665253579616547}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1220, "makespan": 59, "avg_agents_density": 0.15605653810076775, "runtime": 1.923125649947906}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 864, "makespan": 49, "avg_agents_density": 0.10402526447472978, "runtime": 1.9326058759907028}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 787, "makespan": 49, "avg_agents_density": 0.10914493749893558, "runtime": 1.8172551930038026}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 796, "makespan": 46, "avg_agents_density": 0.12144459120056887, "runtime": 1.1103953609999735}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1072, "makespan": 61, "avg_agents_density": 0.11357524079439166, "runtime": 1.2689138350397116}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 871, "makespan": 50, "avg_agents_density": 0.11043761476475193, "runtime": 1.2800287209975068}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 813, "makespan": 54, "avg_agents_density": 0.09413597764815625, "runtime": 1.7928087860054802}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 1705, "makespan": 100, "avg_agents_density": 0.12781904034854352, "runtime": 2.698704571943381}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1206, "makespan": 59, "avg_agents_density": 0.11169778344932736, "runtime": 1.901339010000811}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 876, "makespan": 63, "avg_agents_density": 0.09073120072154837, "runtime": 1.6746528089715866}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1003, "makespan": 50, "avg_agents_density": 0.1097607328682508, "runtime": 0.5625824219750939}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 655, "makespan": 35, "avg_agents_density": 0.10088567955526632, "runtime": 0.552901650997228}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 816, "makespan": 53, "avg_agents_density": 0.1049078799360181, "runtime": 1.8889398340397747}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 946, "makespan": 57, "avg_agents_density": 0.09759080561397206, "runtime": 1.9455437479628017}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 430, "makespan": 33, "avg_agents_density": 0.09315323741186587, "runtime": 1.0053966449777363}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 667, "makespan": 34, "avg_agents_density": 0.10179104654550009, "runtime": 1.07026618400414}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 944, "makespan": 60, "avg_agents_density": 0.09399409064207376, "runtime": 1.9782651979621733}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1125, "makespan": 57, "avg_agents_density": 0.08964944625957595, "runtime": 1.2594536570395576}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1076, "makespan": 59, "avg_agents_density": 0.11220250316884567, "runtime": 0.895830212844885}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 856, "makespan": 47, "avg_agents_density": 0.11426242689181948, "runtime": 0.22192243605968542}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 530, "makespan": 30, "avg_agents_density": 0.11259022415543052, "runtime": 0.35102433792781085}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1552, "makespan": 58, "avg_agents_density": 0.14461328737073847, "runtime": 2.3565668710361933}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1823, "makespan": 71, "avg_agents_density": 0.15199672668111783, "runtime": 2.756975187061471}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 1595, "makespan": 112, "avg_agents_density": 0.1348004403893919, "runtime": 4.360370095950202}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1533, "makespan": 73, "avg_agents_density": 0.1585158174948513, "runtime": 2.439852297975449}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1910, "makespan": 66, "avg_agents_density": 0.13931267026894628, "runtime": 2.42697480096831}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2235, "makespan": 84, "avg_agents_density": 0.1597397228307834, "runtime": 2.91874379303772}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1391, "makespan": 51, "avg_agents_density": 0.1482038845395112, "runtime": 1.894907093999791}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2963, "makespan": 128, "avg_agents_density": 0.14918253366984918, "runtime": 4.834788997861324}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 1920, "makespan": 101, "avg_agents_density": 0.1600832172593824, "runtime": 3.6077504389104433}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1598, "makespan": 55, "avg_agents_density": 0.187813985853498, "runtime": 2.344785027031321}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1339, "makespan": 61, "avg_agents_density": 0.13105971507805833, "runtime": 2.461710839008447}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4010, "makespan": 128, "avg_agents_density": 0.23793772633163326, "runtime": 5.531644071961637}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1722, "makespan": 61, "avg_agents_density": 0.16243481765776463, "runtime": 2.270572152949171}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1559, "makespan": 53, "avg_agents_density": 0.15107225944090108, "runtime": 2.5390773749968503}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1586, "makespan": 128, "avg_agents_density": 0.1597461643078833, "runtime": 5.178546555907815}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1753, "makespan": 67, "avg_agents_density": 0.15753157681884528, "runtime": 3.1565380550309783}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2289, "makespan": 75, "avg_agents_density": 0.18014809086989123, "runtime": 2.766696357051842}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1423, "makespan": 67, "avg_agents_density": 0.12280025242289382, "runtime": 2.8339457820693497}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2607, "makespan": 92, "avg_agents_density": 0.17217432739220354, "runtime": 3.675112014010665}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3628, "makespan": 128, "avg_agents_density": 0.18588177660496003, "runtime": 3.6977259159175446}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1618, "makespan": 47, "avg_agents_density": 0.14953822130451455, "runtime": 1.5016600319941062}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 2536, "makespan": 113, "avg_agents_density": 0.16467379601174056, "runtime": 4.160899764014175}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1118, "makespan": 42, "avg_agents_density": 0.14102300745113244, "runtime": 1.566697166999802}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1760, "makespan": 71, "avg_agents_density": 0.16275611307109283, "runtime": 1.8574616569676436}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2025, "makespan": 74, "avg_agents_density": 0.14996241020883802, "runtime": 3.0627685329091037}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 703, "makespan": 31, "avg_agents_density": 0.1340395230836622, "runtime": 1.2151303719438147}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1293, "makespan": 58, "avg_agents_density": 0.129854938784236, "runtime": 2.0421445469837636}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 2140, "makespan": 99, "avg_agents_density": 0.13645092659138325, "runtime": 3.2461607399454806}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2727, "makespan": 82, "avg_agents_density": 0.1475931132414335, "runtime": 3.1175184899620945}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2005, "makespan": 69, "avg_agents_density": 0.1672132333036509, "runtime": 2.4613703200157033}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2081, "makespan": 82, "avg_agents_density": 0.175516584151411, "runtime": 3.544989033936872}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 933, "makespan": 37, "avg_agents_density": 0.1488501046610611, "runtime": 1.244138785987161}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2610, "makespan": 70, "avg_agents_density": 0.18707901145196654, "runtime": 3.8737676759483293}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 3540, "makespan": 79, "avg_agents_density": 0.21339906865732336, "runtime": 3.5546987309498945}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2844, "makespan": 128, "avg_agents_density": 0.1903227178400217, "runtime": 5.408300980023341}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2252, "makespan": 58, "avg_agents_density": 0.19935323101369767, "runtime": 3.5659271419863217}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2277, "makespan": 56, "avg_agents_density": 0.19216342376950207, "runtime": 3.3119991119601764}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 5296, "makespan": 128, "avg_agents_density": 0.21425762240242016, "runtime": 5.66591964395775}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 3457, "makespan": 112, "avg_agents_density": 0.19399524064756246, "runtime": 4.268604754994158}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.609375, "CSR": 0.0, "ep_length": 128, "SoC": 6056, "makespan": 128, "avg_agents_density": 0.20000598551645415, "runtime": 5.14779193099821}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 3371, "makespan": 91, "avg_agents_density": 0.19604717187765908, "runtime": 3.492823582026176}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2359, "makespan": 76, "avg_agents_density": 0.21262422517653842, "runtime": 2.966315818950534}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2636, "makespan": 75, "avg_agents_density": 0.17744593355134766, "runtime": 2.735472097978345}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.453125, "CSR": 0.0, "ep_length": 128, "SoC": 6444, "makespan": 128, "avg_agents_density": 0.3313430393098453, "runtime": 5.001782566963811}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2611, "makespan": 70, "avg_agents_density": 0.20030279217870378, "runtime": 2.701932591968216}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2252, "makespan": 57, "avg_agents_density": 0.19984883445986734, "runtime": 2.0482615880318917}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2320, "makespan": 61, "avg_agents_density": 0.21253020366011086, "runtime": 2.594539122073911}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 3723, "makespan": 87, "avg_agents_density": 0.20579727985310992, "runtime": 3.331229922856437}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 3471, "makespan": 81, "avg_agents_density": 0.21485179383066297, "runtime": 3.085813789992244}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1935, "makespan": 52, "avg_agents_density": 0.15387062894994297, "runtime": 1.9029027119104285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4795, "makespan": 128, "avg_agents_density": 0.18872885937065603, "runtime": 5.796943090113928}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5670, "makespan": 128, "avg_agents_density": 0.209973748038811, "runtime": 5.047147001110716}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3267, "makespan": 128, "avg_agents_density": 0.1862593085517421, "runtime": 5.290451965047396}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2868, "makespan": 65, "avg_agents_density": 0.2069452187488199, "runtime": 2.445924134008237}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2067, "makespan": 59, "avg_agents_density": 0.18749753374451042, "runtime": 2.7957270860206336}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 3606, "makespan": 93, "avg_agents_density": 0.19942520192229324, "runtime": 3.663008236006135}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 4133, "makespan": 128, "avg_agents_density": 0.19012705672229774, "runtime": 5.761346628001775}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 929, "makespan": 30, "avg_agents_density": 0.18584822860846922, "runtime": 1.1736683750204975}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2429, "makespan": 78, "avg_agents_density": 0.1735986830264804, "runtime": 3.126845520979259}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 3857, "makespan": 119, "avg_agents_density": 0.1711759733138922, "runtime": 4.484055068925954}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4530, "makespan": 128, "avg_agents_density": 0.20496444332104666, "runtime": 5.0517642510531005}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 3838, "makespan": 128, "avg_agents_density": 0.18994367140542318, "runtime": 5.013769753917586}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 4042, "makespan": 122, "avg_agents_density": 0.23041970197996334, "runtime": 4.587743706943002}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2177, "makespan": 66, "avg_agents_density": 0.20119730814683245, "runtime": 3.7203846350021195}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-152000"}]