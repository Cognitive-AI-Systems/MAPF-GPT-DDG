[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 723, "makespan": 42, "avg_agents_density": 0.10430877662462125, "runtime": 1.091858573956415}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 792, "makespan": 49, "avg_agents_density": 0.11962973237769108, "runtime": 0.798087111019413}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1102, "makespan": 128, "avg_agents_density": 0.08286093136771049, "runtime": 2.1704507519461913}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 768, "makespan": 38, "avg_agents_density": 0.10684922986135136, "runtime": 1.0766400279244408}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 860, "makespan": 50, "avg_agents_density": 0.10284008023539955, "runtime": 1.1082465410145232}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 1198, "makespan": 96, "avg_agents_density": 0.10482775431274072, "runtime": 1.8242906880477676}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 909, "makespan": 63, "avg_agents_density": 0.09327324409949689, "runtime": 1.1088825429906137}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1070, "makespan": 53, "avg_agents_density": 0.10561344362434519, "runtime": 1.338085986993974}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1135, "makespan": 61, "avg_agents_density": 0.11205788803437497, "runtime": 1.1333804220339516}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 691, "makespan": 41, "avg_agents_density": 0.12674356549141982, "runtime": 0.7199252279970096}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 890, "makespan": 52, "avg_agents_density": 0.09113841746407457, "runtime": 0.9421809719933663}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1036, "makespan": 54, "avg_agents_density": 0.14408049183971167, "runtime": 1.12079491604527}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 840, "makespan": 37, "avg_agents_density": 0.10530122969625129, "runtime": 1.004612894001184}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 663, "makespan": 42, "avg_agents_density": 0.10524804680251, "runtime": 1.0440947890165262}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 677, "makespan": 40, "avg_agents_density": 0.11791649357877772, "runtime": 0.6470623439236078}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 932, "makespan": 45, "avg_agents_density": 0.10998937205878903, "runtime": 0.7014316569111543}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 958, "makespan": 46, "avg_agents_density": 0.12140541887769417, "runtime": 0.7223128809564514}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 737, "makespan": 47, "avg_agents_density": 0.09291464884874008, "runtime": 0.8880175019876333}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1191, "makespan": 52, "avg_agents_density": 0.12351042206976758, "runtime": 1.3386971580039244}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 1869, "makespan": 104, "avg_agents_density": 0.11119891080818303, "runtime": 2.0084306690114317}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 1100, "makespan": 103, "avg_agents_density": 0.09373139305425322, "runtime": 1.927041369926883}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 947, "makespan": 44, "avg_agents_density": 0.11165666243187719, "runtime": 0.6978622789611109}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 754, "makespan": 49, "avg_agents_density": 0.09529967760813776, "runtime": 0.7867379520175746}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 926, "makespan": 54, "avg_agents_density": 0.1142328373400734, "runtime": 1.5219835840252927}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1075, "makespan": 60, "avg_agents_density": 0.10573230766674079, "runtime": 1.523345283974777}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 463, "makespan": 32, "avg_agents_density": 0.09267506689002407, "runtime": 0.5260730870504631}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 753, "makespan": 40, "avg_agents_density": 0.09644017630195746, "runtime": 0.7670128850004403}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 904, "makespan": 56, "avg_agents_density": 0.08679393358681431, "runtime": 1.4039876579627162}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1379, "makespan": 74, "avg_agents_density": 0.1007479401948587, "runtime": 0.5426638499775436}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 999, "makespan": 51, "avg_agents_density": 0.11198299709069316, "runtime": 0.7907711139851017}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 671, "makespan": 31, "avg_agents_density": 0.11221581753890522, "runtime": 0.7192850400460884}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 564, "makespan": 31, "avg_agents_density": 0.11471469897050574, "runtime": 0.6023977380100405}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1512, "makespan": 52, "avg_agents_density": 0.14451487335896493, "runtime": 2.523352671050816}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1553, "makespan": 54, "avg_agents_density": 0.1634271714936405, "runtime": 1.4314409909857204}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1687, "makespan": 76, "avg_agents_density": 0.1489931516205101, "runtime": 2.1478762659826316}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1455, "makespan": 57, "avg_agents_density": 0.16386399213954744, "runtime": 1.5955008499586256}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2301, "makespan": 74, "avg_agents_density": 0.1708221023116638, "runtime": 2.9106143518874887}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2303, "makespan": 79, "avg_agents_density": 0.15912726917637537, "runtime": 3.019789367011981}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 2437, "makespan": 110, "avg_agents_density": 0.14890524209184477, "runtime": 3.0608024060202297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3041, "makespan": 128, "avg_agents_density": 0.1467437988003233, "runtime": 4.472242617004667}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1783, "makespan": 65, "avg_agents_density": 0.16934176859560135, "runtime": 2.5089177649497287}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1721, "makespan": 128, "avg_agents_density": 0.16848430137759457, "runtime": 4.521878059953451}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1253, "makespan": 45, "avg_agents_density": 0.12645978137263558, "runtime": 1.3198826829902828}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4413, "makespan": 128, "avg_agents_density": 0.23719284126426682, "runtime": 4.967336951987818}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1527, "makespan": 53, "avg_agents_density": 0.16065474853435072, "runtime": 2.2263957689719973}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1638, "makespan": 58, "avg_agents_density": 0.14991871147495964, "runtime": 2.2370488929736894}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 1805, "makespan": 108, "avg_agents_density": 0.15854875814524877, "runtime": 3.214620476035634}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1710, "makespan": 52, "avg_agents_density": 0.15793006359389256, "runtime": 2.0656778330012457}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1999, "makespan": 70, "avg_agents_density": 0.1750465558289846, "runtime": 1.7579318049829453}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1200, "makespan": 52, "avg_agents_density": 0.11988754880286631, "runtime": 1.9914553399721626}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2499, "makespan": 81, "avg_agents_density": 0.15916763498162528, "runtime": 2.9095860000670655}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4169, "makespan": 128, "avg_agents_density": 0.22622908297133826, "runtime": 2.7344362259609625}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 2206, "makespan": 98, "avg_agents_density": 0.1436213291815134, "runtime": 2.2511788589763455}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2095, "makespan": 71, "avg_agents_density": 0.16506268188406523, "runtime": 1.7931737768667517}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1161, "makespan": 52, "avg_agents_density": 0.14402768860922524, "runtime": 1.5370886860182509}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1505, "makespan": 55, "avg_agents_density": 0.1623854693389127, "runtime": 1.3634239178936696}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.7916666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3180, "makespan": 128, "avg_agents_density": 0.16859101958321174, "runtime": 3.605369841112406}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 655, "makespan": 28, "avg_agents_density": 0.13782994003292595, "runtime": 0.8613126350392122}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1267, "makespan": 56, "avg_agents_density": 0.13189471228979405, "runtime": 2.1517066399828764}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2166, "makespan": 92, "avg_agents_density": 0.14214595082728015, "runtime": 2.420660549963941}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 2517, "makespan": 90, "avg_agents_density": 0.1575530649517198, "runtime": 2.404984036940732}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1842, "makespan": 60, "avg_agents_density": 0.17948076397170606, "runtime": 1.5101223189994926}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1953, "makespan": 87, "avg_agents_density": 0.17905451042964285, "runtime": 2.4877577730367193}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 924, "makespan": 34, "avg_agents_density": 0.1479800170332907, "runtime": 0.788317485988955}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 3121, "makespan": 80, "avg_agents_density": 0.18486479719943513, "runtime": 4.733641042053932}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 3798, "makespan": 77, "avg_agents_density": 0.21593278454059728, "runtime": 4.303914457952487}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4417, "makespan": 128, "avg_agents_density": 0.1975788657035894, "runtime": 6.891519297001651}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2327, "makespan": 58, "avg_agents_density": 0.1962283057555683, "runtime": 2.8277942839777097}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3837, "makespan": 101, "avg_agents_density": 0.22975489576030966, "runtime": 5.533206038948265}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5339, "makespan": 128, "avg_agents_density": 0.20086627699799622, "runtime": 6.427317753885291}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 3954, "makespan": 128, "avg_agents_density": 0.1943732546841654, "runtime": 6.189179352979409}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 5502, "makespan": 128, "avg_agents_density": 0.19285558965856098, "runtime": 6.181040534022031}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 3433, "makespan": 83, "avg_agents_density": 0.20202619487974283, "runtime": 4.028393153974321}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2410, "makespan": 73, "avg_agents_density": 0.22371685395482954, "runtime": 3.465946636017179}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 4814, "makespan": 128, "avg_agents_density": 0.185904859657641, "runtime": 6.286502055882011}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 128, "SoC": 6745, "makespan": 128, "avg_agents_density": 0.37209032821556337, "runtime": 6.339480794937117}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2689, "makespan": 63, "avg_agents_density": 0.20429124474136523, "runtime": 3.0369337610463845}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2630, "makespan": 64, "avg_agents_density": 0.18970547404055269, "runtime": 3.080511073960224}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3122, "makespan": 99, "avg_agents_density": 0.19838630608256885, "runtime": 5.486084544085315}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 3140, "makespan": 81, "avg_agents_density": 0.19645584719383116, "runtime": 3.940417668054579}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4941, "makespan": 128, "avg_agents_density": 0.22132955305599383, "runtime": 6.308509774957201}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2313, "makespan": 68, "avg_agents_density": 0.1549499890520852, "runtime": 3.344100069036358}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 5194, "makespan": 128, "avg_agents_density": 0.18800794288531963, "runtime": 5.5082292539736954}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 6980, "makespan": 128, "avg_agents_density": 0.219964026378951, "runtime": 5.7611872569832485}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4230, "makespan": 128, "avg_agents_density": 0.1889797017984791, "runtime": 4.803068301043822}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 3347, "makespan": 98, "avg_agents_density": 0.19926781192027268, "runtime": 4.479479751957115}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1776, "makespan": 53, "avg_agents_density": 0.18880292782909866, "runtime": 2.667694646093878}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 3499, "makespan": 111, "avg_agents_density": 0.19380069936709685, "runtime": 5.403974868080695}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3662, "makespan": 128, "avg_agents_density": 0.19506086676268472, "runtime": 5.918641330979881}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 1013, "makespan": 34, "avg_agents_density": 0.1774844791525999, "runtime": 1.570659197983332}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2051, "makespan": 58, "avg_agents_density": 0.178320898448462, "runtime": 2.5936604110174812}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3903, "makespan": 128, "avg_agents_density": 0.17807963638094151, "runtime": 6.10044687797199}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 4136, "makespan": 117, "avg_agents_density": 0.19957409615069613, "runtime": 5.7287215279066}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 4219, "makespan": 111, "avg_agents_density": 0.21654735134109337, "runtime": 5.2910806798463454}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 3178, "makespan": 98, "avg_agents_density": 0.21604301972293266, "runtime": 4.825097991968505}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1686, "makespan": 62, "avg_agents_density": 0.19009729694643318, "runtime": 3.5765559490246233}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-64000"}]