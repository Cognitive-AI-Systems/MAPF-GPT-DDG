[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 646, "makespan": 60, "avg_agents_density": 0.09404617691798717, "runtime": 1.289492019044701}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 797, "makespan": 47, "avg_agents_density": 0.13130103852148856, "runtime": 0.6372645570081659}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 1041, "makespan": 128, "avg_agents_density": 0.08261033790228248, "runtime": 1.2605193797498941}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 585, "makespan": 32, "avg_agents_density": 0.11019171901645443, "runtime": 0.7052003330609296}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 856, "makespan": 48, "avg_agents_density": 0.10927589499146892, "runtime": 1.0411269139731303}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 1034, "makespan": 95, "avg_agents_density": 0.10408110360444434, "runtime": 1.1524033161404077}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 664, "makespan": 37, "avg_agents_density": 0.09679263462741983, "runtime": 0.4189378099399619}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1236, "makespan": 65, "avg_agents_density": 0.12339689737816041, "runtime": 1.4646047210262623}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 961, "makespan": 47, "avg_agents_density": 0.13073702525812286, "runtime": 0.6038627199886832}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 575, "makespan": 37, "avg_agents_density": 0.12717222140315337, "runtime": 0.4331313800648786}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 791, "makespan": 42, "avg_agents_density": 0.08242225295891344, "runtime": 0.8671202948899008}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1175, "makespan": 64, "avg_agents_density": 0.1607318121515951, "runtime": 0.8020346029952634}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 717, "makespan": 38, "avg_agents_density": 0.1098901132703883, "runtime": 0.8270489439601079}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 522, "makespan": 33, "avg_agents_density": 0.11359830689091237, "runtime": 0.7274770739313681}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 762, "makespan": 43, "avg_agents_density": 0.12524010342982578, "runtime": 0.4941540949221235}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 887, "makespan": 51, "avg_agents_density": 0.11384092035504774, "runtime": 0.576817331922939}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 703, "makespan": 34, "avg_agents_density": 0.11393629369950817, "runtime": 0.3872540719457902}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 760, "makespan": 58, "avg_agents_density": 0.09737750063131499, "runtime": 1.23998073983239}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 981, "makespan": 49, "avg_agents_density": 0.12297564831140541, "runtime": 1.0854708011320326}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 1375, "makespan": 88, "avg_agents_density": 0.11573209020761693, "runtime": 0.5002631940587889}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 835, "makespan": 48, "avg_agents_density": 0.09211660534225694, "runtime": 0.5503693521022797}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 876, "makespan": 50, "avg_agents_density": 0.1190070775922403, "runtime": 0.508714608324226}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 653, "makespan": 36, "avg_agents_density": 0.10025497615529724, "runtime": 0.30638314492534846}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 743, "makespan": 46, "avg_agents_density": 0.10704027926925687, "runtime": 1.0068299200502224}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 791, "makespan": 45, "avg_agents_density": 0.10150549818108073, "runtime": 0.9772041740070563}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 479, "makespan": 38, "avg_agents_density": 0.09231780600990447, "runtime": 0.4034713048604317}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 631, "makespan": 35, "avg_agents_density": 0.09476504643991063, "runtime": 0.541386420984054}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 977, "makespan": 62, "avg_agents_density": 0.09362508816393247, "runtime": 1.2803210211568512}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1013, "makespan": 69, "avg_agents_density": 0.09648537391949188, "runtime": 0.20566606594366021}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 903, "makespan": 54, "avg_agents_density": 0.10717309899040568, "runtime": 0.6155999999027699}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 699, "makespan": 117, "avg_agents_density": 0.10251290459931692, "runtime": 0.7160882350290194}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 585, "makespan": 32, "avg_agents_density": 0.11748818358778394, "runtime": 0.23370285498094745}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1151, "makespan": 60, "avg_agents_density": 0.14083836153413956, "runtime": 1.821066040894948}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1433, "makespan": 48, "avg_agents_density": 0.16315875516149092, "runtime": 1.1667587992269546}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1206, "makespan": 44, "avg_agents_density": 0.14837694609174154, "runtime": 1.0280152020277455}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1331, "makespan": 51, "avg_agents_density": 0.16991488535812993, "runtime": 1.1420292570546735}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1401, "makespan": 53, "avg_agents_density": 0.14509945196864324, "runtime": 1.4558082800358534}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1716, "makespan": 62, "avg_agents_density": 0.15822259879047895, "runtime": 1.6385848147037905}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1579, "makespan": 128, "avg_agents_density": 0.13978816961075308, "runtime": 2.9219368000049144}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 2803, "makespan": 100, "avg_agents_density": 0.158830606817711, "runtime": 2.663199169910513}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1645, "makespan": 62, "avg_agents_density": 0.18185448039654056, "runtime": 1.4849335720646195}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1187, "makespan": 54, "avg_agents_density": 0.17514309476458714, "runtime": 1.4205645639740396}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1491, "makespan": 68, "avg_agents_density": 0.1282024206097178, "runtime": 1.746859048056649}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.3958333333333333, "CSR": 0.0, "ep_length": 128, "SoC": 4249, "makespan": 128, "avg_agents_density": 0.33182575946185155, "runtime": 3.2610802409762982}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1434, "makespan": 57, "avg_agents_density": 0.16082318966417358, "runtime": 1.6725629149877932}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1124, "makespan": 40, "avg_agents_density": 0.15272082823535604, "runtime": 1.1284566309477668}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1387, "makespan": 48, "avg_agents_density": 0.18389800843357734, "runtime": 1.079377852001926}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1553, "makespan": 48, "avg_agents_density": 0.17211659501124146, "runtime": 1.4254115160147194}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1765, "makespan": 62, "avg_agents_density": 0.174299365307754, "runtime": 1.3505822440201882}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1023, "makespan": 39, "avg_agents_density": 0.12259439303085154, "runtime": 1.017258912033867}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2105, "makespan": 82, "avg_agents_density": 0.16124909955101036, "runtime": 2.164326860976871}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 125, "SoC": 4075, "makespan": 125, "avg_agents_density": 0.19278903425725855, "runtime": 2.4850824398745317}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1585, "makespan": 63, "avg_agents_density": 0.1463129532082265, "runtime": 1.3851594501174986}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2078, "makespan": 81, "avg_agents_density": 0.17464599194994282, "runtime": 1.6759623300749809}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1166, "makespan": 57, "avg_agents_density": 0.14090955640519282, "runtime": 1.376340578077361}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1496, "makespan": 45, "avg_agents_density": 0.17208507292804978, "runtime": 0.9311933330900501}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1593, "makespan": 58, "avg_agents_density": 0.16400070492776203, "runtime": 1.350396351859672}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 630, "makespan": 30, "avg_agents_density": 0.13783655668213687, "runtime": 0.7372913360595703}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1015, "makespan": 42, "avg_agents_density": 0.13317752692971327, "runtime": 1.1933992499834858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1711, "makespan": 78, "avg_agents_density": 0.1374393112125053, "runtime": 1.697808359109331}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2454, "makespan": 89, "avg_agents_density": 0.1489381888575307, "runtime": 2.007096726913005}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1692, "makespan": 58, "avg_agents_density": 0.16321741944454957, "runtime": 1.2898803151329048}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1256, "makespan": 51, "avg_agents_density": 0.17834610816322924, "runtime": 1.120737839024514}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 798, "makespan": 32, "avg_agents_density": 0.14620263084922736, "runtime": 0.6491867499717046}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2202, "makespan": 65, "avg_agents_density": 0.1782481781463529, "runtime": 2.3676712780143134}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2428, "makespan": 73, "avg_agents_density": 0.21361055092686998, "runtime": 2.5688479550590273}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2534, "makespan": 88, "avg_agents_density": 0.19720286942964402, "runtime": 3.089947912900243}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2221, "makespan": 68, "avg_agents_density": 0.19973574750549386, "runtime": 2.419707104068948}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 128, "SoC": 4784, "makespan": 128, "avg_agents_density": 0.2874812766396131, "runtime": 4.229653389833402}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 4731, "makespan": 128, "avg_agents_density": 0.21289123969189916, "runtime": 4.3158176648721565}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2705, "makespan": 87, "avg_agents_density": 0.19101271650838675, "runtime": 2.7375667831511237}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 128, "SoC": 5498, "makespan": 128, "avg_agents_density": 0.22175476486474952, "runtime": 4.035219845158281}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3022, "makespan": 94, "avg_agents_density": 0.2093087691111961, "runtime": 2.9516230459848884}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 3453, "makespan": 103, "avg_agents_density": 0.24286428089909198, "runtime": 3.2294122148305178}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 4132, "makespan": 128, "avg_agents_density": 0.2263030037114445, "runtime": 4.026461558911251}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 128, "SoC": 7102, "makespan": 128, "avg_agents_density": 0.42148670117336856, "runtime": 4.024092468986055}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 3418, "makespan": 128, "avg_agents_density": 0.20463676770493938, "runtime": 4.019159392977599}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1986, "makespan": 53, "avg_agents_density": 0.19637618005689006, "runtime": 1.6646997578791343}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 2834, "makespan": 109, "avg_agents_density": 0.21365247977654844, "runtime": 3.693761927977903}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 3316, "makespan": 78, "avg_agents_density": 0.2346936395995738, "runtime": 2.396349670016207}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 128, "SoC": 5042, "makespan": 128, "avg_agents_density": 0.2698867457345252, "runtime": 3.975590752874268}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1557, "makespan": 46, "avg_agents_density": 0.14849561267839595, "runtime": 1.446060637041228}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4732, "makespan": 128, "avg_agents_density": 0.18120105848829013, "runtime": 3.50221776185208}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 6774, "makespan": 128, "avg_agents_density": 0.2208018530652604, "runtime": 3.7008565749856643}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2584, "makespan": 86, "avg_agents_density": 0.1881965913107305, "runtime": 2.425628292025067}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 3010, "makespan": 100, "avg_agents_density": 0.20851414279083993, "runtime": 2.9132026550360024}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1829, "makespan": 72, "avg_agents_density": 0.18291339797333458, "runtime": 2.1826603660010733}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2734, "makespan": 61, "avg_agents_density": 0.21266012050785904, "runtime": 1.9171073820325546}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4483, "makespan": 128, "avg_agents_density": 0.19449747481257973, "runtime": 3.8070402337471023}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 896, "makespan": 31, "avg_agents_density": 0.18158456206726636, "runtime": 0.9611008230422158}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2171, "makespan": 78, "avg_agents_density": 0.17160550614188333, "runtime": 2.307175044872565}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3257, "makespan": 99, "avg_agents_density": 0.1901088238590286, "runtime": 2.9842471140727866}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 4488, "makespan": 113, "avg_agents_density": 0.21716232848872596, "runtime": 3.5119308287394233}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4221, "makespan": 128, "avg_agents_density": 0.2224612299349452, "runtime": 3.8996156819921453}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 3182, "makespan": 128, "avg_agents_density": 0.22045590655232092, "runtime": 4.032477266067872}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-standard-392000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 3096, "makespan": 104, "avg_agents_density": 0.19707376837867074, "runtime": 3.5506019417662174}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-standard-392000"}]