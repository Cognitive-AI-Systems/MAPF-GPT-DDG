[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 727, "makespan": 37, "avg_agents_density": 0.09676604503164812, "runtime": 0.9904388849390671}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 796, "makespan": 39, "avg_agents_density": 0.12413973342789711, "runtime": 0.7329017507727258}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 798, "makespan": 65, "avg_agents_density": 0.08727113420217317, "runtime": 1.5107930699596182}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 758, "makespan": 54, "avg_agents_density": 0.10586920588142563, "runtime": 2.1414802230428904}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 819, "makespan": 44, "avg_agents_density": 0.11101265490110733, "runtime": 1.50959126802627}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 975, "makespan": 54, "avg_agents_density": 0.10447593263140795, "runtime": 0.9911634310265072}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1016, "makespan": 68, "avg_agents_density": 0.10394809632980528, "runtime": 2.0139778887387365}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1211, "makespan": 74, "avg_agents_density": 0.10554708868368842, "runtime": 2.6804624368669465}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1147, "makespan": 53, "avg_agents_density": 0.11552494061748465, "runtime": 1.9394287287723273}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 712, "makespan": 39, "avg_agents_density": 0.1237932271455219, "runtime": 1.20632255054079}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 749, "makespan": 54, "avg_agents_density": 0.08523695045316647, "runtime": 1.3681744020432234}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 1158, "makespan": 93, "avg_agents_density": 0.13189909403445924, "runtime": 3.0932580183725804}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 707, "makespan": 35, "avg_agents_density": 0.10515303184095354, "runtime": 1.3522356138564646}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 676, "makespan": 35, "avg_agents_density": 0.10986458142593208, "runtime": 1.1977115919580683}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 697, "makespan": 40, "avg_agents_density": 0.12603287939118885, "runtime": 0.7745108199887909}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1010, "makespan": 61, "avg_agents_density": 0.10750626525148872, "runtime": 1.7030931601766497}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 705, "makespan": 34, "avg_agents_density": 0.11676536404836609, "runtime": 1.1977806377690285}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 720, "makespan": 45, "avg_agents_density": 0.09198845283059477, "runtime": 1.385124382970389}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1173, "makespan": 68, "avg_agents_density": 0.1170043261557334, "runtime": 2.053272525081411}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1240, "makespan": 82, "avg_agents_density": 0.11031588340083141, "runtime": 1.3258063119719736}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 784, "makespan": 48, "avg_agents_density": 0.0922318896597074, "runtime": 0.929468575050123}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 839, "makespan": 38, "avg_agents_density": 0.11771902964320148, "runtime": 0.6791596089024097}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 713, "makespan": 44, "avg_agents_density": 0.09755388067396759, "runtime": 0.7463313339394517}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 725, "makespan": 41, "avg_agents_density": 0.11403423426973637, "runtime": 1.3349540809867904}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 841, "makespan": 56, "avg_agents_density": 0.0977565700827076, "runtime": 1.7047919469187036}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 439, "makespan": 30, "avg_agents_density": 0.09406097724207152, "runtime": 0.9162070918828249}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 733, "makespan": 44, "avg_agents_density": 0.09218226856795554, "runtime": 1.04405739082722}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 916, "makespan": 57, "avg_agents_density": 0.08924745239443817, "runtime": 1.7647177930921316}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1005, "makespan": 52, "avg_agents_density": 0.0863742805643897, "runtime": 0.771774988155812}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 766, "makespan": 37, "avg_agents_density": 0.10822463362289723, "runtime": 0.5991644291207194}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 824, "makespan": 42, "avg_agents_density": 0.11403653975813369, "runtime": 0.8605363182141446}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 548, "makespan": 27, "avg_agents_density": 0.11524514242882747, "runtime": 0.3661356961238198}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1721, "makespan": 56, "avg_agents_density": 0.14578411711871941, "runtime": 2.316347745829262}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1541, "makespan": 51, "avg_agents_density": 0.16248199513944075, "runtime": 1.8821181998355314}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1350, "makespan": 47, "avg_agents_density": 0.14388799136057132, "runtime": 2.039477410085965}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1501, "makespan": 58, "avg_agents_density": 0.16847276678975587, "runtime": 2.3203397316974588}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1458, "makespan": 54, "avg_agents_density": 0.14984466944326474, "runtime": 2.3428478413261473}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2221, "makespan": 79, "avg_agents_density": 0.15373748407676685, "runtime": 3.525312806246802}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1471, "makespan": 64, "avg_agents_density": 0.14325213238295031, "runtime": 2.609843954036478}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3028, "makespan": 128, "avg_agents_density": 0.15561487075384917, "runtime": 5.159130665240809}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1553, "makespan": 53, "avg_agents_density": 0.1702139818826158, "runtime": 2.1163974920636974}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1346, "makespan": 47, "avg_agents_density": 0.17324219826953172, "runtime": 2.118422025232576}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1458, "makespan": 56, "avg_agents_density": 0.12818957382848292, "runtime": 2.439554443815723}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 128, "SoC": 4281, "makespan": 128, "avg_agents_density": 0.31499200495010665, "runtime": 5.593973865674343}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1359, "makespan": 53, "avg_agents_density": 0.16420965171898866, "runtime": 2.305679949000478}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1662, "makespan": 58, "avg_agents_density": 0.15386318787012665, "runtime": 2.4382440610206686}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1526, "makespan": 48, "avg_agents_density": 0.17424756241100015, "runtime": 1.9396194082219154}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2092, "makespan": 85, "avg_agents_density": 0.16298322966631323, "runtime": 3.633728210348636}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1942, "makespan": 60, "avg_agents_density": 0.16889217443462823, "runtime": 2.370563342818059}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1371, "makespan": 59, "avg_agents_density": 0.12665779243325465, "runtime": 2.4965951872291043}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2194, "makespan": 81, "avg_agents_density": 0.15830216867613625, "runtime": 3.375219708948862}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2967, "makespan": 91, "avg_agents_density": 0.17420559973256752, "runtime": 3.0559504730044864}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 1884, "makespan": 102, "avg_agents_density": 0.14024136522290834, "runtime": 3.3719499174621888}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1686, "makespan": 59, "avg_agents_density": 0.1599709251124616, "runtime": 2.351879058405757}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1304, "makespan": 45, "avg_agents_density": 0.15105287722773927, "runtime": 1.9342896718299016}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1548, "makespan": 49, "avg_agents_density": 0.17225541230298103, "runtime": 1.662171873904299}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1762, "makespan": 72, "avg_agents_density": 0.1538189666986621, "runtime": 2.9139072868274525}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 670, "makespan": 30, "avg_agents_density": 0.13700006654504687, "runtime": 1.319866045145318}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1211, "makespan": 54, "avg_agents_density": 0.129681220230114, "runtime": 2.3994552668882534}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3248, "makespan": 128, "avg_agents_density": 0.14882557739686825, "runtime": 4.458377673465293}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2265, "makespan": 86, "avg_agents_density": 0.14127289717439864, "runtime": 3.194523275073152}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2039, "makespan": 91, "avg_agents_density": 0.15384794480148448, "runtime": 3.479096765338909}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1797, "makespan": 67, "avg_agents_density": 0.18022871876615193, "runtime": 2.672905034967698}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1358, "makespan": 55, "avg_agents_density": 0.1539265929352487, "runtime": 2.21765889483504}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 3051, "makespan": 80, "avg_agents_density": 0.18409756754176765, "runtime": 4.066788114258088}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3556, "makespan": 101, "avg_agents_density": 0.2108110018479486, "runtime": 5.173901850183029}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 5433, "makespan": 128, "avg_agents_density": 0.23858866053187988, "runtime": 6.27673919708468}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2831, "makespan": 70, "avg_agents_density": 0.21578822932324537, "runtime": 3.914785106142517}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 4444, "makespan": 128, "avg_agents_density": 0.27194268191975723, "runtime": 5.902213784342166}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4762, "makespan": 128, "avg_agents_density": 0.20176326375407294, "runtime": 6.444463884050492}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 3322, "makespan": 103, "avg_agents_density": 0.19191249321883871, "runtime": 4.3698807042092085}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 128, "SoC": 6362, "makespan": 128, "avg_agents_density": 0.21112643534078682, "runtime": 5.511225983675104}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2959, "makespan": 73, "avg_agents_density": 0.21106237800065583, "runtime": 3.081152494996786}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2711, "makespan": 74, "avg_agents_density": 0.2242553973753984, "runtime": 2.955756948213093}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2466, "makespan": 75, "avg_agents_density": 0.1744097116899216, "runtime": 3.377403013932053}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 128, "SoC": 6190, "makespan": 128, "avg_agents_density": 0.3383174140703884, "runtime": 5.288685677747708}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 3742, "makespan": 120, "avg_agents_density": 0.20503687701788448, "runtime": 5.359436671657022}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2731, "makespan": 97, "avg_agents_density": 0.1967554590967865, "runtime": 4.272890332678799}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 2396, "makespan": 98, "avg_agents_density": 0.2035412193620988, "runtime": 5.045706580567639}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4247, "makespan": 128, "avg_agents_density": 0.20894990626459237, "runtime": 5.891174129093997}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 5744, "makespan": 128, "avg_agents_density": 0.22061318410120986, "runtime": 5.537153773766477}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2045, "makespan": 67, "avg_agents_density": 0.15363581858555334, "runtime": 3.057217884110287}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 5258, "makespan": 128, "avg_agents_density": 0.202466513979051, "runtime": 5.726937392435502}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 5636, "makespan": 128, "avg_agents_density": 0.20536297184864327, "runtime": 5.577148036914878}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4032, "makespan": 128, "avg_agents_density": 0.18393178901425736, "runtime": 5.85419281932991}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 3230, "makespan": 68, "avg_agents_density": 0.21254795705160068, "runtime": 2.872359922796022}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1756, "makespan": 51, "avg_agents_density": 0.18015770054276625, "runtime": 2.5272644360084087}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 3118, "makespan": 82, "avg_agents_density": 0.20461911409578362, "runtime": 3.699414129718207}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4064, "makespan": 128, "avg_agents_density": 0.1931389080846838, "runtime": 5.858826500130817}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1041, "makespan": 36, "avg_agents_density": 0.18428648096816277, "runtime": 1.540404943865724}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1943, "makespan": 53, "avg_agents_density": 0.16845076909460233, "runtime": 2.464733049913775}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4635, "makespan": 128, "avg_agents_density": 0.1854588827938875, "runtime": 5.650986823369749}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4185, "makespan": 128, "avg_agents_density": 0.19570132214185385, "runtime": 5.607987290772144}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 4941, "makespan": 126, "avg_agents_density": 0.2350043281100564, "runtime": 5.833010285627097}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 3368, "makespan": 119, "avg_agents_density": 0.21655354265301308, "runtime": 5.013154501153622}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1507, "makespan": 51, "avg_agents_density": 0.18853792972020236, "runtime": 2.880711277073715}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-192000"}]