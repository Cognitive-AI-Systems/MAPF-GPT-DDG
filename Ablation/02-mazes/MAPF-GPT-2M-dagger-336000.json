[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 651, "makespan": 36, "avg_agents_density": 0.09825966026943168, "runtime": 1.2285635680309497}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 963, "makespan": 57, "avg_agents_density": 0.11972023007153294, "runtime": 1.9381896730483277}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 811, "makespan": 55, "avg_agents_density": 0.0861343428336915, "runtime": 1.8284410980559187}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 732, "makespan": 46, "avg_agents_density": 0.10252366978862702, "runtime": 1.6048634409817168}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 881, "makespan": 47, "avg_agents_density": 0.10890438733691131, "runtime": 1.4461168380366871}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 979, "makespan": 47, "avg_agents_density": 0.11533682544715418, "runtime": 1.5843473010027083}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 744, "makespan": 51, "avg_agents_density": 0.09576153003634222, "runtime": 1.6499333329993533}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1293, "makespan": 74, "avg_agents_density": 0.10457385957301114, "runtime": 2.6090621940384153}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 985, "makespan": 50, "avg_agents_density": 0.1131866748099047, "runtime": 1.8875712640001439}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 713, "makespan": 40, "avg_agents_density": 0.12193963553799063, "runtime": 1.2827105390897486}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 888, "makespan": 61, "avg_agents_density": 0.0884385484752397, "runtime": 2.1166486220172374}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1008, "makespan": 53, "avg_agents_density": 0.1406510572385226, "runtime": 1.7886372879729606}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 680, "makespan": 35, "avg_agents_density": 0.10672121873997895, "runtime": 1.3242313640512293}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 664, "makespan": 42, "avg_agents_density": 0.111897827259541, "runtime": 1.4049384399550036}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 726, "makespan": 38, "avg_agents_density": 0.11661847331797773, "runtime": 1.281287463993067}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 928, "makespan": 51, "avg_agents_density": 0.11135721354863166, "runtime": 1.2369088780251332}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 878, "makespan": 40, "avg_agents_density": 0.11776558047000346, "runtime": 1.3387131289637182}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 827, "makespan": 53, "avg_agents_density": 0.08924132913557453, "runtime": 1.4072474810527638}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1448, "makespan": 73, "avg_agents_density": 0.12274815757054272, "runtime": 2.4973568740097107}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1038, "makespan": 53, "avg_agents_density": 0.11106824213751888, "runtime": 1.6492256720812293}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 882, "makespan": 56, "avg_agents_density": 0.08912432830872037, "runtime": 1.8881420950347092}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1042, "makespan": 53, "avg_agents_density": 0.10925654535566957, "runtime": 0.5719233650306705}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 645, "makespan": 39, "avg_agents_density": 0.09775430058984158, "runtime": 1.2001265930593945}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 842, "makespan": 51, "avg_agents_density": 0.1088127397825159, "runtime": 1.734286914987024}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 894, "makespan": 59, "avg_agents_density": 0.09886005795958473, "runtime": 1.9660396859544562}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 434, "makespan": 29, "avg_agents_density": 0.0951868856986272, "runtime": 1.004629382994608}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 719, "makespan": 43, "avg_agents_density": 0.09459807002483328, "runtime": 0.5141100890323287}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 926, "makespan": 57, "avg_agents_density": 0.08927729860619359, "runtime": 1.7196238989854464}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1070, "makespan": 67, "avg_agents_density": 0.09475904858632916, "runtime": 1.122595413995441}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 816, "makespan": 36, "avg_agents_density": 0.11163573693016038, "runtime": 1.1597405189677374}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 725, "makespan": 43, "avg_agents_density": 0.10955363016895632, "runtime": 0.18452574699767865}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 523, "makespan": 26, "avg_agents_density": 0.11437976141013974, "runtime": 0.741255932036438}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1332, "makespan": 47, "avg_agents_density": 0.14560428628172378, "runtime": 2.405891557049472}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1759, "makespan": 50, "avg_agents_density": 0.15641544209892574, "runtime": 1.6355493920564186}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1321, "makespan": 56, "avg_agents_density": 0.1443109261159281, "runtime": 2.0752902549575083}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1401, "makespan": 50, "avg_agents_density": 0.16495922070060406, "runtime": 1.840455372017459}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1779, "makespan": 66, "avg_agents_density": 0.1480231700951881, "runtime": 2.4893465130589902}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2665, "makespan": 91, "avg_agents_density": 0.15465314858858137, "runtime": 3.265255481019267}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1151, "makespan": 49, "avg_agents_density": 0.1387899756279349, "runtime": 1.733660878977389}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2669, "makespan": 78, "avg_agents_density": 0.15020559369426364, "runtime": 3.4451723959791707}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1634, "makespan": 55, "avg_agents_density": 0.17197917917053868, "runtime": 2.126963597984286}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1374, "makespan": 55, "avg_agents_density": 0.1761129472260436, "runtime": 2.1257720610301476}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1346, "makespan": 58, "avg_agents_density": 0.1228456986210993, "runtime": 2.520903927012114}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.7708333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4284, "makespan": 128, "avg_agents_density": 0.24819244587112324, "runtime": 5.152518712973688}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1549, "makespan": 57, "avg_agents_density": 0.1631634741184424, "runtime": 2.199781593051739}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1169, "makespan": 41, "avg_agents_density": 0.1478179562631204, "runtime": 1.5646638860634994}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1474, "makespan": 55, "avg_agents_density": 0.16869595608951052, "runtime": 1.9815489650063682}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1546, "makespan": 50, "avg_agents_density": 0.15708689417406255, "runtime": 2.0140994699759176}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2137, "makespan": 79, "avg_agents_density": 0.17889731496600095, "runtime": 2.744806740010972}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1206, "makespan": 52, "avg_agents_density": 0.11837258260226388, "runtime": 1.7325653890293324}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2146, "makespan": 67, "avg_agents_density": 0.158669107639021, "runtime": 2.4034770669968566}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3410, "makespan": 99, "avg_agents_density": 0.18502558060420252, "runtime": 3.2937964938755613}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1699, "makespan": 65, "avg_agents_density": 0.14227356119776, "runtime": 2.4482641099457396}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1704, "makespan": 58, "avg_agents_density": 0.15404806256435463, "runtime": 2.1260231039195787}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1187, "makespan": 48, "avg_agents_density": 0.14608268451910128, "runtime": 1.8548691310570575}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1653, "makespan": 54, "avg_agents_density": 0.17568852912346378, "runtime": 1.8923015820037108}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1837, "makespan": 91, "avg_agents_density": 0.15280413385602637, "runtime": 3.2537054511049064}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 676, "makespan": 30, "avg_agents_density": 0.13801655652277114, "runtime": 1.150339322979562}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1205, "makespan": 52, "avg_agents_density": 0.13346904837140802, "runtime": 1.8768594760331325}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1585, "makespan": 59, "avg_agents_density": 0.13215115208355768, "runtime": 2.3004639490391128}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2433, "makespan": 92, "avg_agents_density": 0.14503450993551653, "runtime": 3.269507103948854}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1887, "makespan": 53, "avg_agents_density": 0.16865956866802326, "runtime": 1.933160191954812}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1494, "makespan": 49, "avg_agents_density": 0.187258750908467, "runtime": 2.0446682851033984}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 871, "makespan": 32, "avg_agents_density": 0.14686783305548698, "runtime": 1.3792380489612697}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2692, "makespan": 71, "avg_agents_density": 0.18214056189834585, "runtime": 3.937193113961257}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 3214, "makespan": 75, "avg_agents_density": 0.20547648110418334, "runtime": 4.281147612971836}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2809, "makespan": 74, "avg_agents_density": 0.20394104185785647, "runtime": 4.118914601029246}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 2217, "makespan": 52, "avg_agents_density": 0.19675660428454303, "runtime": 3.9631216249399586}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 3819, "makespan": 93, "avg_agents_density": 0.23700211069605806, "runtime": 5.187115820925101}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4562, "makespan": 128, "avg_agents_density": 0.2044599020825784, "runtime": 6.99803970711946}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2324, "makespan": 59, "avg_agents_density": 0.18382740440186401, "runtime": 2.9429132440127432}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 5897, "makespan": 128, "avg_agents_density": 0.2359680086452029, "runtime": 5.983684781996999}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2395, "makespan": 55, "avg_agents_density": 0.20451576676275485, "runtime": 2.5972724460152676}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2434, "makespan": 68, "avg_agents_density": 0.21688553096262564, "runtime": 3.434484808021807}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 3621, "makespan": 98, "avg_agents_density": 0.17654724387131018, "runtime": 4.8099826869001845}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.359375, "CSR": 0.0, "ep_length": 128, "SoC": 6484, "makespan": 128, "avg_agents_density": 0.3434034148591322, "runtime": 6.233093221846502}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2669, "makespan": 62, "avg_agents_density": 0.20455327769186915, "runtime": 3.184580829984043}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2150, "makespan": 56, "avg_agents_density": 0.18778307925728902, "runtime": 2.6746367840096354}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 2720, "makespan": 128, "avg_agents_density": 0.19793025007673418, "runtime": 6.907352348061977}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 3078, "makespan": 73, "avg_agents_density": 0.20612098168790818, "runtime": 3.7745988069218583}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 4341, "makespan": 102, "avg_agents_density": 0.23202786848255602, "runtime": 4.7582347620336805}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1814, "makespan": 57, "avg_agents_density": 0.15224527781736247, "runtime": 2.746818527128198}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4407, "makespan": 128, "avg_agents_density": 0.19284628552506555, "runtime": 5.756988023000304}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 4814, "makespan": 113, "avg_agents_density": 0.1950300267771529, "runtime": 4.768299109040527}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2712, "makespan": 77, "avg_agents_density": 0.1848538907331093, "runtime": 3.7649573138332926}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2458, "makespan": 64, "avg_agents_density": 0.19661369592320593, "runtime": 3.140372032983578}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1752, "makespan": 53, "avg_agents_density": 0.17628850117313666, "runtime": 2.5978644339484163}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 3213, "makespan": 93, "avg_agents_density": 0.20497527137553, "runtime": 4.31079536996549}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 3710, "makespan": 128, "avg_agents_density": 0.1936622964213975, "runtime": 6.05517254989536}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 961, "makespan": 34, "avg_agents_density": 0.18543831832614588, "runtime": 1.3826825040450785}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1922, "makespan": 58, "avg_agents_density": 0.16845844251517575, "runtime": 2.2643442460976075}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 3593, "makespan": 104, "avg_agents_density": 0.1711626522545732, "runtime": 4.738143417955143}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 5630, "makespan": 128, "avg_agents_density": 0.22224112185669223, "runtime": 6.163600102052442}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2915, "makespan": 70, "avg_agents_density": 0.20283972122500563, "runtime": 3.1371131019986933}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3976, "makespan": 128, "avg_agents_density": 0.2206506777241387, "runtime": 6.117416911147302}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1769, "makespan": 56, "avg_agents_density": 0.19594577612302855, "runtime": 3.1504529149387963}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-336000"}]