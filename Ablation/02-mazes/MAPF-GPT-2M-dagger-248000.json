[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 731, "makespan": 42, "avg_agents_density": 0.10158913729764123, "runtime": 0.699249040990253}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 803, "makespan": 47, "avg_agents_density": 0.12058704633058552, "runtime": 0.6476689680566778}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 909, "makespan": 75, "avg_agents_density": 0.0854698566999913, "runtime": 1.1613182529690675}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 658, "makespan": 37, "avg_agents_density": 0.1139850763695735, "runtime": 1.1173960470332531}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 833, "makespan": 57, "avg_agents_density": 0.09999908662615499, "runtime": 1.5663846200186526}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1153, "makespan": 68, "avg_agents_density": 0.10795913476989945, "runtime": 1.5908386788942153}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 803, "makespan": 57, "avg_agents_density": 0.09289916920373509, "runtime": 1.3892234570375877}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1103, "makespan": 63, "avg_agents_density": 0.10765981164533997, "runtime": 1.778347946019494}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 985, "makespan": 43, "avg_agents_density": 0.12076496132611635, "runtime": 1.2023915500030853}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 787, "makespan": 43, "avg_agents_density": 0.12630606763733956, "runtime": 1.0289512640592875}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 866, "makespan": 59, "avg_agents_density": 0.0888033662668365, "runtime": 0.9528511799580883}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1185, "makespan": 57, "avg_agents_density": 0.14259001479511887, "runtime": 1.3766832040273584}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 729, "makespan": 37, "avg_agents_density": 0.1032854101609404, "runtime": 1.0197631150076631}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 666, "makespan": 34, "avg_agents_density": 0.1083520966469003, "runtime": 0.9835380710137542}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 684, "makespan": 45, "avg_agents_density": 0.12010595622670836, "runtime": 0.7753532230271958}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1220, "makespan": 63, "avg_agents_density": 0.11406492071534928, "runtime": 0.9815238440205576}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 847, "makespan": 47, "avg_agents_density": 0.11886203385012534, "runtime": 0.884907272993587}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 657, "makespan": 44, "avg_agents_density": 0.09186501156598002, "runtime": 0.9823211869370425}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1054, "makespan": 56, "avg_agents_density": 0.11978431450597465, "runtime": 1.451910384974326}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1160, "makespan": 58, "avg_agents_density": 0.10830768491514081, "runtime": 0.6597899240005063}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 892, "makespan": 57, "avg_agents_density": 0.08918778825970146, "runtime": 0.4300567420432344}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 980, "makespan": 50, "avg_agents_density": 0.10704599807272909, "runtime": 0.6281573399755871}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 633, "makespan": 38, "avg_agents_density": 0.09425200078442439, "runtime": 0.4996181809838163}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 854, "makespan": 48, "avg_agents_density": 0.11559185868103915, "runtime": 1.1514756479882635}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 914, "makespan": 55, "avg_agents_density": 0.09804175321372847, "runtime": 1.2370501020195661}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 440, "makespan": 29, "avg_agents_density": 0.09435127088807332, "runtime": 0.4276562040031422}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 855, "makespan": 47, "avg_agents_density": 0.10126914887576992, "runtime": 1.0452251550159417}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 980, "makespan": 59, "avg_agents_density": 0.09007437902746543, "runtime": 1.3277140040445374}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1066, "makespan": 56, "avg_agents_density": 0.0911032217490304, "runtime": 0.33034884398512077}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1090, "makespan": 55, "avg_agents_density": 0.10381529413333128, "runtime": 0.2930423939105822}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 725, "makespan": 36, "avg_agents_density": 0.11692564796483988, "runtime": 0.2738304819649784}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 536, "makespan": 27, "avg_agents_density": 0.11445654238971135, "runtime": 0.3894473679974908}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1340, "makespan": 54, "avg_agents_density": 0.14626552771617235, "runtime": 1.832294414009084}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1491, "makespan": 44, "avg_agents_density": 0.15985497775434387, "runtime": 1.3365119380760007}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1404, "makespan": 82, "avg_agents_density": 0.1391868871691337, "runtime": 2.3261811151896836}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1233, "makespan": 43, "avg_agents_density": 0.16470999673046124, "runtime": 1.190025273084757}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1740, "makespan": 76, "avg_agents_density": 0.14306961722300277, "runtime": 2.474032229874865}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2169, "makespan": 68, "avg_agents_density": 0.16254898469573617, "runtime": 2.209385486014071}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1186, "makespan": 52, "avg_agents_density": 0.1420355007696517, "runtime": 1.4978326560085407}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2590, "makespan": 79, "avg_agents_density": 0.1521294662189261, "runtime": 2.4499598670226987}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1612, "makespan": 51, "avg_agents_density": 0.1656389268422999, "runtime": 1.6705829279671889}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1373, "makespan": 45, "avg_agents_density": 0.17774051379586106, "runtime": 1.3605053380306344}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1395, "makespan": 63, "avg_agents_density": 0.12199023586606991, "runtime": 2.005407365024439}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4807, "makespan": 128, "avg_agents_density": 0.2778777741635088, "runtime": 4.059249404992443}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1415, "makespan": 55, "avg_agents_density": 0.16369736968049522, "runtime": 1.8709793140151305}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1458, "makespan": 46, "avg_agents_density": 0.14505344393968983, "runtime": 1.5714695130009204}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1253, "makespan": 42, "avg_agents_density": 0.17304169519885998, "runtime": 1.2312796929909382}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1835, "makespan": 80, "avg_agents_density": 0.16476347503923547, "runtime": 2.7335666670114733}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1680, "makespan": 58, "avg_agents_density": 0.16558872981186296, "runtime": 1.6927625380485551}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1237, "makespan": 47, "avg_agents_density": 0.12522759213163223, "runtime": 1.4558204999775626}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2619, "makespan": 95, "avg_agents_density": 0.16147779140787508, "runtime": 2.757648506973055}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2675, "makespan": 85, "avg_agents_density": 0.16682293656940847, "runtime": 2.175319279092946}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1687, "makespan": 70, "avg_agents_density": 0.14289289799603022, "runtime": 1.6135215830872767}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2026, "makespan": 75, "avg_agents_density": 0.15705255483133418, "runtime": 1.985012190969428}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1132, "makespan": 44, "avg_agents_density": 0.1419505964697175, "runtime": 1.218424527993193}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1588, "makespan": 48, "avg_agents_density": 0.18117333577348688, "runtime": 1.3009777120314538}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 2311, "makespan": 94, "avg_agents_density": 0.15764696155155805, "runtime": 2.894995708949864}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 664, "makespan": 29, "avg_agents_density": 0.1349286316925924, "runtime": 0.8354348690627376}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1329, "makespan": 61, "avg_agents_density": 0.1322436011813186, "runtime": 1.7632973740546731}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 3030, "makespan": 109, "avg_agents_density": 0.15250655171712446, "runtime": 3.1717105089628603}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2626, "makespan": 92, "avg_agents_density": 0.1507748814187834, "runtime": 2.765518392014201}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2368, "makespan": 86, "avg_agents_density": 0.1482430273729004, "runtime": 2.376930467056809}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1690, "makespan": 66, "avg_agents_density": 0.17490783487684022, "runtime": 1.9623277859209338}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 878, "makespan": 33, "avg_agents_density": 0.14686796485413917, "runtime": 0.9935548449720955}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2636, "makespan": 69, "avg_agents_density": 0.18511183452689883, "runtime": 2.989547796023544}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 3118, "makespan": 73, "avg_agents_density": 0.20784353531454616, "runtime": 3.2725505540147424}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3444, "makespan": 128, "avg_agents_density": 0.1950572137405963, "runtime": 4.704594258990255}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2239, "makespan": 61, "avg_agents_density": 0.20221370809212846, "runtime": 2.8481150150182657}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2311, "makespan": 56, "avg_agents_density": 0.19681856680425275, "runtime": 2.5158151580399135}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5560, "makespan": 128, "avg_agents_density": 0.20389726179436846, "runtime": 5.233318760001566}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4430, "makespan": 128, "avg_agents_density": 0.1988783174721191, "runtime": 4.838080653003999}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5411, "makespan": 128, "avg_agents_density": 0.19872705708096164, "runtime": 4.453491972919437}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2912, "makespan": 87, "avg_agents_density": 0.1965527958961006, "runtime": 3.3178747280180687}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2397, "makespan": 71, "avg_agents_density": 0.21418057799687942, "runtime": 2.601571494989912}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 3216, "makespan": 93, "avg_agents_density": 0.17669600427629986, "runtime": 3.292038636893267}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 128, "SoC": 7097, "makespan": 128, "avg_agents_density": 0.3729226856769926, "runtime": 4.501519399927929}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 3357, "makespan": 100, "avg_agents_density": 0.20230030876701793, "runtime": 3.693100854899967}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2456, "makespan": 71, "avg_agents_density": 0.1951554279921882, "runtime": 2.3240390839782776}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2274, "makespan": 57, "avg_agents_density": 0.2202485294625719, "runtime": 2.8199670610629255}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2771, "makespan": 73, "avg_agents_density": 0.19912342368877117, "runtime": 2.832873430059408}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.65625, "CSR": 0.0, "ep_length": 128, "SoC": 5351, "makespan": 128, "avg_agents_density": 0.24838558982304007, "runtime": 4.671946249975008}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2015, "makespan": 62, "avg_agents_density": 0.15560375257464176, "runtime": 2.298177172036958}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5670, "makespan": 128, "avg_agents_density": 0.19977098965428175, "runtime": 4.283015852997778}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 128, "SoC": 6677, "makespan": 128, "avg_agents_density": 0.2646290204976478, "runtime": 4.3062619760021335}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3935, "makespan": 128, "avg_agents_density": 0.18263075127163808, "runtime": 4.29293371005042}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2802, "makespan": 79, "avg_agents_density": 0.1991685207989528, "runtime": 2.637280227994779}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1658, "makespan": 46, "avg_agents_density": 0.18199850272841653, "runtime": 1.590118393971352}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2893, "makespan": 101, "avg_agents_density": 0.19031342033909512, "runtime": 3.7841073339805007}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3152, "makespan": 128, "avg_agents_density": 0.1975946462131515, "runtime": 4.402700652004569}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1070, "makespan": 35, "avg_agents_density": 0.18046531031449756, "runtime": 1.314407979050884}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2009, "makespan": 58, "avg_agents_density": 0.17689828954057338, "runtime": 1.9437992659659358}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 3158, "makespan": 120, "avg_agents_density": 0.17080492856317683, "runtime": 4.384168003933155}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3937, "makespan": 94, "avg_agents_density": 0.20173299780401507, "runtime": 3.5166516659228364}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 3476, "makespan": 108, "avg_agents_density": 0.20077759359021857, "runtime": 4.0018323949188925}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 3665, "makespan": 107, "avg_agents_density": 0.21694826599048667, "runtime": 3.8177089410019107}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1627, "makespan": 50, "avg_agents_density": 0.1963468131674808, "runtime": 2.2349087079783203}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-248000"}]