[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 736, "makespan": 42, "avg_agents_density": 0.09827228782460415, "runtime": 1.0510012509621447}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 906, "makespan": 51, "avg_agents_density": 0.12437507226695597, "runtime": 1.7278767690149834}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 775, "makespan": 42, "avg_agents_density": 0.09490648934368999, "runtime": 0.8983946510270471}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 624, "makespan": 39, "avg_agents_density": 0.10818183304734692, "runtime": 1.1903103820077376}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 946, "makespan": 51, "avg_agents_density": 0.1061564757118462, "runtime": 1.3010028419812443}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1042, "makespan": 62, "avg_agents_density": 0.10404853602338696, "runtime": 2.030896988901077}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 752, "makespan": 41, "avg_agents_density": 0.0948493493539086, "runtime": 0.8272968879900873}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1089, "makespan": 48, "avg_agents_density": 0.10532447836041096, "runtime": 1.4366785150341457}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 935, "makespan": 46, "avg_agents_density": 0.11609202586075905, "runtime": 1.0242256610508775}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 613, "makespan": 38, "avg_agents_density": 0.12643608275380475, "runtime": 0.764303287040093}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 797, "makespan": 44, "avg_agents_density": 0.08921328706441134, "runtime": 1.459743505998631}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 1108, "makespan": 84, "avg_agents_density": 0.13385891262569477, "runtime": 2.542021929897601}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 681, "makespan": 35, "avg_agents_density": 0.1129285400355991, "runtime": 1.0954186389717506}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 691, "makespan": 47, "avg_agents_density": 0.10679664557669626, "runtime": 1.4859267300053034}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 789, "makespan": 46, "avg_agents_density": 0.1264179766778111, "runtime": 1.352883913932601}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 873, "makespan": 45, "avg_agents_density": 0.10859153712631384, "runtime": 0.7575847879925277}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 713, "makespan": 35, "avg_agents_density": 0.11230224626391123, "runtime": 0.6397579319600482}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 804, "makespan": 52, "avg_agents_density": 0.09660058870331349, "runtime": 1.141184450010769}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1127, "makespan": 57, "avg_agents_density": 0.11906355206059768, "runtime": 1.8450986390234903}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1166, "makespan": 60, "avg_agents_density": 0.11973167355733758, "runtime": 1.232926878001308}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1043, "makespan": 73, "avg_agents_density": 0.09451341137808131, "runtime": 1.5870990360126598}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1061, "makespan": 59, "avg_agents_density": 0.12194793460770052, "runtime": 0.5557313689641887}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 634, "makespan": 35, "avg_agents_density": 0.09720567362509935, "runtime": 0.7524914870155044}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 814, "makespan": 44, "avg_agents_density": 0.11506807057667759, "runtime": 1.4551291120733367}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 819, "makespan": 47, "avg_agents_density": 0.09898077013975877, "runtime": 1.5539282119716518}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 422, "makespan": 31, "avg_agents_density": 0.09367114164165306, "runtime": 0.4600643599842442}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 704, "makespan": 43, "avg_agents_density": 0.09874675779297558, "runtime": 0.7737243419833248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 878, "makespan": 52, "avg_agents_density": 0.0888520759049482, "runtime": 1.7096511130221188}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1055, "makespan": 54, "avg_agents_density": 0.0903257986382971, "runtime": 0.8290209369442891}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1020, "makespan": 59, "avg_agents_density": 0.1032545585124751, "runtime": 1.12541659490671}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 598, "makespan": 36, "avg_agents_density": 0.11199121478135388, "runtime": 0.13830465298087802}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 524, "makespan": 27, "avg_agents_density": 0.11848126975874272, "runtime": 0.6034318360179896}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1523, "makespan": 59, "avg_agents_density": 0.14818961167368389, "runtime": 2.708279585975106}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1428, "makespan": 51, "avg_agents_density": 0.16409063621521816, "runtime": 1.6867306379135698}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1368, "makespan": 48, "avg_agents_density": 0.13996295949106075, "runtime": 2.05056236096425}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1395, "makespan": 50, "avg_agents_density": 0.15726207375780887, "runtime": 1.7101052369689569}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1398, "makespan": 53, "avg_agents_density": 0.14917906978269796, "runtime": 2.3059699019941036}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2427, "makespan": 128, "avg_agents_density": 0.1463885758618587, "runtime": 4.550988093978958}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1315, "makespan": 59, "avg_agents_density": 0.14247698053722013, "runtime": 1.9648026869544992}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3155, "makespan": 128, "avg_agents_density": 0.16251842083242632, "runtime": 5.058428473901586}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1495, "makespan": 55, "avg_agents_density": 0.17463224435918315, "runtime": 2.321232998991036}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1918, "makespan": 67, "avg_agents_density": 0.17526996786384372, "runtime": 2.4500098359567346}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1272, "makespan": 51, "avg_agents_density": 0.12809499626869092, "runtime": 2.2293775789876236}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.8333333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4102, "makespan": 128, "avg_agents_density": 0.22633378547915953, "runtime": 5.162544900042121}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1457, "makespan": 48, "avg_agents_density": 0.15954866548530441, "runtime": 2.2543321239645593}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1390, "makespan": 44, "avg_agents_density": 0.14546986338815468, "runtime": 1.8030134430155158}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1424, "makespan": 50, "avg_agents_density": 0.17515799059609385, "runtime": 1.7414126439689426}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1829, "makespan": 58, "avg_agents_density": 0.15602624638980786, "runtime": 2.3216693670401582}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 2783, "makespan": 109, "avg_agents_density": 0.17402761168000133, "runtime": 3.4437491690332536}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1257, "makespan": 45, "avg_agents_density": 0.12433800178827012, "runtime": 1.7324962559941923}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2571, "makespan": 89, "avg_agents_density": 0.16391217549586082, "runtime": 2.9367523041000823}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 4673, "makespan": 128, "avg_agents_density": 0.25557717795115353, "runtime": 3.4816174659645185}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1993, "makespan": 78, "avg_agents_density": 0.1409802354887733, "runtime": 2.4499625439493684}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1958, "makespan": 64, "avg_agents_density": 0.16929376269424712, "runtime": 2.040451419990859}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1037, "makespan": 45, "avg_agents_density": 0.14480880630703685, "runtime": 1.5431097050750395}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1445, "makespan": 45, "avg_agents_density": 0.16367545740098813, "runtime": 1.308221706043696}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1806, "makespan": 68, "avg_agents_density": 0.14830590361908794, "runtime": 2.240637102033361}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 691, "makespan": 32, "avg_agents_density": 0.13519484577864976, "runtime": 1.0362433360423893}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1431, "makespan": 57, "avg_agents_density": 0.12492973884978717, "runtime": 2.470947402936872}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1759, "makespan": 52, "avg_agents_density": 0.13374291954533443, "runtime": 1.7235905309789814}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2298, "makespan": 80, "avg_agents_density": 0.14008953905555002, "runtime": 2.5477861380495597}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1795, "makespan": 61, "avg_agents_density": 0.16603116945500102, "runtime": 2.101585496988264}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1390, "makespan": 45, "avg_agents_density": 0.17913003670972974, "runtime": 1.435214327982976}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 895, "makespan": 39, "avg_agents_density": 0.14386655237612417, "runtime": 1.2040277849300765}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2711, "makespan": 70, "avg_agents_density": 0.18597169255569357, "runtime": 2.7550600089743966}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 3178, "makespan": 72, "avg_agents_density": 0.21397148563562782, "runtime": 2.6285034099128097}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3607, "makespan": 92, "avg_agents_density": 0.2116775224534381, "runtime": 4.0677011140214745}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 2019, "makespan": 51, "avg_agents_density": 0.20245346346587226, "runtime": 1.9792566770047415}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2683, "makespan": 74, "avg_agents_density": 0.20925320617673146, "runtime": 2.9613499160768697}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 4714, "makespan": 128, "avg_agents_density": 0.20150826400303246, "runtime": 5.89492553799937}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 3753, "makespan": 123, "avg_agents_density": 0.19289508614959763, "runtime": 4.741925066991826}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 128, "SoC": 6356, "makespan": 128, "avg_agents_density": 0.2616078987962608, "runtime": 5.058095780026633}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2829, "makespan": 67, "avg_agents_density": 0.20536818605816198, "runtime": 3.1803259800653905}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2376, "makespan": 75, "avg_agents_density": 0.2161665264440523, "runtime": 3.114816716974019}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2291, "makespan": 72, "avg_agents_density": 0.16520305184614392, "runtime": 2.6559090280352393}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.390625, "CSR": 0.0, "ep_length": 128, "SoC": 6775, "makespan": 128, "avg_agents_density": 0.37853755998144134, "runtime": 4.955373835997307}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2696, "makespan": 71, "avg_agents_density": 0.1996058734814982, "runtime": 2.8429338699788786}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2428, "makespan": 64, "avg_agents_density": 0.1935886088060432, "runtime": 2.387529133964563}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 3101, "makespan": 103, "avg_agents_density": 0.2132780884969785, "runtime": 4.466858316984144}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3329, "makespan": 84, "avg_agents_density": 0.20624850129980585, "runtime": 4.067780726982164}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 128, "SoC": 6093, "makespan": 128, "avg_agents_density": 0.2758810029106727, "runtime": 5.6304852420289535}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1798, "makespan": 65, "avg_agents_density": 0.15264929070092087, "runtime": 3.1022073499916587}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 5557, "makespan": 128, "avg_agents_density": 0.22554847195795724, "runtime": 5.805519146990264}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 5777, "makespan": 128, "avg_agents_density": 0.22702927478006665, "runtime": 5.523539251065813}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 3392, "makespan": 113, "avg_agents_density": 0.20091341263960666, "runtime": 5.185331041982863}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 3314, "makespan": 76, "avg_agents_density": 0.2145363354577767, "runtime": 3.5694884350086795}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1641, "makespan": 61, "avg_agents_density": 0.1766263087285476, "runtime": 2.727089631051058}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 3440, "makespan": 87, "avg_agents_density": 0.1994565219756021, "runtime": 4.063140623024083}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4006, "makespan": 128, "avg_agents_density": 0.19899656706271066, "runtime": 5.846996303007472}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1068, "makespan": 43, "avg_agents_density": 0.17885994316071596, "runtime": 2.0946298509516055}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2363, "makespan": 72, "avg_agents_density": 0.18219028123032446, "runtime": 3.10602614506206}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4565, "makespan": 128, "avg_agents_density": 0.17799951537329511, "runtime": 5.680422430974431}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 5596, "makespan": 128, "avg_agents_density": 0.23871037929889077, "runtime": 5.908582289950573}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 3096, "makespan": 79, "avg_agents_density": 0.20912125115781902, "runtime": 3.6906165289401542}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 3932, "makespan": 104, "avg_agents_density": 0.22803677492690466, "runtime": 4.141928157987422}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1556, "makespan": 50, "avg_agents_density": 0.19190374438823765, "runtime": 1.9908343020215398}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-280000"}]