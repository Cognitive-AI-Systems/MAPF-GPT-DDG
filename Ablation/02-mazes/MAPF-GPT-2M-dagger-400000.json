[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 659, "makespan": 34, "avg_agents_density": 0.09927443066169055, "runtime": 1.0902207210310735}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 851, "makespan": 45, "avg_agents_density": 0.12052468729931912, "runtime": 0.8765923710307106}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 913, "makespan": 83, "avg_agents_density": 0.082735188646599, "runtime": 1.7321217210119357}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 725, "makespan": 49, "avg_agents_density": 0.11154530215774176, "runtime": 1.6156798829179024}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 829, "makespan": 48, "avg_agents_density": 0.1002517762494541, "runtime": 1.7273906159680337}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1038, "makespan": 48, "avg_agents_density": 0.10611696091749902, "runtime": 1.5612342489912407}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 703, "makespan": 38, "avg_agents_density": 0.10395830855253414, "runtime": 1.4207221949473023}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1249, "makespan": 54, "avg_agents_density": 0.10922760755482941, "runtime": 1.3624528019863646}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 896, "makespan": 44, "avg_agents_density": 0.11065792419546229, "runtime": 1.4239247710065683}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 714, "makespan": 46, "avg_agents_density": 0.12412359491304256, "runtime": 0.5322868400253356}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 808, "makespan": 60, "avg_agents_density": 0.0846929069921034, "runtime": 1.7582575320120668}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 911, "makespan": 41, "avg_agents_density": 0.1494645522537125, "runtime": 1.2772990929806838}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 661, "makespan": 35, "avg_agents_density": 0.10869281133511631, "runtime": 0.9370402850181563}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 659, "makespan": 36, "avg_agents_density": 0.1065824770496757, "runtime": 0.9666042559692869}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 768, "makespan": 42, "avg_agents_density": 0.12239886613244753, "runtime": 1.1577846359869}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 884, "makespan": 43, "avg_agents_density": 0.11961358901105154, "runtime": 0.4173904050694546}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 786, "makespan": 39, "avg_agents_density": 0.10826337224084262, "runtime": 1.2305772330437321}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 677, "makespan": 50, "avg_agents_density": 0.09275122349554851, "runtime": 1.7030029889865546}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1030, "makespan": 49, "avg_agents_density": 0.11303895887609175, "runtime": 1.7776209179864964}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 831, "makespan": 41, "avg_agents_density": 0.11627382179037611, "runtime": 0.4423063530266518}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 886, "makespan": 63, "avg_agents_density": 0.08917851869614506, "runtime": 0.7861320370138856}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 842, "makespan": 53, "avg_agents_density": 0.10945403465971892, "runtime": 0.41231400999822654}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 621, "makespan": 39, "avg_agents_density": 0.09320253175069645, "runtime": 0.7196472409123089}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 792, "makespan": 40, "avg_agents_density": 0.11548294947195846, "runtime": 1.244773616985185}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 852, "makespan": 45, "avg_agents_density": 0.10140503226229752, "runtime": 1.7807339380524354}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 415, "makespan": 29, "avg_agents_density": 0.09256339138008078, "runtime": 0.7722308990050806}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 643, "makespan": 36, "avg_agents_density": 0.09666379504319261, "runtime": 1.006491138075944}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 975, "makespan": 60, "avg_agents_density": 0.09012523442722035, "runtime": 1.6369910410576267}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1000, "makespan": 57, "avg_agents_density": 0.08724466165683241, "runtime": 0.584508438987541}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 849, "makespan": 56, "avg_agents_density": 0.11129785052824398, "runtime": 0.5397350399871357}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 663, "makespan": 33, "avg_agents_density": 0.11403740954549844, "runtime": 0.288452759035863}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 535, "makespan": 38, "avg_agents_density": 0.1091122513438922, "runtime": 0.5395062480674824}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1384, "makespan": 46, "avg_agents_density": 0.1461609396042369, "runtime": 1.9580218550254358}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1838, "makespan": 63, "avg_agents_density": 0.15821104702262312, "runtime": 1.6862734860333148}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1337, "makespan": 62, "avg_agents_density": 0.13920550906829543, "runtime": 1.9579553639050573}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1387, "makespan": 50, "avg_agents_density": 0.17769817836609977, "runtime": 1.5829551280476153}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1484, "makespan": 52, "avg_agents_density": 0.14210067411654836, "runtime": 1.9379023120127385}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1699, "makespan": 58, "avg_agents_density": 0.16099655557699896, "runtime": 2.219098386965925}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1143, "makespan": 45, "avg_agents_density": 0.14300127607131946, "runtime": 1.4993073670048034}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 3441, "makespan": 123, "avg_agents_density": 0.14655685441617955, "runtime": 4.994780947017716}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1580, "makespan": 52, "avg_agents_density": 0.1647352308965537, "runtime": 1.9374000569805503}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1422, "makespan": 53, "avg_agents_density": 0.1724128150574771, "runtime": 1.7709024580253754}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1590, "makespan": 74, "avg_agents_density": 0.1322980218751302, "runtime": 2.6895095859945286}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3116, "makespan": 128, "avg_agents_density": 0.21835395420162815, "runtime": 4.692495042152586}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1270, "makespan": 50, "avg_agents_density": 0.16149988618912445, "runtime": 2.0311539670510683}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1249, "makespan": 47, "avg_agents_density": 0.14991064814441377, "runtime": 1.7165715920127695}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1393, "makespan": 54, "avg_agents_density": 0.17975869126135666, "runtime": 1.6937365460034925}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1523, "makespan": 46, "avg_agents_density": 0.15921085673071242, "runtime": 1.8166894580062944}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1984, "makespan": 62, "avg_agents_density": 0.18515992934951028, "runtime": 1.9439661619544495}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1206, "makespan": 47, "avg_agents_density": 0.12076765009143182, "runtime": 1.5216542340203887}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2061, "makespan": 71, "avg_agents_density": 0.1561826564528181, "runtime": 2.3474532419786556}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 4086, "makespan": 123, "avg_agents_density": 0.1983072668782473, "runtime": 2.9189376859285403}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1529, "makespan": 54, "avg_agents_density": 0.14265547155620698, "runtime": 1.8523590040422278}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1884, "makespan": 63, "avg_agents_density": 0.16057811180468684, "runtime": 2.127473361964803}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1108, "makespan": 46, "avg_agents_density": 0.1374182405181859, "runtime": 1.3439570099872071}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1631, "makespan": 58, "avg_agents_density": 0.16890664678038195, "runtime": 2.1439214020501822}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1728, "makespan": 67, "avg_agents_density": 0.15509621301066165, "runtime": 2.1450156469800277}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 647, "makespan": 29, "avg_agents_density": 0.13674365417927614, "runtime": 0.9421876069973223}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1173, "makespan": 42, "avg_agents_density": 0.13219449463754085, "runtime": 1.6334497289790306}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1921, "makespan": 68, "avg_agents_density": 0.13315779962464216, "runtime": 1.9499315570428735}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2112, "makespan": 68, "avg_agents_density": 0.13716749557853308, "runtime": 2.2668464770977153}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1904, "makespan": 70, "avg_agents_density": 0.15111737554819907, "runtime": 1.9802370059478562}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1599, "makespan": 58, "avg_agents_density": 0.18334626284129435, "runtime": 1.544296316933469}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 925, "makespan": 39, "avg_agents_density": 0.1480344964383237, "runtime": 1.0464402280049399}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2723, "makespan": 70, "avg_agents_density": 0.1799478439929547, "runtime": 3.485158736963058}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 3862, "makespan": 91, "avg_agents_density": 0.22297948682579707, "runtime": 4.468634131058934}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 3287, "makespan": 79, "avg_agents_density": 0.22695303515957432, "runtime": 3.6100615249597467}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 2315, "makespan": 54, "avg_agents_density": 0.1993208448460816, "runtime": 2.749121223023394}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2726, "makespan": 75, "avg_agents_density": 0.1975970160465629, "runtime": 3.373469010097324}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3692, "makespan": 102, "avg_agents_density": 0.19728595540586297, "runtime": 4.89882094594941}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2563, "makespan": 76, "avg_agents_density": 0.18339023805239488, "runtime": 3.4145551538822474}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 128, "SoC": 5647, "makespan": 128, "avg_agents_density": 0.23340235263022852, "runtime": 5.778253605065402}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2803, "makespan": 65, "avg_agents_density": 0.21464358382068585, "runtime": 2.908858836017316}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2097, "makespan": 55, "avg_agents_density": 0.21731714247093376, "runtime": 2.586456392033142}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2877, "makespan": 97, "avg_agents_density": 0.17963629420432936, "runtime": 4.322889009024948}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 0.390625, "CSR": 0.0, "ep_length": 128, "SoC": 6467, "makespan": 128, "avg_agents_density": 0.35173337019035683, "runtime": 5.77183859507204}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2913, "makespan": 74, "avg_agents_density": 0.1950459938242999, "runtime": 3.5578657529258635}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2546, "makespan": 78, "avg_agents_density": 0.18998110832454088, "runtime": 3.5955278150358936}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2617, "makespan": 70, "avg_agents_density": 0.2077875307308771, "runtime": 3.594682644092245}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 3161, "makespan": 69, "avg_agents_density": 0.19354119951371715, "runtime": 2.7321747039968614}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 3448, "makespan": 106, "avg_agents_density": 0.19751487413477012, "runtime": 4.412864091063966}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1725, "makespan": 63, "avg_agents_density": 0.15283386299710186, "runtime": 2.631658069061814}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4658, "makespan": 128, "avg_agents_density": 0.18821798310417925, "runtime": 5.293797343954793}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 5272, "makespan": 128, "avg_agents_density": 0.19566386052226942, "runtime": 4.695817909974721}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 2718, "makespan": 93, "avg_agents_density": 0.191705142440471, "runtime": 4.045090137980878}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2916, "makespan": 63, "avg_agents_density": 0.20144163827910605, "runtime": 2.8104722149437293}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2176, "makespan": 69, "avg_agents_density": 0.1908318398184397, "runtime": 3.0709465600230033}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2675, "makespan": 68, "avg_agents_density": 0.2060727105185227, "runtime": 2.847983144063619}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 3200, "makespan": 86, "avg_agents_density": 0.19257634964373624, "runtime": 3.495963648034376}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 937, "makespan": 35, "avg_agents_density": 0.1838899910307076, "runtime": 1.4285166079935152}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1919, "makespan": 57, "avg_agents_density": 0.17544622707876367, "runtime": 2.683141476009041}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 3081, "makespan": 94, "avg_agents_density": 0.17132587732739918, "runtime": 3.9908074379054597}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4382, "makespan": 128, "avg_agents_density": 0.20096355085904097, "runtime": 5.34341670795402}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 3276, "makespan": 107, "avg_agents_density": 0.1926607446698381, "runtime": 4.293603864891338}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3346, "makespan": 102, "avg_agents_density": 0.21939142159973385, "runtime": 4.64882528486487}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1434, "makespan": 48, "avg_agents_density": 0.18544461780462412, "runtime": 2.598709170037182}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-400000"}]