[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 767, "makespan": 45, "avg_agents_density": 0.0984337576146049, "runtime": 0.6739893319318071}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1136, "makespan": 62, "avg_agents_density": 0.12054167275778269, "runtime": 1.1285273802350275}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 888, "makespan": 84, "avg_agents_density": 0.08614375396169408, "runtime": 0.7681171701406129}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 671, "makespan": 39, "avg_agents_density": 0.10572234503131687, "runtime": 0.7958290552487597}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 899, "makespan": 60, "avg_agents_density": 0.10366631582875895, "runtime": 1.282897293975111}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1074, "makespan": 70, "avg_agents_density": 0.10683674899369668, "runtime": 1.4240836921380833}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 1069, "makespan": 93, "avg_agents_density": 0.09503465271855845, "runtime": 2.0023142988211475}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 1432, "makespan": 94, "avg_agents_density": 0.10368113785545018, "runtime": 1.8574817230110057}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 991, "makespan": 47, "avg_agents_density": 0.11823218015485011, "runtime": 0.931498464778997}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 747, "makespan": 66, "avg_agents_density": 0.12138812573251066, "runtime": 0.6168642240809277}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 889, "makespan": 61, "avg_agents_density": 0.087868000649231, "runtime": 1.3408698888961226}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 1463, "makespan": 126, "avg_agents_density": 0.13778992163781723, "runtime": 2.188348278636113}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 915, "makespan": 48, "avg_agents_density": 0.10638960700457202, "runtime": 0.9818337588803843}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 622, "makespan": 40, "avg_agents_density": 0.10624009230157706, "runtime": 0.9156099471729249}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1134, "makespan": 56, "avg_agents_density": 0.12081981801586725, "runtime": 1.0189038519165479}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 996, "makespan": 58, "avg_agents_density": 0.10973344534719481, "runtime": 0.3371620719553903}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 999, "makespan": 59, "avg_agents_density": 0.11226178687283771, "runtime": 1.0929217661032453}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 639, "makespan": 49, "avg_agents_density": 0.08698463879547974, "runtime": 1.0948822889477015}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1379, "makespan": 87, "avg_agents_density": 0.11186271478691032, "runtime": 1.7728790640248917}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1502, "makespan": 128, "avg_agents_density": 0.11075174268837445, "runtime": 0.6971627924358472}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 921, "makespan": 72, "avg_agents_density": 0.0934818320741962, "runtime": 1.1358704989543185}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 846, "makespan": 45, "avg_agents_density": 0.1100603448808263, "runtime": 0.2513948830892332}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 681, "makespan": 46, "avg_agents_density": 0.09489274291859054, "runtime": 0.6473416720400564}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 1002, "makespan": 94, "avg_agents_density": 0.10376795124748657, "runtime": 1.8075559136341326}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1027, "makespan": 64, "avg_agents_density": 0.09490187286779374, "runtime": 1.0615902410354465}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 418, "makespan": 29, "avg_agents_density": 0.09250052074612958, "runtime": 0.5068286909372546}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 728, "makespan": 38, "avg_agents_density": 0.09664356345891545, "runtime": 0.7697101889643818}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 1214, "makespan": 98, "avg_agents_density": 0.08634698184359642, "runtime": 1.6194613888510503}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1295, "makespan": 69, "avg_agents_density": 0.09021971413107159, "runtime": 0.36016981315333396}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 1320, "makespan": 81, "avg_agents_density": 0.09814957098644912, "runtime": 0.8141719427076168}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1017, "makespan": 74, "avg_agents_density": 0.11139508353076129, "runtime": 0.45668073691194877}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 596, "makespan": 42, "avg_agents_density": 0.10985768998492113, "runtime": 0.4344907889026217}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2103, "makespan": 68, "avg_agents_density": 0.1635878089556797, "runtime": 1.9652826311648823}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 1982, "makespan": 81, "avg_agents_density": 0.14968443512876353, "runtime": 1.8555629720212892}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1422, "makespan": 70, "avg_agents_density": 0.1365588117373375, "runtime": 1.7891980409040116}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1396, "makespan": 47, "avg_agents_density": 0.15986381884167816, "runtime": 1.2022080922615714}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1783, "makespan": 67, "avg_agents_density": 0.14861105616563158, "runtime": 1.7121184079442173}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2679, "makespan": 87, "avg_agents_density": 0.15248652271285867, "runtime": 2.383578934764955}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1456, "makespan": 57, "avg_agents_density": 0.1435237911286274, "runtime": 1.4823313321685418}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3176, "makespan": 128, "avg_agents_density": 0.1507678408396735, "runtime": 3.6090107742347755}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1653, "makespan": 65, "avg_agents_density": 0.16244951228449375, "runtime": 1.6431648074067198}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 1880, "makespan": 128, "avg_agents_density": 0.1696403963857557, "runtime": 3.3683380577131175}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1369, "makespan": 52, "avg_agents_density": 0.12783764155389304, "runtime": 1.4605416308622807}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2329, "makespan": 80, "avg_agents_density": 0.2031652385151179, "runtime": 2.0265320105827413}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1931, "makespan": 71, "avg_agents_density": 0.16250618191310537, "runtime": 1.9682749730418436}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1353, "makespan": 43, "avg_agents_density": 0.1466291129248228, "runtime": 1.2512891142978333}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1458, "makespan": 50, "avg_agents_density": 0.17709262180250424, "runtime": 1.2554602451855317}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 1952, "makespan": 98, "avg_agents_density": 0.1696810366964986, "runtime": 2.733513393846806}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1942, "makespan": 60, "avg_agents_density": 0.1732629792275682, "runtime": 1.5157559228828177}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1191, "makespan": 55, "avg_agents_density": 0.12467164321682056, "runtime": 1.3562554979580455}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 2678, "makespan": 128, "avg_agents_density": 0.1569443903168304, "runtime": 3.1970231468440033}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.7708333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4825, "makespan": 128, "avg_agents_density": 0.22062866587258845, "runtime": 2.168126486823894}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1767, "makespan": 70, "avg_agents_density": 0.1437848691539796, "runtime": 1.5150671360315755}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 2376, "makespan": 123, "avg_agents_density": 0.16353967427079447, "runtime": 2.6018686059396714}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1090, "makespan": 41, "avg_agents_density": 0.15144778599403427, "runtime": 0.9610650302493013}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1527, "makespan": 49, "avg_agents_density": 0.1738942638921318, "runtime": 1.077353738131933}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1783, "makespan": 66, "avg_agents_density": 0.15482990696186122, "runtime": 1.7637587530189194}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 757, "makespan": 38, "avg_agents_density": 0.13819496605134712, "runtime": 0.9642833131947555}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1053, "makespan": 35, "avg_agents_density": 0.13780243066370065, "runtime": 0.8967164799105376}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 2565, "makespan": 109, "avg_agents_density": 0.13793548938682085, "runtime": 2.5228273941902444}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 2787, "makespan": 114, "avg_agents_density": 0.14839626289853478, "runtime": 2.5171300154179335}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 2883, "makespan": 109, "avg_agents_density": 0.18078730462154408, "runtime": 2.7657576334895566}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1863, "makespan": 63, "avg_agents_density": 0.1792023424784292, "runtime": 1.435786385089159}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 985, "makespan": 42, "avg_agents_density": 0.1408584165927697, "runtime": 1.0184967699460685}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4101, "makespan": 128, "avg_agents_density": 0.20301731996932368, "runtime": 4.609008927538525}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 4650, "makespan": 115, "avg_agents_density": 0.21747459984017245, "runtime": 4.1778829483664595}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4129, "makespan": 128, "avg_agents_density": 0.21951081596095992, "runtime": 4.44718759303214}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 2384, "makespan": 128, "avg_agents_density": 0.19255884899366668, "runtime": 4.616145688982215}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4941, "makespan": 128, "avg_agents_density": 0.24120356140286928, "runtime": 4.5478399937273934}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5552, "makespan": 128, "avg_agents_density": 0.2181589051964932, "runtime": 4.339600792096462}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 3118, "makespan": 89, "avg_agents_density": 0.19193990501847452, "runtime": 2.9467923081247136}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 128, "SoC": 5943, "makespan": 128, "avg_agents_density": 0.19825329152740762, "runtime": 4.143038303300273}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3720, "makespan": 128, "avg_agents_density": 0.18661366738460264, "runtime": 4.159551908320282}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3015, "makespan": 128, "avg_agents_density": 0.21708716613348822, "runtime": 4.095251338905655}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2835, "makespan": 82, "avg_agents_density": 0.17519645832539543, "runtime": 2.7000138871371746}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 128, "SoC": 6586, "makespan": 128, "avg_agents_density": 0.3662396910133548, "runtime": 4.146126061619725}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 3633, "makespan": 128, "avg_agents_density": 0.19838397328159446, "runtime": 4.069376885774545}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3346, "makespan": 128, "avg_agents_density": 0.1898119095037663, "runtime": 4.0983351218746975}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3519, "makespan": 128, "avg_agents_density": 0.21545988223781998, "runtime": 3.93340190424351}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4029, "makespan": 128, "avg_agents_density": 0.19896810008000954, "runtime": 3.9835643691476434}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 5210, "makespan": 128, "avg_agents_density": 0.2173801073425102, "runtime": 4.018583565601148}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 2071, "makespan": 53, "avg_agents_density": 0.15532387240638587, "runtime": 1.6497707709786482}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5686, "makespan": 128, "avg_agents_density": 0.19659597369669898, "runtime": 3.6480702609405853}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 128, "SoC": 7040, "makespan": 128, "avg_agents_density": 0.25833476639714864, "runtime": 3.7166069918312132}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3383, "makespan": 101, "avg_agents_density": 0.20312318669975105, "runtime": 2.9264567100908607}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 3779, "makespan": 120, "avg_agents_density": 0.2143427737569627, "runtime": 3.3833176960470155}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1751, "makespan": 49, "avg_agents_density": 0.18702056453409507, "runtime": 1.4053383541759104}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4327, "makespan": 128, "avg_agents_density": 0.20467310667154606, "runtime": 3.936461531848181}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4156, "makespan": 128, "avg_agents_density": 0.20122374275889018, "runtime": 4.052317564259283}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1002, "makespan": 40, "avg_agents_density": 0.1740912541715016, "runtime": 1.2355311079300009}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 2169, "makespan": 54, "avg_agents_density": 0.18945913564204156, "runtime": 1.6930403119768016}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 3754, "makespan": 109, "avg_agents_density": 0.1761931192564125, "runtime": 3.3828836367465556}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 4285, "makespan": 120, "avg_agents_density": 0.20817977960279463, "runtime": 3.8106536417035386}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 4001, "makespan": 128, "avg_agents_density": 0.19728256724234006, "runtime": 4.067818568611983}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 128, "SoC": 4760, "makespan": 128, "avg_agents_density": 0.22126471304949646, "runtime": 4.087997086928226}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1532, "makespan": 47, "avg_agents_density": 0.19402196778572126, "runtime": 1.7872531039756723}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-48000"}]