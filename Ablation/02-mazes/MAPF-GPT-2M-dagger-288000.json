[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 648, "makespan": 33, "avg_agents_density": 0.0989477209013985, "runtime": 1.2654194089991506}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 966, "makespan": 51, "avg_agents_density": 0.12089964656630789, "runtime": 1.8328009419492446}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 862, "makespan": 50, "avg_agents_density": 0.08844454454904997, "runtime": 1.7333910179295344}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 709, "makespan": 42, "avg_agents_density": 0.10876307950101251, "runtime": 1.3475853179697879}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 889, "makespan": 44, "avg_agents_density": 0.1159639384706193, "runtime": 1.2431671059748624}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1069, "makespan": 69, "avg_agents_density": 0.10514957899091026, "runtime": 2.487598852982046}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 888, "makespan": 53, "avg_agents_density": 0.09830472550339354, "runtime": 1.83394549395598}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1269, "makespan": 71, "avg_agents_density": 0.11366878819153113, "runtime": 2.5738577610463835}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1027, "makespan": 50, "avg_agents_density": 0.11177092096245454, "runtime": 1.7947893329837825}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 650, "makespan": 41, "avg_agents_density": 0.1345196548740812, "runtime": 1.1463982420391403}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 849, "makespan": 60, "avg_agents_density": 0.08853984332799754, "runtime": 2.0518470771203283}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1059, "makespan": 49, "avg_agents_density": 0.15161010756179766, "runtime": 1.771983173020999}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 718, "makespan": 35, "avg_agents_density": 0.11515503830779873, "runtime": 1.1883531040512025}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 647, "makespan": 39, "avg_agents_density": 0.10841333780242188, "runtime": 1.5448174860503059}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 681, "makespan": 43, "avg_agents_density": 0.12290872000327681, "runtime": 1.6571768390276702}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 952, "makespan": 42, "avg_agents_density": 0.1095878367490965, "runtime": 1.0641506040847162}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 807, "makespan": 40, "avg_agents_density": 0.1060997956039859, "runtime": 1.0079948968923418}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 655, "makespan": 44, "avg_agents_density": 0.08941063619192181, "runtime": 1.1610747469821945}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1164, "makespan": 52, "avg_agents_density": 0.1237388132160553, "runtime": 1.707421697996324}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1175, "makespan": 69, "avg_agents_density": 0.11005628809156469, "runtime": 1.8207844169810414}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 977, "makespan": 82, "avg_agents_density": 0.09209743619484487, "runtime": 2.6307786240358837}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 898, "makespan": 40, "avg_agents_density": 0.1166546702310249, "runtime": 0.6488359739305452}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 629, "makespan": 39, "avg_agents_density": 0.09639411657903617, "runtime": 1.030451814949629}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 711, "makespan": 40, "avg_agents_density": 0.11713476724416218, "runtime": 1.3679563749901718}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 869, "makespan": 58, "avg_agents_density": 0.09675520340780026, "runtime": 2.048267749894876}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 425, "makespan": 31, "avg_agents_density": 0.09361239506701687, "runtime": 0.6420293750416022}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 730, "makespan": 46, "avg_agents_density": 0.09253695871453403, "runtime": 0.7441076079412596}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 864, "makespan": 45, "avg_agents_density": 0.09364974389649819, "runtime": 1.6308963808696717}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1058, "makespan": 63, "avg_agents_density": 0.09071030684297283, "runtime": 0.7426580689789262}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 909, "makespan": 44, "avg_agents_density": 0.10821354010199355, "runtime": 1.0581223189947195}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 749, "makespan": 39, "avg_agents_density": 0.11181773128717107, "runtime": 0.37445397800183855}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 557, "makespan": 31, "avg_agents_density": 0.11324682528863485, "runtime": 0.6434259089583065}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1375, "makespan": 45, "avg_agents_density": 0.14436761647784965, "runtime": 1.8653633140347665}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1636, "makespan": 58, "avg_agents_density": 0.15160137742359286, "runtime": 2.0476280610018875}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1273, "makespan": 54, "avg_agents_density": 0.14350513413424643, "runtime": 1.993672137017711}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1272, "makespan": 49, "avg_agents_density": 0.1587683765463493, "runtime": 1.6602091509703314}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1571, "makespan": 59, "avg_agents_density": 0.15238487128327086, "runtime": 2.5228909959696466}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2944, "makespan": 128, "avg_agents_density": 0.14730545739950615, "runtime": 4.518676274994505}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1425, "makespan": 52, "avg_agents_density": 0.14343535896333787, "runtime": 1.8527749969944125}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 3054, "makespan": 128, "avg_agents_density": 0.15514327523985944, "runtime": 4.6832595628802665}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1615, "makespan": 70, "avg_agents_density": 0.16715538023085022, "runtime": 2.697886258974904}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1496, "makespan": 48, "avg_agents_density": 0.17885720042201914, "runtime": 1.5921822779491777}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1286, "makespan": 52, "avg_agents_density": 0.1297633592809657, "runtime": 2.1287729510077043}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 128, "SoC": 4085, "makespan": 128, "avg_agents_density": 0.3124401885473676, "runtime": 4.627910189097747}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1510, "makespan": 57, "avg_agents_density": 0.16078923855911287, "runtime": 2.219596116017783}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1307, "makespan": 52, "avg_agents_density": 0.14820277626800402, "runtime": 1.8581212839344516}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1463, "makespan": 51, "avg_agents_density": 0.1713675381059526, "runtime": 1.7665488649945473}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1538, "makespan": 48, "avg_agents_density": 0.16553498500973782, "runtime": 1.995754641960957}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1486, "makespan": 50, "avg_agents_density": 0.16182277887212587, "runtime": 1.6442500089469831}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1246, "makespan": 51, "avg_agents_density": 0.1304969638970869, "runtime": 1.6829121600021608}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3426, "makespan": 128, "avg_agents_density": 0.1743213189525302, "runtime": 4.436323903064476}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 2580, "makespan": 107, "avg_agents_density": 0.1700119308931283, "runtime": 3.691094800029532}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1811, "makespan": 61, "avg_agents_density": 0.1422889309560148, "runtime": 2.039771966970875}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1554, "makespan": 47, "avg_agents_density": 0.15641021602160754, "runtime": 1.6272516219760291}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1168, "makespan": 47, "avg_agents_density": 0.14698098873023827, "runtime": 1.6457771819841582}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1646, "makespan": 55, "avg_agents_density": 0.16819055885161263, "runtime": 1.8170173129765317}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1985, "makespan": 71, "avg_agents_density": 0.15882214652728482, "runtime": 2.5530600929487264}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 662, "makespan": 36, "avg_agents_density": 0.1321639462909062, "runtime": 1.121994567947695}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1304, "makespan": 44, "avg_agents_density": 0.13318216226982318, "runtime": 1.954769147967454}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1994, "makespan": 70, "avg_agents_density": 0.13698763918116746, "runtime": 2.3752329759736313}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2628, "makespan": 95, "avg_agents_density": 0.15217420011365201, "runtime": 3.1094774969969876}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2116, "makespan": 85, "avg_agents_density": 0.15755431521262875, "runtime": 2.920623910118593}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1487, "makespan": 59, "avg_agents_density": 0.18187258873930334, "runtime": 1.9001276930503082}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 873, "makespan": 32, "avg_agents_density": 0.1514802347212461, "runtime": 1.1064187179872533}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2563, "makespan": 76, "avg_agents_density": 0.1795308508883111, "runtime": 3.4353738600184442}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 4047, "makespan": 128, "avg_agents_density": 0.20048461916970833, "runtime": 6.28629712809925}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2409, "makespan": 79, "avg_agents_density": 0.19987366096315698, "runtime": 4.47350905201165}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2349, "makespan": 63, "avg_agents_density": 0.203794475471465, "runtime": 2.90798407389957}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2603, "makespan": 79, "avg_agents_density": 0.1989934490458256, "runtime": 3.9653567040222697}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 5066, "makespan": 128, "avg_agents_density": 0.20032794975632232, "runtime": 5.881911358999787}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 3159, "makespan": 123, "avg_agents_density": 0.1857103048296521, "runtime": 5.512968549039215}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 128, "SoC": 5900, "makespan": 128, "avg_agents_density": 0.20113362049026975, "runtime": 6.250601921885391}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 3829, "makespan": 106, "avg_agents_density": 0.21119000803277183, "runtime": 5.321787567940191}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2228, "makespan": 55, "avg_agents_density": 0.22459310570217375, "runtime": 2.6101556369831087}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2106, "makespan": 58, "avg_agents_density": 0.16899852843197435, "runtime": 2.568766534081078}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 128, "SoC": 6684, "makespan": 128, "avg_agents_density": 0.3516455760279447, "runtime": 5.949015756996232}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 2568, "makespan": 54, "avg_agents_density": 0.2053117495969025, "runtime": 2.415299156054971}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1850, "makespan": 55, "avg_agents_density": 0.18747392762181064, "runtime": 2.6522080719296355}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 2604, "makespan": 128, "avg_agents_density": 0.1996408953418086, "runtime": 6.237852586025838}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2813, "makespan": 95, "avg_agents_density": 0.20335416156156594, "runtime": 4.120073972051614}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3851, "makespan": 128, "avg_agents_density": 0.20150733072273547, "runtime": 5.932135521958116}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1852, "makespan": 56, "avg_agents_density": 0.1505067861266703, "runtime": 2.8243800119671505}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 6008, "makespan": 128, "avg_agents_density": 0.2150971633190864, "runtime": 5.588715353951557}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 128, "SoC": 6577, "makespan": 128, "avg_agents_density": 0.2343902296220612, "runtime": 5.300621949878405}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 128, "SoC": 3629, "makespan": 128, "avg_agents_density": 0.18600414866313553, "runtime": 5.939061024822877}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2937, "makespan": 65, "avg_agents_density": 0.21294530952373172, "runtime": 2.6982982759654988}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1573, "makespan": 45, "avg_agents_density": 0.17997248590116213, "runtime": 2.0368601339578163}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 3188, "makespan": 83, "avg_agents_density": 0.21067306530474234, "runtime": 4.0724429229449015}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 128, "SoC": 4112, "makespan": 128, "avg_agents_density": 0.1930277781914067, "runtime": 5.274775930942269}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 1014, "makespan": 30, "avg_agents_density": 0.18210642995889065, "runtime": 1.455808235987206}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1890, "makespan": 54, "avg_agents_density": 0.1754788287261686, "runtime": 2.3533852769905934}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4920, "makespan": 128, "avg_agents_density": 0.18778642700612144, "runtime": 6.275128799141385}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5756, "makespan": 128, "avg_agents_density": 0.22719400096834266, "runtime": 6.17459708993556}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 3660, "makespan": 113, "avg_agents_density": 0.20388329978074654, "runtime": 5.373750426064362}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 3213, "makespan": 114, "avg_agents_density": 0.22978882249024965, "runtime": 5.286703395991935}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1558, "makespan": 50, "avg_agents_density": 0.19334519425684615, "runtime": 2.354659178032307}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-dagger-288000"}]