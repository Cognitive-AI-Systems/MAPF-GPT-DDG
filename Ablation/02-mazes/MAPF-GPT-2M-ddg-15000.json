[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 672, "makespan": 32, "avg_agents_density": 0.09896895878520291, "runtime": 0.5064703861135058}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 978, "makespan": 60, "avg_agents_density": 0.1165089971531278, "runtime": 0.7366104768007062}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1222, "makespan": 128, "avg_agents_density": 0.08054220531479875, "runtime": 1.4317087223171256}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 669, "makespan": 34, "avg_agents_density": 0.11363722101499485, "runtime": 0.7374617449822836}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 842, "makespan": 47, "avg_agents_density": 0.11091359081599901, "runtime": 1.0169443272752687}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1357, "makespan": 91, "avg_agents_density": 0.10162823620725349, "runtime": 1.5339502223068848}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 835, "makespan": 128, "avg_agents_density": 0.09588062644177035, "runtime": 1.791740411950741}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 1602, "makespan": 122, "avg_agents_density": 0.1038024130075841, "runtime": 2.6715391983743757}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1101, "makespan": 66, "avg_agents_density": 0.10716618948915474, "runtime": 1.1118356609367765}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 702, "makespan": 37, "avg_agents_density": 0.12960978550941102, "runtime": 0.430686684907414}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 904, "makespan": 68, "avg_agents_density": 0.08502630484370902, "runtime": 1.0069820007192902}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1237, "makespan": 66, "avg_agents_density": 0.16237792919682723, "runtime": 0.8232051327358931}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 665, "makespan": 36, "avg_agents_density": 0.11170493208607148, "runtime": 0.7977163120522164}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 642, "makespan": 37, "avg_agents_density": 0.11008127531183827, "runtime": 0.8005226779496297}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 944, "makespan": 112, "avg_agents_density": 0.11111611811992982, "runtime": 1.4560986538417637}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 993, "makespan": 80, "avg_agents_density": 0.10473873863251525, "runtime": 0.9034092668443918}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 1583, "makespan": 128, "avg_agents_density": 0.10857477841425897, "runtime": 1.4245039159432054}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 652, "makespan": 39, "avg_agents_density": 0.0907205185349705, "runtime": 0.8267037702607922}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 1444, "makespan": 86, "avg_agents_density": 0.1197180088039854, "runtime": 1.9296450281399302}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1182, "makespan": 91, "avg_agents_density": 0.1123602128176724, "runtime": 0.7424767931806855}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1369, "makespan": 128, "avg_agents_density": 0.09291218672338042, "runtime": 1.4423280261689797}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 1046, "makespan": 128, "avg_agents_density": 0.1047396032632048, "runtime": 1.0668124575167894}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 617, "makespan": 35, "avg_agents_density": 0.09469995320672694, "runtime": 0.40606480895075947}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 854, "makespan": 128, "avg_agents_density": 0.09767027150903115, "runtime": 2.714469560829457}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 889, "makespan": 53, "avg_agents_density": 0.10047456930565579, "runtime": 0.9324015098973177}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 428, "makespan": 29, "avg_agents_density": 0.09685439937297616, "runtime": 0.2921530772000551}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 722, "makespan": 41, "avg_agents_density": 0.09735788828667571, "runtime": 0.9377212797990069}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 890, "makespan": 62, "avg_agents_density": 0.08635584094181394, "runtime": 1.1966572960373014}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1130, "makespan": 62, "avg_agents_density": 0.09121143433696872, "runtime": 0.38170309917768463}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 1255, "makespan": 128, "avg_agents_density": 0.10133119170800138, "runtime": 1.051912223920226}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 790, "makespan": 128, "avg_agents_density": 0.10302224672165464, "runtime": 0.6964667607098818}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 512, "makespan": 27, "avg_agents_density": 0.11070714572719369, "runtime": 0.3038837709464133}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1437, "makespan": 60, "avg_agents_density": 0.14704872421765866, "runtime": 1.8212029561400414}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 1833, "makespan": 93, "avg_agents_density": 0.1544239167145066, "runtime": 2.130809751281049}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2397, "makespan": 128, "avg_agents_density": 0.14097524469363015, "runtime": 3.0205724940169603}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 2342, "makespan": 103, "avg_agents_density": 0.17858377918928034, "runtime": 2.3441983467782848}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1822, "makespan": 69, "avg_agents_density": 0.159445425624955, "runtime": 1.8200061901588924}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2815, "makespan": 128, "avg_agents_density": 0.15336212724423462, "runtime": 3.500891944859177}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1412, "makespan": 69, "avg_agents_density": 0.14690118063697832, "runtime": 1.7532183999428526}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 3407, "makespan": 128, "avg_agents_density": 0.15061229961038675, "runtime": 3.4024294370319694}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 2142, "makespan": 94, "avg_agents_density": 0.16981758930577523, "runtime": 2.4957410010392778}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1968, "makespan": 128, "avg_agents_density": 0.1792461933331742, "runtime": 3.326327196904458}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1571, "makespan": 72, "avg_agents_density": 0.12753401699949754, "runtime": 1.832513464265503}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.5208333333333334, "CSR": 0.0, "ep_length": 128, "SoC": 4073, "makespan": 128, "avg_agents_density": 0.2929497638744308, "runtime": 3.3750144201912917}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1643, "makespan": 83, "avg_agents_density": 0.1629084685191843, "runtime": 2.2670746041694656}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1226, "makespan": 40, "avg_agents_density": 0.15243972218885485, "runtime": 1.1606667831656523}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 1459, "makespan": 101, "avg_agents_density": 0.16089420492040607, "runtime": 2.525266555021517}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1989, "makespan": 87, "avg_agents_density": 0.16527128413038158, "runtime": 2.588091944810003}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 3826, "makespan": 128, "avg_agents_density": 0.2450410317553595, "runtime": 2.8844270649715327}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1175, "makespan": 44, "avg_agents_density": 0.12317558331386887, "runtime": 1.1485921339481138}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 2749, "makespan": 128, "avg_agents_density": 0.16351772799420478, "runtime": 3.439789851778187}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 128, "SoC": 4297, "makespan": 128, "avg_agents_density": 0.17885550257962687, "runtime": 1.990636931732297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1824, "makespan": 77, "avg_agents_density": 0.14658350246219606, "runtime": 1.6661181629169732}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 1991, "makespan": 83, "avg_agents_density": 0.1669057725385691, "runtime": 1.3238850519992411}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1049, "makespan": 43, "avg_agents_density": 0.14935063935711607, "runtime": 1.0668335889931768}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1867, "makespan": 70, "avg_agents_density": 0.17013711525142908, "runtime": 1.573407320131082}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 1790, "makespan": 76, "avg_agents_density": 0.15590116907562435, "runtime": 1.8638987900922075}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 639, "makespan": 27, "avg_agents_density": 0.13911547552170161, "runtime": 0.6835230149445124}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1265, "makespan": 49, "avg_agents_density": 0.14056581062275356, "runtime": 1.4287730748183094}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 2240, "makespan": 107, "avg_agents_density": 0.13446986011914744, "runtime": 2.3770649726502597}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 128, "SoC": 3900, "makespan": 128, "avg_agents_density": 0.17150089456480375, "runtime": 2.8408700614236295}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2263, "makespan": 97, "avg_agents_density": 0.1618183335417919, "runtime": 2.1707523652003147}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 128, "SoC": 1788, "makespan": 128, "avg_agents_density": 0.17294963804065672, "runtime": 2.743389145936817}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 891, "makespan": 37, "avg_agents_density": 0.14452480561585834, "runtime": 0.8871039577643387}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.671875, "CSR": 0.0, "ep_length": 128, "SoC": 4482, "makespan": 128, "avg_agents_density": 0.22425507599820022, "runtime": 4.385648202267475}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 5347, "makespan": 128, "avg_agents_density": 0.2331885815342617, "runtime": 4.460901586106047}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 4991, "makespan": 128, "avg_agents_density": 0.22207330916739312, "runtime": 4.407781649788376}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 128, "SoC": 3796, "makespan": 128, "avg_agents_density": 0.21157342738486468, "runtime": 4.467269310145639}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3843, "makespan": 128, "avg_agents_density": 0.22691242180450047, "runtime": 4.441819378291257}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 128, "SoC": 7254, "makespan": 128, "avg_agents_density": 0.30941176361681283, "runtime": 4.465879576804582}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 3810, "makespan": 128, "avg_agents_density": 0.1917806419913536, "runtime": 4.079785507987253}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 128, "SoC": 6411, "makespan": 128, "avg_agents_density": 0.22138075398230928, "runtime": 4.101355806167703}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 3663, "makespan": 122, "avg_agents_density": 0.2089220031637521, "runtime": 3.8090602713637054}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 128, "SoC": 3010, "makespan": 128, "avg_agents_density": 0.21527894138294126, "runtime": 4.083416585170198}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 128, "SoC": 4522, "makespan": 128, "avg_agents_density": 0.21043148105579088, "runtime": 4.042730682122055}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 128, "SoC": 7462, "makespan": 128, "avg_agents_density": 0.3649113574679303, "runtime": 4.041211249947082}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2459, "makespan": 70, "avg_agents_density": 0.2073619294680774, "runtime": 2.2683552443631925}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2229, "makespan": 60, "avg_agents_density": 0.20002870807381398, "runtime": 1.9511087068240158}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2631, "makespan": 79, "avg_agents_density": 0.20853180864869786, "runtime": 2.9242277158773504}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 3829, "makespan": 126, "avg_agents_density": 0.20858677353552496, "runtime": 4.027377000194974}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 128, "SoC": 5463, "makespan": 128, "avg_agents_density": 0.21339532113784482, "runtime": 4.063184640544932}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1747, "makespan": 59, "avg_agents_density": 0.14977574758135329, "runtime": 1.874546245788224}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 128, "SoC": 6468, "makespan": 128, "avg_agents_density": 0.2280844108052902, "runtime": 3.8372708983370103}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.515625, "CSR": 0.0, "ep_length": 128, "SoC": 6660, "makespan": 128, "avg_agents_density": 0.2579404681229406, "runtime": 3.6643429588293657}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 128, "SoC": 4296, "makespan": 128, "avg_agents_density": 0.20070151687545187, "runtime": 3.716531586716883}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 4321, "makespan": 109, "avg_agents_density": 0.20110679359384118, "runtime": 3.133833975822199}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1569, "makespan": 42, "avg_agents_density": 0.18735776191294823, "runtime": 1.2695858421502635}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 128, "SoC": 4800, "makespan": 128, "avg_agents_density": 0.21681717105217357, "runtime": 3.9777243541320786}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 128, "SoC": 4048, "makespan": 128, "avg_agents_density": 0.19169298657445652, "runtime": 3.827608415274881}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 882, "makespan": 29, "avg_agents_density": 0.18083919375193772, "runtime": 0.9592437449027784}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2260, "makespan": 72, "avg_agents_density": 0.1753864017791318, "runtime": 2.186507831152994}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 128, "SoC": 5161, "makespan": 128, "avg_agents_density": 0.18764228748705097, "runtime": 3.9830554358195513}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 128, "SoC": 4978, "makespan": 128, "avg_agents_density": 0.19980007696264337, "runtime": 4.005485558940563}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 4344, "makespan": 128, "avg_agents_density": 0.21186991357598056, "runtime": 3.9587505442323163}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 128, "SoC": 3830, "makespan": 128, "avg_agents_density": 0.22298292589719584, "runtime": 4.032810363918543}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2374, "makespan": 75, "avg_agents_density": 0.2073051955016838, "runtime": 2.7040214700391516}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAPF-GPT-2M-ddg-15000"}]